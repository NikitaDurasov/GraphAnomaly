{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import networkx as nx\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import seaborn\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import time\n",
    "from shutil import copyfile\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "%matplotlib inline \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def projection_on_set(vector, set_of_vectors):\n",
    "    projection_vector = np.zeros(*vector.shape) \n",
    "    for ort_vector in set_of_vectors:\n",
    "        projection_vector += np.dot(vector, ort_vector) / np.linalg.norm(ort_vector) * ort_vector\n",
    "    return projection_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import AnonymousWalkEmbeddings, AnonymousWalkKernel, func_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'AnonymousWalkEmbeddings' from 'AnonymousWalkEmbeddings.pyc'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(AnonymousWalkEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'AnonymousWalkKernel' from 'AnonymousWalkKernel.pyc'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(AnonymousWalkKernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Детектирование аномалий в потоках графов "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Описание \n",
    "\n",
    "В этом блоке будем сравнивать алгоритмы, которые могут выделять аномальные элементы в потоках графов.\n",
    "Для сравнения будем использовать алгоритмы [ParCube](#parcube), [DeltaCon](#deltacon), [Concept Drift and Anomaly Detection in Graph Streams](#cdadgs) и [наш](#ref) алгоритм\n",
    "\n",
    "Будем проводить эксперименты на датасете [TwitterSecurity2014](http://odds.cs.stonybrook.edu/twittersecurity-dataset/)\n",
    "* количество нод ~ 130 к\n",
    "* количество таймстемпов ~ 120 \n",
    "* 20 аномальных дней \n",
    "\n",
    "Сам датасет состоит из строк вида: user_1 user_2 number_of_co-mentions\n",
    "\n",
    "В качестве метрики для сравнения будем считать precision/recall \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='parcube'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ParCube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='deltacon'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## DeltaCon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='cdadgs'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Concept Drift and Anomaly Detection in Graph Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='ref'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Reference "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Сначала пробмуем поучить модель с такими же параметрами, как на MUTAG из туториала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs: 455\n",
      "Number of words: 877\n",
      "Initialized\n",
      "Epoch: 0\n",
      "Graph 0: 277 nodes\n",
      "Average loss at step 100: 3602.339346\n",
      "Average loss at step 200: 1172.914967\n",
      "Average loss at step 300: 684.647561\n",
      "Average loss at step 400: 468.869386\n",
      "Average loss at step 500: 390.594023\n",
      "Average loss at step 600: 288.138184\n",
      "Average loss at step 700: 243.335294\n",
      "Average loss at step 800: 209.387005\n",
      "Average loss at step 900: 203.216913\n",
      "Average loss at step 1000: 172.829003\n",
      "Time: 50.02439785\n",
      "Graph 1: 274 nodes\n",
      "Average loss at step 1100: 303.022395\n",
      "Average loss at step 1200: 183.730655\n",
      "Average loss at step 1300: 152.609131\n",
      "Average loss at step 1400: 146.667617\n",
      "Average loss at step 1500: 137.455054\n",
      "Average loss at step 1600: 128.028732\n",
      "Average loss at step 1700: 124.808108\n",
      "Average loss at step 1800: 125.368159\n",
      "Average loss at step 1900: 126.241265\n",
      "Average loss at step 2000: 128.161740\n",
      "Graph 2: 278 nodes\n",
      "Average loss at step 2100: 148.836990\n",
      "Average loss at step 2200: 94.702521\n",
      "Average loss at step 2300: 94.679395\n",
      "Average loss at step 2400: 86.731931\n",
      "Average loss at step 2500: 89.699287\n",
      "Average loss at step 2600: 91.027112\n",
      "Average loss at step 2700: 85.838740\n",
      "Average loss at step 2800: 87.942311\n",
      "Average loss at step 2900: 87.485507\n",
      "Average loss at step 3000: 83.900557\n",
      "Graph 3: 293 nodes\n",
      "Average loss at step 3100: 189.238864\n",
      "Average loss at step 3200: 125.675804\n",
      "Average loss at step 3300: 127.822085\n",
      "Average loss at step 3400: 127.245429\n",
      "Average loss at step 3500: 119.736539\n",
      "Average loss at step 3600: 117.796056\n",
      "Average loss at step 3700: 118.372075\n",
      "Average loss at step 3800: 118.980980\n",
      "Average loss at step 3900: 116.938608\n",
      "Average loss at step 4000: 119.371545\n",
      "Graph 4: 262 nodes\n",
      "Average loss at step 4100: 302.742023\n",
      "Average loss at step 4200: 158.249192\n",
      "Average loss at step 4300: 149.580251\n",
      "Average loss at step 4400: 141.207665\n",
      "Average loss at step 4500: 142.701304\n",
      "Average loss at step 4600: 141.482985\n",
      "Average loss at step 4700: 136.145273\n",
      "Average loss at step 4800: 141.095750\n",
      "Average loss at step 4900: 135.222329\n",
      "Average loss at step 5000: 135.822232\n",
      "Graph 5: 31 nodes\n",
      "Average loss at step 5100: 48.029847\n",
      "Average loss at step 5200: 24.556260\n",
      "Average loss at step 5300: 21.444134\n",
      "Average loss at step 5400: 22.182086\n",
      "Average loss at step 5500: 20.794250\n",
      "Average loss at step 5600: 21.581207\n",
      "Average loss at step 5700: 22.626720\n",
      "Average loss at step 5800: 21.152911\n",
      "Average loss at step 5900: 22.152155\n",
      "Average loss at step 6000: 22.041418\n",
      "Graph 6: 32 nodes\n",
      "Average loss at step 6100: 89.628739\n",
      "Average loss at step 6200: 45.168043\n",
      "Average loss at step 6300: 41.885235\n",
      "Average loss at step 6400: 35.807054\n",
      "Average loss at step 6500: 35.592315\n",
      "Average loss at step 6600: 33.239510\n",
      "Average loss at step 6700: 36.310587\n",
      "Average loss at step 6800: 36.580298\n",
      "Average loss at step 6900: 34.633953\n",
      "Average loss at step 7000: 33.993062\n",
      "Graph 7: 264 nodes\n",
      "Average loss at step 7100: 145.476657\n",
      "Average loss at step 7200: 107.701821\n",
      "Average loss at step 7300: 105.051123\n",
      "Average loss at step 7400: 104.013854\n",
      "Average loss at step 7500: 102.692856\n",
      "Average loss at step 7600: 105.505515\n",
      "Average loss at step 7700: 104.355170\n",
      "Average loss at step 7800: 103.369581\n",
      "Average loss at step 7900: 102.181459\n",
      "Average loss at step 8000: 100.597233\n",
      "Graph 8: 229 nodes\n",
      "Average loss at step 8100: 272.676151\n",
      "Average loss at step 8200: 137.301410\n",
      "Average loss at step 8300: 128.007540\n",
      "Average loss at step 8400: 120.522896\n",
      "Average loss at step 8500: 121.524658\n",
      "Average loss at step 8600: 125.846631\n",
      "Average loss at step 8700: 119.084075\n",
      "Average loss at step 8800: 118.001547\n",
      "Average loss at step 8900: 118.519923\n",
      "Average loss at step 9000: 119.732725\n",
      "Graph 9: 230 nodes\n",
      "Average loss at step 9100: 151.655798\n",
      "Average loss at step 9200: 118.686434\n",
      "Average loss at step 9300: 115.416525\n",
      "Average loss at step 9400: 114.984444\n",
      "Average loss at step 9500: 115.526636\n",
      "Average loss at step 9600: 108.040615\n",
      "Average loss at step 9700: 103.864518\n",
      "Average loss at step 9800: 105.075048\n",
      "Average loss at step 9900: 109.210468\n",
      "Average loss at step 10000: 110.091219\n",
      "Graph 10: 306 nodes\n",
      "Average loss at step 10100: 196.382740\n",
      "Average loss at step 10200: 121.175156\n",
      "Average loss at step 10300: 122.047117\n",
      "Average loss at step 10400: 117.200695\n",
      "Average loss at step 10500: 110.159777\n",
      "Average loss at step 10600: 120.104863\n",
      "Average loss at step 10700: 116.626937\n",
      "Average loss at step 10800: 117.236857\n",
      "Average loss at step 10900: 113.007700\n",
      "Average loss at step 11000: 117.810474\n",
      "Time: 53.8494169712\n",
      "Graph 11: 262 nodes\n",
      "Average loss at step 11100: 252.400526\n",
      "Average loss at step 11200: 113.278119\n",
      "Average loss at step 11300: 105.897680\n",
      "Average loss at step 11400: 101.441774\n",
      "Average loss at step 11500: 113.447645\n",
      "Average loss at step 11600: 104.000177\n",
      "Average loss at step 11700: 107.125840\n",
      "Average loss at step 11800: 111.639966\n",
      "Average loss at step 11900: 105.782423\n",
      "Average loss at step 12000: 108.729885\n",
      "Graph 12: 229 nodes\n",
      "Average loss at step 12100: 166.203925\n",
      "Average loss at step 12200: 113.322640\n",
      "Average loss at step 12300: 105.249002\n",
      "Average loss at step 12400: 102.508598\n",
      "Average loss at step 12500: 102.638713\n",
      "Average loss at step 12600: 98.783971\n",
      "Average loss at step 12700: 103.733518\n",
      "Average loss at step 12800: 104.114169\n",
      "Average loss at step 12900: 106.541305\n",
      "Average loss at step 13000: 101.648529\n",
      "Graph 13: 277 nodes\n",
      "Average loss at step 13100: 148.929514\n",
      "Average loss at step 13200: 103.214843\n",
      "Average loss at step 13300: 100.197361\n",
      "Average loss at step 13400: 104.743945\n",
      "Average loss at step 13500: 107.508631\n",
      "Average loss at step 13600: 104.584383\n",
      "Average loss at step 13700: 102.866889\n",
      "Average loss at step 13800: 104.682637\n",
      "Average loss at step 13900: 97.779812\n",
      "Average loss at step 14000: 102.399244\n",
      "Graph 14: 200 nodes\n",
      "Average loss at step 14100: 100.522125\n",
      "Average loss at step 14200: 83.925338\n",
      "Average loss at step 14300: 83.406873\n",
      "Average loss at step 14400: 78.855091\n",
      "Average loss at step 14500: 79.481002\n",
      "Average loss at step 14600: 79.012410\n",
      "Average loss at step 14700: 79.068121\n",
      "Average loss at step 14800: 77.150744\n",
      "Average loss at step 14900: 79.050546\n",
      "Average loss at step 15000: 80.761538\n",
      "Graph 15: 232 nodes\n",
      "Average loss at step 15100: 146.993339\n",
      "Average loss at step 15200: 90.511802\n",
      "Average loss at step 15300: 90.088967\n",
      "Average loss at step 15400: 80.643425\n",
      "Average loss at step 15500: 87.751443\n",
      "Average loss at step 15600: 86.801749\n",
      "Average loss at step 15700: 85.605744\n",
      "Average loss at step 15800: 86.812228\n",
      "Average loss at step 15900: 88.189585\n",
      "Average loss at step 16000: 84.678025\n",
      "Graph 16: 245 nodes\n",
      "Average loss at step 16100: 195.873142\n",
      "Average loss at step 16200: 107.192514\n",
      "Average loss at step 16300: 95.334843\n",
      "Average loss at step 16400: 98.907125\n",
      "Average loss at step 16500: 98.039310\n",
      "Average loss at step 16600: 104.249119\n",
      "Average loss at step 16700: 100.766756\n",
      "Average loss at step 16800: 98.797008\n",
      "Average loss at step 16900: 94.379300\n",
      "Average loss at step 17000: 93.572617\n",
      "Graph 17: 252 nodes\n",
      "Average loss at step 17100: 134.778149\n",
      "Average loss at step 17200: 104.420677\n",
      "Average loss at step 17300: 98.137122\n",
      "Average loss at step 17400: 95.922546\n",
      "Average loss at step 17500: 95.739434\n",
      "Average loss at step 17600: 96.724233\n",
      "Average loss at step 17700: 94.950243\n",
      "Average loss at step 17800: 96.450297\n",
      "Average loss at step 17900: 92.180906\n",
      "Average loss at step 18000: 91.927341\n",
      "Graph 18: 207 nodes\n",
      "Average loss at step 18100: 154.554782\n",
      "Average loss at step 18200: 113.437331\n",
      "Average loss at step 18300: 109.133249\n",
      "Average loss at step 18400: 111.485688\n",
      "Average loss at step 18500: 109.597680\n",
      "Average loss at step 18600: 111.580751\n",
      "Average loss at step 18700: 107.109941\n",
      "Average loss at step 18800: 105.314744\n",
      "Average loss at step 18900: 108.636529\n",
      "Average loss at step 19000: 104.089635\n",
      "Graph 19: 207 nodes\n",
      "Average loss at step 19100: 164.702927\n",
      "Average loss at step 19200: 133.068038\n",
      "Average loss at step 19300: 127.254280\n",
      "Average loss at step 19400: 124.872050\n",
      "Average loss at step 19500: 123.782661\n",
      "Average loss at step 19600: 126.214278\n",
      "Average loss at step 19700: 120.388677\n",
      "Average loss at step 19800: 122.571153\n",
      "Average loss at step 19900: 123.764197\n",
      "Average loss at step 20000: 115.118449\n",
      "Graph 20: 249 nodes\n",
      "Average loss at step 20100: 151.101331\n",
      "Average loss at step 20200: 112.751488\n",
      "Average loss at step 20300: 109.964084\n",
      "Average loss at step 20400: 106.533510\n",
      "Average loss at step 20500: 108.026854\n",
      "Average loss at step 20600: 104.639102\n",
      "Average loss at step 20700: 106.109118\n",
      "Average loss at step 20800: 106.384314\n",
      "Average loss at step 20900: 105.512829\n",
      "Average loss at step 21000: 106.574528\n",
      "Time: 58.7982919216\n",
      "Graph 21: 263 nodes\n",
      "Average loss at step 21100: 155.825913\n",
      "Average loss at step 21200: 112.321398\n",
      "Average loss at step 21300: 109.525517\n",
      "Average loss at step 21400: 106.247533\n",
      "Average loss at step 21500: 103.202425\n",
      "Average loss at step 21600: 96.571240\n",
      "Average loss at step 21700: 100.625217\n",
      "Average loss at step 21800: 104.659180\n",
      "Average loss at step 21900: 106.885947\n",
      "Average loss at step 22000: 107.193667\n",
      "Graph 22: 237 nodes\n",
      "Average loss at step 22100: 117.789050\n",
      "Average loss at step 22200: 81.772634\n",
      "Average loss at step 22300: 84.783606\n",
      "Average loss at step 22400: 82.910964\n",
      "Average loss at step 22500: 85.603355\n",
      "Average loss at step 22600: 82.372093\n",
      "Average loss at step 22700: 84.311994\n",
      "Average loss at step 22800: 85.161704\n",
      "Average loss at step 22900: 82.172605\n",
      "Average loss at step 23000: 78.899072\n",
      "Graph 23: 248 nodes\n",
      "Average loss at step 23100: 142.632085\n",
      "Average loss at step 23200: 92.090321\n",
      "Average loss at step 23300: 91.825084\n",
      "Average loss at step 23400: 90.431265\n",
      "Average loss at step 23500: 92.343703\n",
      "Average loss at step 23600: 89.886710\n",
      "Average loss at step 23700: 88.229729\n",
      "Average loss at step 23800: 93.294775\n",
      "Average loss at step 23900: 84.333969\n",
      "Average loss at step 24000: 90.020649\n",
      "Graph 24: 250 nodes\n",
      "Average loss at step 24100: 132.580628\n",
      "Average loss at step 24200: 110.603361\n",
      "Average loss at step 24300: 115.658291\n",
      "Average loss at step 24400: 113.700298\n",
      "Average loss at step 24500: 110.958484\n",
      "Average loss at step 24600: 107.768050\n",
      "Average loss at step 24700: 106.793067\n",
      "Average loss at step 24800: 106.633006\n",
      "Average loss at step 24900: 106.719661\n",
      "Average loss at step 25000: 108.865909\n",
      "Graph 25: 333 nodes\n",
      "Average loss at step 25100: 175.616388\n",
      "Average loss at step 25200: 98.386162\n",
      "Average loss at step 25300: 97.290518\n",
      "Average loss at step 25400: 98.834475\n",
      "Average loss at step 25500: 96.296487\n",
      "Average loss at step 25600: 96.987637\n",
      "Average loss at step 25700: 94.710477\n",
      "Average loss at step 25800: 101.861846\n",
      "Average loss at step 25900: 96.994736\n",
      "Average loss at step 26000: 95.212706\n",
      "Graph 26: 266 nodes\n",
      "Average loss at step 26100: 117.836259\n",
      "Average loss at step 26200: 90.892529\n",
      "Average loss at step 26300: 93.593006\n",
      "Average loss at step 26400: 90.978108\n",
      "Average loss at step 26500: 93.977195\n",
      "Average loss at step 26600: 94.871809\n",
      "Average loss at step 26700: 90.610584\n",
      "Average loss at step 26800: 91.825233\n",
      "Average loss at step 26900: 94.537263\n",
      "Average loss at step 27000: 88.929927\n",
      "Graph 27: 241 nodes\n",
      "Average loss at step 27100: 102.522598\n",
      "Average loss at step 27200: 86.679443\n",
      "Average loss at step 27300: 84.435519\n",
      "Average loss at step 27400: 86.260415\n",
      "Average loss at step 27500: 85.051103\n",
      "Average loss at step 27600: 89.413382\n",
      "Average loss at step 27700: 85.862260\n",
      "Average loss at step 27800: 89.571598\n",
      "Average loss at step 27900: 81.229162\n",
      "Average loss at step 28000: 82.841524\n",
      "Graph 28: 235 nodes\n",
      "Average loss at step 28100: 163.109236\n",
      "Average loss at step 28200: 112.524484\n",
      "Average loss at step 28300: 110.138320\n",
      "Average loss at step 28400: 107.408264\n",
      "Average loss at step 28500: 113.337463\n",
      "Average loss at step 28600: 106.393899\n",
      "Average loss at step 28700: 112.268896\n",
      "Average loss at step 28800: 104.411787\n",
      "Average loss at step 28900: 108.552180\n",
      "Average loss at step 29000: 111.427787\n",
      "Graph 29: 244 nodes\n",
      "Average loss at step 29100: 157.510542\n",
      "Average loss at step 29200: 116.334042\n",
      "Average loss at step 29300: 111.900220\n",
      "Average loss at step 29400: 118.253534\n",
      "Average loss at step 29500: 110.269254\n",
      "Average loss at step 29600: 116.429933\n",
      "Average loss at step 29700: 114.482754\n",
      "Average loss at step 29800: 111.572708\n",
      "Average loss at step 29900: 113.975505\n",
      "Average loss at step 30000: 112.609603\n",
      "Graph 30: 257 nodes\n",
      "Average loss at step 30100: 191.311694\n",
      "Average loss at step 30200: 116.675244\n",
      "Average loss at step 30300: 112.614322\n",
      "Average loss at step 30400: 114.868846\n",
      "Average loss at step 30500: 114.196158\n",
      "Average loss at step 30600: 109.188569\n",
      "Average loss at step 30700: 111.953245\n",
      "Average loss at step 30800: 110.605038\n",
      "Average loss at step 30900: 112.672627\n",
      "Average loss at step 31000: 113.375756\n",
      "Time: 58.1204960346\n",
      "Graph 31: 242 nodes\n",
      "Average loss at step 31100: 132.145909\n",
      "Average loss at step 31200: 104.781196\n",
      "Average loss at step 31300: 106.182603\n",
      "Average loss at step 31400: 104.743275\n",
      "Average loss at step 31500: 106.571621\n",
      "Average loss at step 31600: 103.904169\n",
      "Average loss at step 31700: 103.123044\n",
      "Average loss at step 31800: 102.008216\n",
      "Average loss at step 31900: 105.803184\n",
      "Average loss at step 32000: 105.221012\n",
      "Graph 32: 260 nodes\n",
      "Average loss at step 32100: 189.104446\n",
      "Average loss at step 32200: 116.246149\n",
      "Average loss at step 32300: 115.768194\n",
      "Average loss at step 32400: 114.381300\n",
      "Average loss at step 32500: 113.896008\n",
      "Average loss at step 32600: 110.675919\n",
      "Average loss at step 32700: 112.551880\n",
      "Average loss at step 32800: 108.649028\n",
      "Average loss at step 32900: 113.475842\n",
      "Average loss at step 33000: 110.299108\n",
      "Graph 33: 236 nodes\n",
      "Average loss at step 33100: 129.598631\n",
      "Average loss at step 33200: 98.055394\n",
      "Average loss at step 33300: 98.059013\n",
      "Average loss at step 33400: 97.669532\n",
      "Average loss at step 33500: 99.000234\n",
      "Average loss at step 33600: 95.685223\n",
      "Average loss at step 33700: 94.561444\n",
      "Average loss at step 33800: 99.108080\n",
      "Average loss at step 33900: 95.167969\n",
      "Average loss at step 34000: 94.501326\n",
      "Graph 34: 263 nodes\n",
      "Average loss at step 34100: 124.255045\n",
      "Average loss at step 34200: 87.445220\n",
      "Average loss at step 34300: 87.323961\n",
      "Average loss at step 34400: 90.882956\n",
      "Average loss at step 34500: 88.412652\n",
      "Average loss at step 34600: 82.569076\n",
      "Average loss at step 34700: 83.427119\n",
      "Average loss at step 34800: 90.837161\n",
      "Average loss at step 34900: 85.119485\n",
      "Average loss at step 35000: 85.548620\n",
      "Graph 35: 236 nodes\n",
      "Average loss at step 35100: 123.748395\n",
      "Average loss at step 35200: 101.836368\n",
      "Average loss at step 35300: 99.539650\n",
      "Average loss at step 35400: 102.646544\n",
      "Average loss at step 35500: 97.799374\n",
      "Average loss at step 35600: 102.389480\n",
      "Average loss at step 35700: 93.385554\n",
      "Average loss at step 35800: 98.163561\n",
      "Average loss at step 35900: 95.928573\n",
      "Average loss at step 36000: 98.799503\n",
      "Graph 36: 266 nodes\n",
      "Average loss at step 36100: 125.650825\n",
      "Average loss at step 36200: 108.645553\n",
      "Average loss at step 36300: 104.547368\n",
      "Average loss at step 36400: 101.354550\n",
      "Average loss at step 36500: 103.032310\n",
      "Average loss at step 36600: 102.925221\n",
      "Average loss at step 36700: 101.158027\n",
      "Average loss at step 36800: 102.356748\n",
      "Average loss at step 36900: 101.636703\n",
      "Average loss at step 37000: 102.677658\n",
      "Graph 37: 295 nodes\n",
      "Average loss at step 37100: 156.702994\n",
      "Average loss at step 37200: 113.538344\n",
      "Average loss at step 37300: 114.374918\n",
      "Average loss at step 37400: 109.462855\n",
      "Average loss at step 37500: 110.243671\n",
      "Average loss at step 37600: 107.868239\n",
      "Average loss at step 37700: 111.009893\n",
      "Average loss at step 37800: 111.552574\n",
      "Average loss at step 37900: 114.366703\n",
      "Average loss at step 38000: 110.520856\n",
      "Graph 38: 270 nodes\n",
      "Average loss at step 38100: 180.085557\n",
      "Average loss at step 38200: 142.465795\n",
      "Average loss at step 38300: 139.403444\n",
      "Average loss at step 38400: 132.666749\n",
      "Average loss at step 38500: 136.299346\n",
      "Average loss at step 38600: 137.320855\n",
      "Average loss at step 38700: 136.732830\n",
      "Average loss at step 38800: 133.745229\n",
      "Average loss at step 38900: 132.605003\n",
      "Average loss at step 39000: 126.541746\n",
      "Graph 39: 249 nodes\n",
      "Average loss at step 39100: 113.456822\n",
      "Average loss at step 39200: 92.501471\n",
      "Average loss at step 39300: 93.681201\n",
      "Average loss at step 39400: 89.587324\n",
      "Average loss at step 39500: 92.373833\n",
      "Average loss at step 39600: 89.866943\n",
      "Average loss at step 39700: 88.785928\n",
      "Average loss at step 39800: 90.947179\n",
      "Average loss at step 39900: 93.938593\n",
      "Average loss at step 40000: 83.763248\n",
      "Graph 40: 308 nodes\n",
      "Average loss at step 40100: 133.326851\n",
      "Average loss at step 40200: 105.777773\n",
      "Average loss at step 40300: 107.799013\n",
      "Average loss at step 40400: 109.154630\n",
      "Average loss at step 40500: 105.153273\n",
      "Average loss at step 40600: 107.270224\n",
      "Average loss at step 40700: 107.393782\n",
      "Average loss at step 40800: 106.279391\n",
      "Average loss at step 40900: 105.910329\n",
      "Average loss at step 41000: 105.611691\n",
      "Time: 52.2497041225\n",
      "Graph 41: 300 nodes\n",
      "Average loss at step 41100: 122.801251\n",
      "Average loss at step 41200: 98.517550\n",
      "Average loss at step 41300: 94.918563\n",
      "Average loss at step 41400: 100.127278\n",
      "Average loss at step 41500: 100.883674\n",
      "Average loss at step 41600: 96.702625\n",
      "Average loss at step 41700: 99.215073\n",
      "Average loss at step 41800: 93.222767\n",
      "Average loss at step 41900: 97.229976\n",
      "Average loss at step 42000: 95.333244\n",
      "Graph 42: 340 nodes\n",
      "Average loss at step 42100: 95.670868\n",
      "Average loss at step 42200: 85.603981\n",
      "Average loss at step 42300: 83.281740\n",
      "Average loss at step 42400: 85.552202\n",
      "Average loss at step 42500: 86.334875\n",
      "Average loss at step 42600: 79.879151\n",
      "Average loss at step 42700: 80.002429\n",
      "Average loss at step 42800: 86.353037\n",
      "Average loss at step 42900: 81.917715\n",
      "Average loss at step 43000: 84.372664\n",
      "Graph 43: 303 nodes\n",
      "Average loss at step 43100: 125.724729\n",
      "Average loss at step 43200: 87.541384\n",
      "Average loss at step 43300: 86.471391\n",
      "Average loss at step 43400: 86.316441\n",
      "Average loss at step 43500: 89.537751\n",
      "Average loss at step 43600: 84.801868\n",
      "Average loss at step 43700: 87.083368\n",
      "Average loss at step 43800: 85.199431\n",
      "Average loss at step 43900: 88.008312\n",
      "Average loss at step 44000: 86.136858\n",
      "Graph 44: 316 nodes\n",
      "Average loss at step 44100: 106.368184\n",
      "Average loss at step 44200: 89.588781\n",
      "Average loss at step 44300: 82.213590\n",
      "Average loss at step 44400: 92.481797\n",
      "Average loss at step 44500: 84.257748\n",
      "Average loss at step 44600: 85.731394\n",
      "Average loss at step 44700: 85.664738\n",
      "Average loss at step 44800: 84.500411\n",
      "Average loss at step 44900: 90.103222\n",
      "Average loss at step 45000: 85.875654\n",
      "Graph 45: 381 nodes\n",
      "Average loss at step 45100: 124.624791\n",
      "Average loss at step 45200: 114.189516\n",
      "Average loss at step 45300: 110.849589\n",
      "Average loss at step 45400: 116.822113\n",
      "Average loss at step 45500: 108.001721\n",
      "Average loss at step 45600: 105.609808\n",
      "Average loss at step 45700: 110.669778\n",
      "Average loss at step 45800: 110.024851\n",
      "Average loss at step 45900: 108.291531\n",
      "Average loss at step 46000: 107.069337\n",
      "Graph 46: 367 nodes\n",
      "Average loss at step 46100: 134.299522\n",
      "Average loss at step 46200: 106.185976\n",
      "Average loss at step 46300: 108.084340\n",
      "Average loss at step 46400: 104.712301\n",
      "Average loss at step 46500: 103.521400\n",
      "Average loss at step 46600: 104.055707\n",
      "Average loss at step 46700: 105.276489\n",
      "Average loss at step 46800: 105.765491\n",
      "Average loss at step 46900: 110.116949\n",
      "Average loss at step 47000: 105.183783\n",
      "Graph 47: 352 nodes\n",
      "Average loss at step 47100: 129.950177\n",
      "Average loss at step 47200: 105.465118\n",
      "Average loss at step 47300: 101.541745\n",
      "Average loss at step 47400: 102.752593\n",
      "Average loss at step 47500: 100.428774\n",
      "Average loss at step 47600: 101.468763\n",
      "Average loss at step 47700: 103.216097\n",
      "Average loss at step 47800: 103.728442\n",
      "Average loss at step 47900: 105.882824\n",
      "Average loss at step 48000: 102.567160\n",
      "Graph 48: 321 nodes\n",
      "Average loss at step 48100: 117.579217\n",
      "Average loss at step 48200: 99.994317\n",
      "Average loss at step 48300: 100.686914\n",
      "Average loss at step 48400: 101.458551\n",
      "Average loss at step 48500: 100.916518\n",
      "Average loss at step 48600: 99.873608\n",
      "Average loss at step 48700: 100.359863\n",
      "Average loss at step 48800: 99.667816\n",
      "Average loss at step 48900: 95.762811\n",
      "Average loss at step 49000: 104.451413\n",
      "Graph 49: 290 nodes\n",
      "Average loss at step 49100: 138.626809\n",
      "Average loss at step 49200: 110.947068\n",
      "Average loss at step 49300: 113.963538\n",
      "Average loss at step 49400: 110.721534\n",
      "Average loss at step 49500: 109.864553\n",
      "Average loss at step 49600: 112.848744\n",
      "Average loss at step 49700: 111.818998\n",
      "Average loss at step 49800: 109.150806\n",
      "Average loss at step 49900: 110.538382\n",
      "Average loss at step 50000: 108.992057\n",
      "Graph 50: 44 nodes\n",
      "Average loss at step 50100: 33.793588\n",
      "Average loss at step 50200: 29.218880\n",
      "Average loss at step 50300: 29.458449\n",
      "Average loss at step 50400: 30.599021\n",
      "Average loss at step 50500: 28.943164\n",
      "Average loss at step 50600: 29.695111\n",
      "Average loss at step 50700: 28.988842\n",
      "Average loss at step 50800: 29.392113\n",
      "Average loss at step 50900: 28.365057\n",
      "Average loss at step 51000: 27.714178\n",
      "Time: 42.2142999172\n",
      "Graph 51: 302 nodes\n",
      "Average loss at step 51100: 170.649704\n",
      "Average loss at step 51200: 112.741945\n",
      "Average loss at step 51300: 108.122437\n",
      "Average loss at step 51400: 111.551860\n",
      "Average loss at step 51500: 109.458665\n",
      "Average loss at step 51600: 114.629754\n",
      "Average loss at step 51700: 110.241241\n",
      "Average loss at step 51800: 108.604872\n",
      "Average loss at step 51900: 105.489109\n",
      "Average loss at step 52000: 112.528185\n",
      "Graph 52: 340 nodes\n",
      "Average loss at step 52100: 165.816658\n",
      "Average loss at step 52200: 127.329741\n",
      "Average loss at step 52300: 131.912085\n",
      "Average loss at step 52400: 131.062562\n",
      "Average loss at step 52500: 126.248708\n",
      "Average loss at step 52600: 128.291744\n",
      "Average loss at step 52700: 128.606603\n",
      "Average loss at step 52800: 130.349694\n",
      "Average loss at step 52900: 127.638376\n",
      "Average loss at step 53000: 129.943872\n",
      "Graph 53: 336 nodes\n",
      "Average loss at step 53100: 143.956935\n",
      "Average loss at step 53200: 115.703800\n",
      "Average loss at step 53300: 115.254787\n",
      "Average loss at step 53400: 117.638749\n",
      "Average loss at step 53500: 110.676445\n",
      "Average loss at step 53600: 114.338606\n",
      "Average loss at step 53700: 108.190139\n",
      "Average loss at step 53800: 115.900706\n",
      "Average loss at step 53900: 114.605760\n",
      "Average loss at step 54000: 116.391472\n",
      "Graph 54: 330 nodes\n",
      "Average loss at step 54100: 123.738686\n",
      "Average loss at step 54200: 107.906083\n",
      "Average loss at step 54300: 108.810130\n",
      "Average loss at step 54400: 107.753198\n",
      "Average loss at step 54500: 107.263129\n",
      "Average loss at step 54600: 108.451118\n",
      "Average loss at step 54700: 108.351375\n",
      "Average loss at step 54800: 104.692779\n",
      "Average loss at step 54900: 105.338301\n",
      "Average loss at step 55000: 106.906168\n",
      "Graph 55: 351 nodes\n",
      "Average loss at step 55100: 130.550787\n",
      "Average loss at step 55200: 109.321045\n",
      "Average loss at step 55300: 107.188812\n",
      "Average loss at step 55400: 110.457123\n",
      "Average loss at step 55500: 105.377685\n",
      "Average loss at step 55600: 107.236268\n",
      "Average loss at step 55700: 103.697606\n",
      "Average loss at step 55800: 108.842182\n",
      "Average loss at step 55900: 105.664053\n",
      "Average loss at step 56000: 109.192144\n",
      "Graph 56: 304 nodes\n",
      "Average loss at step 56100: 145.443435\n",
      "Average loss at step 56200: 108.106375\n",
      "Average loss at step 56300: 105.197732\n",
      "Average loss at step 56400: 105.166421\n",
      "Average loss at step 56500: 106.976789\n",
      "Average loss at step 56600: 102.173040\n",
      "Average loss at step 56700: 102.796125\n",
      "Average loss at step 56800: 106.050151\n",
      "Average loss at step 56900: 104.393943\n",
      "Average loss at step 57000: 105.109831\n",
      "Graph 57: 318 nodes\n",
      "Average loss at step 57100: 106.927169\n",
      "Average loss at step 57200: 103.469777\n",
      "Average loss at step 57300: 102.872171\n",
      "Average loss at step 57400: 99.353207\n",
      "Average loss at step 57500: 105.173802\n",
      "Average loss at step 57600: 94.971412\n",
      "Average loss at step 57700: 102.421542\n",
      "Average loss at step 57800: 103.213556\n",
      "Average loss at step 57900: 101.465400\n",
      "Average loss at step 58000: 99.315540\n",
      "Graph 58: 315 nodes\n",
      "Average loss at step 58100: 164.875046\n",
      "Average loss at step 58200: 100.879447\n",
      "Average loss at step 58300: 105.198912\n",
      "Average loss at step 58400: 100.448427\n",
      "Average loss at step 58500: 104.194036\n",
      "Average loss at step 58600: 105.784841\n",
      "Average loss at step 58700: 100.392589\n",
      "Average loss at step 58800: 98.943908\n",
      "Average loss at step 58900: 99.909781\n",
      "Average loss at step 59000: 98.538509\n",
      "Graph 59: 304 nodes\n",
      "Average loss at step 59100: 100.428413\n",
      "Average loss at step 59200: 91.265644\n",
      "Average loss at step 59300: 88.389579\n",
      "Average loss at step 59400: 88.417444\n",
      "Average loss at step 59500: 89.328452\n",
      "Average loss at step 59600: 88.355082\n",
      "Average loss at step 59700: 86.967889\n",
      "Average loss at step 59800: 85.849595\n",
      "Average loss at step 59900: 87.015545\n",
      "Average loss at step 60000: 89.428887\n",
      "Graph 60: 339 nodes\n",
      "Average loss at step 60100: 126.099350\n",
      "Average loss at step 60200: 104.369657\n",
      "Average loss at step 60300: 102.077768\n",
      "Average loss at step 60400: 99.908931\n",
      "Average loss at step 60500: 99.788772\n",
      "Average loss at step 60600: 103.251067\n",
      "Average loss at step 60700: 100.169804\n",
      "Average loss at step 60800: 101.814850\n",
      "Average loss at step 60900: 100.200565\n",
      "Average loss at step 61000: 103.280344\n",
      "Time: 216.878726006\n",
      "Graph 61: 329 nodes\n",
      "Average loss at step 61100: 119.376397\n",
      "Average loss at step 61200: 108.789513\n",
      "Average loss at step 61300: 108.374169\n",
      "Average loss at step 61400: 104.513494\n",
      "Average loss at step 61500: 104.326950\n",
      "Average loss at step 61600: 102.024101\n",
      "Average loss at step 61700: 106.122761\n",
      "Average loss at step 61800: 107.832628\n",
      "Average loss at step 61900: 101.784377\n",
      "Average loss at step 62000: 102.899654\n",
      "Graph 62: 357 nodes\n",
      "Average loss at step 62100: 147.869091\n",
      "Average loss at step 62200: 128.925845\n",
      "Average loss at step 62300: 128.260593\n",
      "Average loss at step 62400: 126.900770\n",
      "Average loss at step 62500: 127.600291\n",
      "Average loss at step 62600: 126.375491\n",
      "Average loss at step 62700: 128.836847\n",
      "Average loss at step 62800: 122.449829\n",
      "Average loss at step 62900: 125.776927\n",
      "Average loss at step 63000: 128.354716\n",
      "Graph 63: 349 nodes\n",
      "Average loss at step 63100: 94.720457\n",
      "Average loss at step 63200: 78.517874\n",
      "Average loss at step 63300: 73.791991\n",
      "Average loss at step 63400: 75.796476\n",
      "Average loss at step 63500: 73.299831\n",
      "Average loss at step 63600: 75.479053\n",
      "Average loss at step 63700: 74.263443\n",
      "Average loss at step 63800: 77.454296\n",
      "Average loss at step 63900: 76.201426\n",
      "Average loss at step 64000: 72.958535\n",
      "Graph 64: 315 nodes\n",
      "Average loss at step 64100: 109.625186\n",
      "Average loss at step 64200: 79.538591\n",
      "Average loss at step 64300: 79.637678\n",
      "Average loss at step 64400: 77.462043\n",
      "Average loss at step 64500: 78.040956\n",
      "Average loss at step 64600: 76.657867\n",
      "Average loss at step 64700: 80.749651\n",
      "Average loss at step 64800: 76.988189\n",
      "Average loss at step 64900: 78.947902\n",
      "Average loss at step 65000: 74.853146\n",
      "Graph 65: 364 nodes\n",
      "Average loss at step 65100: 159.874219\n",
      "Average loss at step 65200: 129.950271\n",
      "Average loss at step 65300: 132.603323\n",
      "Average loss at step 65400: 126.994063\n",
      "Average loss at step 65500: 125.648613\n",
      "Average loss at step 65600: 127.685921\n",
      "Average loss at step 65700: 127.007109\n",
      "Average loss at step 65800: 126.986443\n",
      "Average loss at step 65900: 125.414992\n",
      "Average loss at step 66000: 120.811997\n",
      "Graph 66: 367 nodes\n",
      "Average loss at step 66100: 155.431572\n",
      "Average loss at step 66200: 131.867000\n",
      "Average loss at step 66300: 132.043844\n",
      "Average loss at step 66400: 126.979585\n",
      "Average loss at step 66500: 126.300241\n",
      "Average loss at step 66600: 133.522378\n",
      "Average loss at step 66700: 128.437939\n",
      "Average loss at step 66800: 133.323719\n",
      "Average loss at step 66900: 129.688606\n",
      "Average loss at step 67000: 131.382838\n",
      "Graph 67: 391 nodes\n",
      "Average loss at step 67100: 125.560212\n",
      "Average loss at step 67200: 107.960965\n",
      "Average loss at step 67300: 110.742818\n",
      "Average loss at step 67400: 109.679465\n",
      "Average loss at step 67500: 107.038734\n",
      "Average loss at step 67600: 105.927257\n",
      "Average loss at step 67700: 107.201596\n",
      "Average loss at step 67800: 106.378702\n",
      "Average loss at step 67900: 108.162744\n",
      "Average loss at step 68000: 106.233028\n",
      "Graph 68: 323 nodes\n",
      "Average loss at step 68100: 127.810169\n",
      "Average loss at step 68200: 112.424673\n",
      "Average loss at step 68300: 110.084404\n",
      "Average loss at step 68400: 110.589323\n",
      "Average loss at step 68500: 109.205027\n",
      "Average loss at step 68600: 114.956443\n",
      "Average loss at step 68700: 115.271946\n",
      "Average loss at step 68800: 110.412885\n",
      "Average loss at step 68900: 107.112616\n",
      "Average loss at step 69000: 107.439251\n",
      "Graph 69: 305 nodes\n",
      "Average loss at step 69100: 113.417168\n",
      "Average loss at step 69200: 78.673698\n",
      "Average loss at step 69300: 81.931370\n",
      "Average loss at step 69400: 85.623899\n",
      "Average loss at step 69500: 77.088329\n",
      "Average loss at step 69600: 81.144413\n",
      "Average loss at step 69700: 83.953265\n",
      "Average loss at step 69800: 83.346920\n",
      "Average loss at step 69900: 82.299846\n",
      "Average loss at step 70000: 76.669655\n",
      "Graph 70: 377 nodes\n",
      "Average loss at step 70100: 133.334292\n",
      "Average loss at step 70200: 100.758855\n",
      "Average loss at step 70300: 91.796739\n",
      "Average loss at step 70400: 97.068864\n",
      "Average loss at step 70500: 97.647475\n",
      "Average loss at step 70600: 98.636729\n",
      "Average loss at step 70700: 101.303649\n",
      "Average loss at step 70800: 98.413112\n",
      "Average loss at step 70900: 95.732721\n",
      "Average loss at step 71000: 99.772291\n",
      "Time: 60.8672158718\n",
      "Graph 71: 355 nodes\n",
      "Average loss at step 71100: 120.888339\n",
      "Average loss at step 71200: 97.953700\n",
      "Average loss at step 71300: 91.822464\n",
      "Average loss at step 71400: 93.150129\n",
      "Average loss at step 71500: 93.434943\n",
      "Average loss at step 71600: 91.511728\n",
      "Average loss at step 71700: 94.819681\n",
      "Average loss at step 71800: 91.216301\n",
      "Average loss at step 71900: 93.941266\n",
      "Average loss at step 72000: 89.059794\n",
      "Graph 72: 328 nodes\n",
      "Average loss at step 72100: 115.648231\n",
      "Average loss at step 72200: 94.958158\n",
      "Average loss at step 72300: 91.833225\n",
      "Average loss at step 72400: 91.111316\n",
      "Average loss at step 72500: 88.523496\n",
      "Average loss at step 72600: 90.687583\n",
      "Average loss at step 72700: 90.870287\n",
      "Average loss at step 72800: 86.835393\n",
      "Average loss at step 72900: 92.409613\n",
      "Average loss at step 73000: 92.720440\n",
      "Graph 73: 308 nodes\n",
      "Average loss at step 73100: 113.227333\n",
      "Average loss at step 73200: 82.696846\n",
      "Average loss at step 73300: 86.131516\n",
      "Average loss at step 73400: 78.929645\n",
      "Average loss at step 73500: 83.741211\n",
      "Average loss at step 73600: 86.536694\n",
      "Average loss at step 73700: 84.205012\n",
      "Average loss at step 73800: 84.676772\n",
      "Average loss at step 73900: 82.906848\n",
      "Average loss at step 74000: 83.534090\n",
      "Graph 74: 290 nodes\n",
      "Average loss at step 74100: 97.086192\n",
      "Average loss at step 74200: 83.737877\n",
      "Average loss at step 74300: 80.278052\n",
      "Average loss at step 74400: 77.326299\n",
      "Average loss at step 74500: 78.906227\n",
      "Average loss at step 74600: 80.648625\n",
      "Average loss at step 74700: 78.874566\n",
      "Average loss at step 74800: 79.805775\n",
      "Average loss at step 74900: 83.401192\n",
      "Average loss at step 75000: 77.642536\n",
      "Graph 75: 356 nodes\n",
      "Average loss at step 75100: 111.816603\n",
      "Average loss at step 75200: 91.721585\n",
      "Average loss at step 75300: 87.467434\n",
      "Average loss at step 75400: 84.848782\n",
      "Average loss at step 75500: 86.139923\n",
      "Average loss at step 75600: 88.821281\n",
      "Average loss at step 75700: 85.216358\n",
      "Average loss at step 75800: 88.149669\n",
      "Average loss at step 75900: 83.134383\n",
      "Average loss at step 76000: 80.050739\n",
      "Graph 76: 380 nodes\n",
      "Average loss at step 76100: 117.443897\n",
      "Average loss at step 76200: 108.997375\n",
      "Average loss at step 76300: 108.542371\n",
      "Average loss at step 76400: 108.917739\n",
      "Average loss at step 76500: 106.110017\n",
      "Average loss at step 76600: 112.113268\n",
      "Average loss at step 76700: 109.807863\n",
      "Average loss at step 76800: 106.135709\n",
      "Average loss at step 76900: 106.795477\n",
      "Average loss at step 77000: 108.315738\n",
      "Graph 77: 386 nodes\n",
      "Average loss at step 77100: 127.378363\n",
      "Average loss at step 77200: 97.429627\n",
      "Average loss at step 77300: 96.152278\n",
      "Average loss at step 77400: 94.121912\n",
      "Average loss at step 77500: 99.896437\n",
      "Average loss at step 77600: 97.576130\n",
      "Average loss at step 77700: 94.981422\n",
      "Average loss at step 77800: 92.265800\n",
      "Average loss at step 77900: 93.510547\n",
      "Average loss at step 78000: 94.181541\n",
      "Graph 78: 397 nodes\n",
      "Average loss at step 78100: 124.219480\n",
      "Average loss at step 78200: 97.404657\n",
      "Average loss at step 78300: 99.126839\n",
      "Average loss at step 78400: 100.221770\n",
      "Average loss at step 78500: 100.835985\n",
      "Average loss at step 78600: 99.235048\n",
      "Average loss at step 78700: 102.584018\n",
      "Average loss at step 78800: 99.402775\n",
      "Average loss at step 78900: 94.466844\n",
      "Average loss at step 79000: 97.314342\n",
      "Graph 79: 341 nodes\n",
      "Average loss at step 79100: 144.174022\n",
      "Average loss at step 79200: 108.231395\n",
      "Average loss at step 79300: 109.164297\n",
      "Average loss at step 79400: 105.830760\n",
      "Average loss at step 79500: 106.039649\n",
      "Average loss at step 79600: 103.999729\n",
      "Average loss at step 79700: 100.409675\n",
      "Average loss at step 79800: 103.301006\n",
      "Average loss at step 79900: 102.350939\n",
      "Average loss at step 80000: 104.290994\n",
      "Graph 80: 343 nodes\n",
      "Average loss at step 80100: 112.709057\n",
      "Average loss at step 80200: 106.246135\n",
      "Average loss at step 80300: 108.222690\n",
      "Average loss at step 80400: 100.104778\n",
      "Average loss at step 80500: 105.731945\n",
      "Average loss at step 80600: 104.015414\n",
      "Average loss at step 80700: 98.996877\n",
      "Average loss at step 80800: 103.896936\n",
      "Average loss at step 80900: 104.777984\n",
      "Average loss at step 81000: 105.312593\n",
      "Time: 63.0802130699\n",
      "Graph 81: 410 nodes\n",
      "Average loss at step 81100: 130.597926\n",
      "Average loss at step 81200: 108.049638\n",
      "Average loss at step 81300: 106.134191\n",
      "Average loss at step 81400: 108.416995\n",
      "Average loss at step 81500: 106.035244\n",
      "Average loss at step 81600: 108.872652\n",
      "Average loss at step 81700: 106.573255\n",
      "Average loss at step 81800: 105.112419\n",
      "Average loss at step 81900: 108.370122\n",
      "Average loss at step 82000: 110.201340\n",
      "Graph 82: 351 nodes\n",
      "Average loss at step 82100: 126.398238\n",
      "Average loss at step 82200: 108.503797\n",
      "Average loss at step 82300: 106.612952\n",
      "Average loss at step 82400: 104.509925\n",
      "Average loss at step 82500: 105.655139\n",
      "Average loss at step 82600: 109.151659\n",
      "Average loss at step 82700: 105.678813\n",
      "Average loss at step 82800: 101.380649\n",
      "Average loss at step 82900: 105.951184\n",
      "Average loss at step 83000: 106.107949\n",
      "Graph 83: 334 nodes\n",
      "Average loss at step 83100: 121.727586\n",
      "Average loss at step 83200: 94.865491\n",
      "Average loss at step 83300: 96.701320\n",
      "Average loss at step 83400: 90.722188\n",
      "Average loss at step 83500: 90.720380\n",
      "Average loss at step 83600: 92.158713\n",
      "Average loss at step 83700: 91.399842\n",
      "Average loss at step 83800: 96.396646\n",
      "Average loss at step 83900: 92.394430\n",
      "Average loss at step 84000: 90.698936\n",
      "Graph 84: 335 nodes\n",
      "Average loss at step 84100: 116.752884\n",
      "Average loss at step 84200: 96.066663\n",
      "Average loss at step 84300: 92.694558\n",
      "Average loss at step 84400: 95.118668\n",
      "Average loss at step 84500: 93.595935\n",
      "Average loss at step 84600: 94.512406\n",
      "Average loss at step 84700: 94.802691\n",
      "Average loss at step 84800: 96.927296\n",
      "Average loss at step 84900: 97.997101\n",
      "Average loss at step 85000: 93.679952\n",
      "Graph 85: 392 nodes\n",
      "Average loss at step 85100: 97.789802\n",
      "Average loss at step 85200: 87.546754\n",
      "Average loss at step 85300: 88.562260\n",
      "Average loss at step 85400: 87.272333\n",
      "Average loss at step 85500: 88.730463\n",
      "Average loss at step 85600: 89.503125\n",
      "Average loss at step 85700: 90.737403\n",
      "Average loss at step 85800: 91.949833\n",
      "Average loss at step 85900: 83.272824\n",
      "Average loss at step 86000: 88.385633\n",
      "Graph 86: 440 nodes\n",
      "Average loss at step 86100: 151.936496\n",
      "Average loss at step 86200: 120.199378\n",
      "Average loss at step 86300: 116.502703\n",
      "Average loss at step 86400: 112.096491\n",
      "Average loss at step 86500: 117.771181\n",
      "Average loss at step 86600: 113.720327\n",
      "Average loss at step 86700: 114.256792\n",
      "Average loss at step 86800: 114.911748\n",
      "Average loss at step 86900: 116.115403\n",
      "Average loss at step 87000: 113.033018\n",
      "Graph 87: 439 nodes\n",
      "Average loss at step 87100: 120.868041\n",
      "Average loss at step 87200: 110.080579\n",
      "Average loss at step 87300: 103.579648\n",
      "Average loss at step 87400: 105.992292\n",
      "Average loss at step 87500: 107.282451\n",
      "Average loss at step 87600: 107.258249\n",
      "Average loss at step 87700: 100.660863\n",
      "Average loss at step 87800: 105.846418\n",
      "Average loss at step 87900: 109.151934\n",
      "Average loss at step 88000: 107.654041\n",
      "Graph 88: 396 nodes\n",
      "Average loss at step 88100: 128.308447\n",
      "Average loss at step 88200: 113.971718\n",
      "Average loss at step 88300: 110.733114\n",
      "Average loss at step 88400: 112.991480\n",
      "Average loss at step 88500: 109.836182\n",
      "Average loss at step 88600: 110.452957\n",
      "Average loss at step 88700: 109.580873\n",
      "Average loss at step 88800: 111.922179\n",
      "Average loss at step 88900: 110.871815\n",
      "Average loss at step 89000: 112.727232\n",
      "Graph 89: 423 nodes\n",
      "Average loss at step 89100: 147.126135\n",
      "Average loss at step 89200: 100.802219\n",
      "Average loss at step 89300: 96.220179\n",
      "Average loss at step 89400: 96.483157\n",
      "Average loss at step 89500: 96.611865\n",
      "Average loss at step 89600: 99.449733\n",
      "Average loss at step 89700: 95.233486\n",
      "Average loss at step 89800: 98.812186\n",
      "Average loss at step 89900: 95.789589\n",
      "Average loss at step 90000: 101.215201\n",
      "Graph 90: 423 nodes\n",
      "Average loss at step 90100: 145.428169\n",
      "Average loss at step 90200: 123.126054\n",
      "Average loss at step 90300: 117.989478\n",
      "Average loss at step 90400: 116.408715\n",
      "Average loss at step 90500: 122.678750\n",
      "Average loss at step 90600: 118.908393\n",
      "Average loss at step 90700: 117.123727\n",
      "Average loss at step 90800: 116.024324\n",
      "Average loss at step 90900: 115.845347\n",
      "Average loss at step 91000: 119.033137\n",
      "Time: 54.658094883\n",
      "Graph 91: 407 nodes\n",
      "Average loss at step 91100: 148.794681\n",
      "Average loss at step 91200: 132.061751\n",
      "Average loss at step 91300: 125.341773\n",
      "Average loss at step 91400: 131.161990\n",
      "Average loss at step 91500: 131.544123\n",
      "Average loss at step 91600: 131.793121\n",
      "Average loss at step 91700: 132.781814\n",
      "Average loss at step 91800: 130.012731\n",
      "Average loss at step 91900: 130.231044\n",
      "Average loss at step 92000: 128.132694\n",
      "Graph 92: 484 nodes\n",
      "Average loss at step 92100: 127.578422\n",
      "Average loss at step 92200: 114.392909\n",
      "Average loss at step 92300: 116.915403\n",
      "Average loss at step 92400: 113.904572\n",
      "Average loss at step 92500: 115.030434\n",
      "Average loss at step 92600: 117.616281\n",
      "Average loss at step 92700: 111.755736\n",
      "Average loss at step 92800: 115.578647\n",
      "Average loss at step 92900: 112.900709\n",
      "Average loss at step 93000: 114.348124\n",
      "Graph 93: 434 nodes\n",
      "Average loss at step 93100: 124.275894\n",
      "Average loss at step 93200: 109.145950\n",
      "Average loss at step 93300: 106.605298\n",
      "Average loss at step 93400: 110.329481\n",
      "Average loss at step 93500: 107.417850\n",
      "Average loss at step 93600: 111.489270\n",
      "Average loss at step 93700: 111.144758\n",
      "Average loss at step 93800: 111.061379\n",
      "Average loss at step 93900: 104.850485\n",
      "Average loss at step 94000: 107.247936\n",
      "Graph 94: 358 nodes\n",
      "Average loss at step 94100: 125.089013\n",
      "Average loss at step 94200: 91.526105\n",
      "Average loss at step 94300: 90.066593\n",
      "Average loss at step 94400: 87.595611\n",
      "Average loss at step 94500: 87.855313\n",
      "Average loss at step 94600: 88.157349\n",
      "Average loss at step 94700: 86.118956\n",
      "Average loss at step 94800: 82.918703\n",
      "Average loss at step 94900: 87.266341\n",
      "Average loss at step 95000: 83.466593\n",
      "Graph 95: 484 nodes\n",
      "Average loss at step 95100: 130.895640\n",
      "Average loss at step 95200: 121.447441\n",
      "Average loss at step 95300: 115.220894\n",
      "Average loss at step 95400: 118.916037\n",
      "Average loss at step 95500: 113.368255\n",
      "Average loss at step 95600: 117.421884\n",
      "Average loss at step 95700: 118.788598\n",
      "Average loss at step 95800: 116.053820\n",
      "Average loss at step 95900: 117.073836\n",
      "Average loss at step 96000: 113.060803\n",
      "Graph 96: 499 nodes\n",
      "Average loss at step 96100: 134.114695\n",
      "Average loss at step 96200: 119.610651\n",
      "Average loss at step 96300: 113.883311\n",
      "Average loss at step 96400: 118.092079\n",
      "Average loss at step 96500: 117.730591\n",
      "Average loss at step 96600: 114.450703\n",
      "Average loss at step 96700: 117.051976\n",
      "Average loss at step 96800: 116.396290\n",
      "Average loss at step 96900: 114.123590\n",
      "Average loss at step 97000: 116.674350\n",
      "Graph 97: 419 nodes\n",
      "Average loss at step 97100: 117.366107\n",
      "Average loss at step 97200: 108.459135\n",
      "Average loss at step 97300: 108.468839\n",
      "Average loss at step 97400: 107.819851\n",
      "Average loss at step 97500: 111.058792\n",
      "Average loss at step 97600: 106.503647\n",
      "Average loss at step 97700: 107.533659\n",
      "Average loss at step 97800: 110.886515\n",
      "Average loss at step 97900: 107.092521\n",
      "Average loss at step 98000: 114.220815\n",
      "Graph 98: 523 nodes\n",
      "Average loss at step 98100: 120.311369\n",
      "Average loss at step 98200: 115.822397\n",
      "Average loss at step 98300: 113.011990\n",
      "Average loss at step 98400: 112.151189\n",
      "Average loss at step 98500: 112.116642\n",
      "Average loss at step 98600: 111.002935\n",
      "Average loss at step 98700: 109.829940\n",
      "Average loss at step 98800: 111.806775\n",
      "Average loss at step 98900: 107.226375\n",
      "Average loss at step 99000: 111.900209\n",
      "Graph 99: 508 nodes\n",
      "Average loss at step 99100: 116.618828\n",
      "Average loss at step 99200: 99.197059\n",
      "Average loss at step 99300: 94.136541\n",
      "Average loss at step 99400: 95.139483\n",
      "Average loss at step 99500: 93.001214\n",
      "Average loss at step 99600: 96.811918\n",
      "Average loss at step 99700: 94.294390\n",
      "Average loss at step 99800: 93.058351\n",
      "Average loss at step 99900: 95.914731\n",
      "Average loss at step 100000: 92.889686\n",
      "Graph 100: 588 nodes\n",
      "Average loss at step 100100: 122.969800\n",
      "Average loss at step 100200: 109.199113\n",
      "Average loss at step 100300: 107.858712\n",
      "Average loss at step 100400: 112.991777\n",
      "Average loss at step 100500: 112.308860\n",
      "Average loss at step 100600: 110.136765\n",
      "Average loss at step 100700: 110.028378\n",
      "Average loss at step 100800: 108.268872\n",
      "Average loss at step 100900: 108.695751\n",
      "Average loss at step 101000: 107.546905\n",
      "Time: 54.7206771374\n",
      "Graph 101: 563 nodes\n",
      "Average loss at step 101100: 100.668952\n",
      "Average loss at step 101200: 93.873399\n",
      "Average loss at step 101300: 90.027740\n",
      "Average loss at step 101400: 91.504564\n",
      "Average loss at step 101500: 93.372015\n",
      "Average loss at step 101600: 91.878698\n",
      "Average loss at step 101700: 90.295946\n",
      "Average loss at step 101800: 93.547815\n",
      "Average loss at step 101900: 86.327265\n",
      "Average loss at step 102000: 90.828946\n",
      "Graph 102: 564 nodes\n",
      "Average loss at step 102100: 107.607161\n",
      "Average loss at step 102200: 98.817245\n",
      "Average loss at step 102300: 98.234842\n",
      "Average loss at step 102400: 100.529482\n",
      "Average loss at step 102500: 96.967705\n",
      "Average loss at step 102600: 98.276298\n",
      "Average loss at step 102700: 93.597103\n",
      "Average loss at step 102800: 97.269925\n",
      "Average loss at step 102900: 95.093288\n",
      "Average loss at step 103000: 96.642329\n",
      "Graph 103: 514 nodes\n",
      "Average loss at step 103100: 108.078726\n",
      "Average loss at step 103200: 102.471307\n",
      "Average loss at step 103300: 102.188214\n",
      "Average loss at step 103400: 101.534664\n",
      "Average loss at step 103500: 99.776126\n",
      "Average loss at step 103600: 103.195340\n",
      "Average loss at step 103700: 96.816091\n",
      "Average loss at step 103800: 98.772473\n",
      "Average loss at step 103900: 96.906028\n",
      "Average loss at step 104000: 104.281352\n",
      "Graph 104: 420 nodes\n",
      "Average loss at step 104100: 91.089234\n",
      "Average loss at step 104200: 82.603770\n",
      "Average loss at step 104300: 83.440361\n",
      "Average loss at step 104400: 78.522376\n",
      "Average loss at step 104500: 81.488354\n",
      "Average loss at step 104600: 79.472293\n",
      "Average loss at step 104700: 82.032099\n",
      "Average loss at step 104800: 80.085461\n",
      "Average loss at step 104900: 80.975920\n",
      "Average loss at step 105000: 80.548395\n",
      "Graph 105: 506 nodes\n",
      "Average loss at step 105100: 122.798099\n",
      "Average loss at step 105200: 97.897237\n",
      "Average loss at step 105300: 94.563896\n",
      "Average loss at step 105400: 95.811614\n",
      "Average loss at step 105500: 92.250615\n",
      "Average loss at step 105600: 92.808977\n",
      "Average loss at step 105700: 96.189860\n",
      "Average loss at step 105800: 94.516613\n",
      "Average loss at step 105900: 93.592007\n",
      "Average loss at step 106000: 90.597544\n",
      "Graph 106: 480 nodes\n",
      "Average loss at step 106100: 116.631808\n",
      "Average loss at step 106200: 103.680092\n",
      "Average loss at step 106300: 100.033207\n",
      "Average loss at step 106400: 101.468690\n",
      "Average loss at step 106500: 98.455225\n",
      "Average loss at step 106600: 100.335701\n",
      "Average loss at step 106700: 98.138112\n",
      "Average loss at step 106800: 98.944199\n",
      "Average loss at step 106900: 99.948207\n",
      "Average loss at step 107000: 99.199233\n",
      "Graph 107: 410 nodes\n",
      "Average loss at step 107100: 108.975015\n",
      "Average loss at step 107200: 94.049484\n",
      "Average loss at step 107300: 95.992132\n",
      "Average loss at step 107400: 100.742875\n",
      "Average loss at step 107500: 95.583280\n",
      "Average loss at step 107600: 95.261220\n",
      "Average loss at step 107700: 100.727133\n",
      "Average loss at step 107800: 99.252014\n",
      "Average loss at step 107900: 97.317898\n",
      "Average loss at step 108000: 97.791991\n",
      "Graph 108: 49 nodes\n",
      "Average loss at step 108100: 4.206898\n",
      "Average loss at step 108200: 3.941968\n",
      "Average loss at step 108300: 4.923976\n",
      "Average loss at step 108400: 3.948619\n",
      "Average loss at step 108500: 3.686239\n",
      "Average loss at step 108600: 4.020378\n",
      "Average loss at step 108700: 4.196664\n",
      "Average loss at step 108800: 3.372955\n",
      "Average loss at step 108900: 4.302234\n",
      "Average loss at step 109000: 3.816241\n",
      "Graph 109: 54 nodes\n",
      "Average loss at step 109100: 23.847702\n",
      "Average loss at step 109200: 22.758469\n",
      "Average loss at step 109300: 22.062908\n",
      "Average loss at step 109400: 21.410385\n",
      "Average loss at step 109500: 21.257146\n",
      "Average loss at step 109600: 22.220622\n",
      "Average loss at step 109700: 20.760690\n",
      "Average loss at step 109800: 21.203190\n",
      "Average loss at step 109900: 20.511886\n",
      "Average loss at step 110000: 21.613113\n",
      "Graph 110: 607 nodes\n",
      "Average loss at step 110100: 98.449814\n",
      "Average loss at step 110200: 92.759537\n",
      "Average loss at step 110300: 90.387382\n",
      "Average loss at step 110400: 89.146252\n",
      "Average loss at step 110500: 88.184774\n",
      "Average loss at step 110600: 94.211314\n",
      "Average loss at step 110700: 89.723537\n",
      "Average loss at step 110800: 90.639717\n",
      "Average loss at step 110900: 89.964998\n",
      "Average loss at step 111000: 93.593351\n",
      "Time: 51.6018311977\n",
      "Graph 111: 682 nodes\n",
      "Average loss at step 111100: 131.544201\n",
      "Average loss at step 111200: 113.401704\n",
      "Average loss at step 111300: 115.990193\n",
      "Average loss at step 111400: 116.740183\n",
      "Average loss at step 111500: 111.392182\n",
      "Average loss at step 111600: 118.926502\n",
      "Average loss at step 111700: 109.639250\n",
      "Average loss at step 111800: 115.306767\n",
      "Average loss at step 111900: 114.094815\n",
      "Average loss at step 112000: 110.865802\n",
      "Graph 112: 720 nodes\n",
      "Average loss at step 112100: 106.180310\n",
      "Average loss at step 112200: 104.284364\n",
      "Average loss at step 112300: 105.219615\n",
      "Average loss at step 112400: 108.799088\n",
      "Average loss at step 112500: 104.663533\n",
      "Average loss at step 112600: 103.173435\n",
      "Average loss at step 112700: 103.416377\n",
      "Average loss at step 112800: 102.272378\n",
      "Average loss at step 112900: 102.753301\n",
      "Average loss at step 113000: 104.267754\n",
      "Graph 113: 630 nodes\n",
      "Average loss at step 113100: 98.177356\n",
      "Average loss at step 113200: 92.592770\n",
      "Average loss at step 113300: 94.078832\n",
      "Average loss at step 113400: 95.699299\n",
      "Average loss at step 113500: 100.205812\n",
      "Average loss at step 113600: 97.872738\n",
      "Average loss at step 113700: 97.084574\n",
      "Average loss at step 113800: 93.985151\n",
      "Average loss at step 113900: 97.920841\n",
      "Average loss at step 114000: 100.293857\n",
      "Graph 114: 568 nodes\n",
      "Average loss at step 114100: 94.505844\n",
      "Average loss at step 114200: 90.224730\n",
      "Average loss at step 114300: 84.335148\n",
      "Average loss at step 114400: 82.072589\n",
      "Average loss at step 114500: 82.476357\n",
      "Average loss at step 114600: 86.670223\n",
      "Average loss at step 114700: 85.704368\n",
      "Average loss at step 114800: 85.094591\n",
      "Average loss at step 114900: 84.283513\n",
      "Average loss at step 115000: 85.816149\n",
      "Graph 115: 689 nodes\n",
      "Average loss at step 115100: 114.332762\n",
      "Average loss at step 115200: 108.071215\n",
      "Average loss at step 115300: 106.187655\n",
      "Average loss at step 115400: 104.442684\n",
      "Average loss at step 115500: 109.656695\n",
      "Average loss at step 115600: 103.065657\n",
      "Average loss at step 115700: 106.979296\n",
      "Average loss at step 115800: 102.123813\n",
      "Average loss at step 115900: 106.563332\n",
      "Average loss at step 116000: 103.761324\n",
      "Graph 116: 623 nodes\n",
      "Average loss at step 116100: 111.196125\n",
      "Average loss at step 116200: 104.696555\n",
      "Average loss at step 116300: 101.520519\n",
      "Average loss at step 116400: 104.935306\n",
      "Average loss at step 116500: 101.471262\n",
      "Average loss at step 116600: 104.200210\n",
      "Average loss at step 116700: 105.495553\n",
      "Average loss at step 116800: 101.058376\n",
      "Average loss at step 116900: 103.301771\n",
      "Average loss at step 117000: 101.655420\n",
      "Graph 117: 707 nodes\n",
      "Average loss at step 117100: 112.293966\n",
      "Average loss at step 117200: 111.104612\n",
      "Average loss at step 117300: 107.431629\n",
      "Average loss at step 117400: 107.204309\n",
      "Average loss at step 117500: 108.241945\n",
      "Average loss at step 117600: 104.564045\n",
      "Average loss at step 117700: 105.891827\n",
      "Average loss at step 117800: 108.399219\n",
      "Average loss at step 117900: 107.694757\n",
      "Average loss at step 118000: 108.383121\n",
      "Graph 118: 650 nodes\n",
      "Average loss at step 118100: 121.340170\n",
      "Average loss at step 118200: 116.703959\n",
      "Average loss at step 118300: 117.212378\n",
      "Average loss at step 118400: 114.698856\n",
      "Average loss at step 118500: 116.720244\n",
      "Average loss at step 118600: 114.290756\n",
      "Average loss at step 118700: 114.950759\n",
      "Average loss at step 118800: 111.671884\n",
      "Average loss at step 118900: 116.058850\n",
      "Average loss at step 119000: 108.933470\n",
      "Graph 119: 625 nodes\n",
      "Average loss at step 119100: 90.106873\n",
      "Average loss at step 119200: 90.447679\n",
      "Average loss at step 119300: 88.920053\n",
      "Average loss at step 119400: 90.704840\n",
      "Average loss at step 119500: 86.203542\n",
      "Average loss at step 119600: 85.691733\n",
      "Average loss at step 119700: 84.419888\n",
      "Average loss at step 119800: 88.826516\n",
      "Average loss at step 119900: 84.487751\n",
      "Average loss at step 120000: 86.588198\n",
      "Graph 120: 808 nodes\n",
      "Average loss at step 120100: 114.553494\n",
      "Average loss at step 120200: 108.044541\n",
      "Average loss at step 120300: 104.128089\n",
      "Average loss at step 120400: 103.482184\n",
      "Average loss at step 120500: 103.765004\n",
      "Average loss at step 120600: 104.792451\n",
      "Average loss at step 120700: 105.961036\n",
      "Average loss at step 120800: 106.997215\n",
      "Average loss at step 120900: 106.764928\n",
      "Average loss at step 121000: 103.674359\n",
      "Time: 53.5797638893\n",
      "Graph 121: 897 nodes\n",
      "Average loss at step 121100: 161.279261\n",
      "Average loss at step 121200: 120.958676\n",
      "Average loss at step 121300: 119.022913\n",
      "Average loss at step 121400: 122.358689\n",
      "Average loss at step 121500: 117.950719\n",
      "Average loss at step 121600: 118.201460\n",
      "Average loss at step 121700: 119.147309\n",
      "Average loss at step 121800: 119.100395\n",
      "Average loss at step 121900: 118.519201\n",
      "Average loss at step 122000: 120.438987\n",
      "Graph 122: 958 nodes\n",
      "Average loss at step 122100: 126.783482\n",
      "Average loss at step 122200: 115.686895\n",
      "Average loss at step 122300: 113.462347\n",
      "Average loss at step 122400: 113.164942\n",
      "Average loss at step 122500: 114.221196\n",
      "Average loss at step 122600: 111.762981\n",
      "Average loss at step 122700: 109.665289\n",
      "Average loss at step 122800: 111.663511\n",
      "Average loss at step 122900: 112.391481\n",
      "Average loss at step 123000: 113.434434\n",
      "Graph 123: 397 nodes\n",
      "Average loss at step 123100: 118.981035\n",
      "Average loss at step 123200: 108.168934\n",
      "Average loss at step 123300: 104.765749\n",
      "Average loss at step 123400: 101.655984\n",
      "Average loss at step 123500: 106.947671\n",
      "Average loss at step 123600: 109.092568\n",
      "Average loss at step 123700: 100.171838\n",
      "Average loss at step 123800: 107.825731\n",
      "Average loss at step 123900: 106.360348\n",
      "Average loss at step 124000: 103.139097\n",
      "Graph 124: 339 nodes\n",
      "Average loss at step 124100: 87.795197\n",
      "Average loss at step 124200: 80.532525\n",
      "Average loss at step 124300: 78.691134\n",
      "Average loss at step 124400: 81.337268\n",
      "Average loss at step 124500: 80.322677\n",
      "Average loss at step 124600: 75.042227\n",
      "Average loss at step 124700: 78.723015\n",
      "Average loss at step 124800: 79.044953\n",
      "Average loss at step 124900: 77.647042\n",
      "Average loss at step 125000: 80.033416\n",
      "Graph 125: 378 nodes\n",
      "Average loss at step 125100: 115.853050\n",
      "Average loss at step 125200: 106.593513\n",
      "Average loss at step 125300: 95.662090\n",
      "Average loss at step 125400: 94.059080\n",
      "Average loss at step 125500: 98.619938\n",
      "Average loss at step 125600: 90.513250\n",
      "Average loss at step 125700: 95.790953\n",
      "Average loss at step 125800: 94.840483\n",
      "Average loss at step 125900: 90.357592\n",
      "Average loss at step 126000: 95.295622\n",
      "Graph 126: 374 nodes\n",
      "Average loss at step 126100: 111.221440\n",
      "Average loss at step 126200: 107.668996\n",
      "Average loss at step 126300: 103.267968\n",
      "Average loss at step 126400: 102.794350\n",
      "Average loss at step 126500: 105.737953\n",
      "Average loss at step 126600: 115.104935\n",
      "Average loss at step 126700: 108.679742\n",
      "Average loss at step 126800: 106.105687\n",
      "Average loss at step 126900: 108.189054\n",
      "Average loss at step 127000: 102.645215\n",
      "Graph 127: 375 nodes\n",
      "Average loss at step 127100: 143.739392\n",
      "Average loss at step 127200: 109.271035\n",
      "Average loss at step 127300: 108.013769\n",
      "Average loss at step 127400: 101.710254\n",
      "Average loss at step 127500: 101.358237\n",
      "Average loss at step 127600: 103.727467\n",
      "Average loss at step 127700: 101.174117\n",
      "Average loss at step 127800: 102.583685\n",
      "Average loss at step 127900: 101.656820\n",
      "Average loss at step 128000: 105.321088\n",
      "Graph 128: 317 nodes\n",
      "Average loss at step 128100: 107.787041\n",
      "Average loss at step 128200: 105.521635\n",
      "Average loss at step 128300: 99.160376\n",
      "Average loss at step 128400: 102.251206\n",
      "Average loss at step 128500: 99.562341\n",
      "Average loss at step 128600: 102.460841\n",
      "Average loss at step 128700: 99.844323\n",
      "Average loss at step 128800: 101.638149\n",
      "Average loss at step 128900: 99.794054\n",
      "Average loss at step 129000: 101.484148\n",
      "Graph 129: 244 nodes\n",
      "Average loss at step 129100: 122.680429\n",
      "Average loss at step 129200: 90.931445\n",
      "Average loss at step 129300: 96.292127\n",
      "Average loss at step 129400: 91.947175\n",
      "Average loss at step 129500: 89.140827\n",
      "Average loss at step 129600: 87.640504\n",
      "Average loss at step 129700: 88.707702\n",
      "Average loss at step 129800: 87.909213\n",
      "Average loss at step 129900: 88.815075\n",
      "Average loss at step 130000: 84.409919\n",
      "Graph 130: 19 nodes\n",
      "Average loss at step 130100: 12.625198\n",
      "Average loss at step 130200: 9.525286\n",
      "Average loss at step 130300: 9.030544\n",
      "Average loss at step 130400: 9.854224\n",
      "Average loss at step 130500: 8.878762\n",
      "Average loss at step 130600: 9.588723\n",
      "Average loss at step 130700: 8.789192\n",
      "Average loss at step 130800: 9.001992\n",
      "Average loss at step 130900: 8.908271\n",
      "Average loss at step 131000: 8.027785\n",
      "Time: 40.6827058792\n",
      "Graph 131: 90 nodes\n",
      "Average loss at step 131100: 76.274267\n",
      "Average loss at step 131200: 72.773580\n",
      "Average loss at step 131300: 70.076873\n",
      "Average loss at step 131400: 71.950426\n",
      "Average loss at step 131500: 73.203127\n",
      "Average loss at step 131600: 68.892643\n",
      "Average loss at step 131700: 69.753242\n",
      "Average loss at step 131800: 72.555742\n",
      "Average loss at step 131900: 71.214803\n",
      "Average loss at step 132000: 72.377467\n",
      "Graph 132: 210 nodes\n",
      "Average loss at step 132100: 118.670397\n",
      "Average loss at step 132200: 101.727105\n",
      "Average loss at step 132300: 89.356381\n",
      "Average loss at step 132400: 90.313239\n",
      "Average loss at step 132500: 92.820727\n",
      "Average loss at step 132600: 87.438945\n",
      "Average loss at step 132700: 90.401403\n",
      "Average loss at step 132800: 94.980203\n",
      "Average loss at step 132900: 94.739303\n",
      "Average loss at step 133000: 90.134051\n",
      "Graph 133: 226 nodes\n",
      "Average loss at step 133100: 91.140972\n",
      "Average loss at step 133200: 78.299952\n",
      "Average loss at step 133300: 78.850571\n",
      "Average loss at step 133400: 80.165304\n",
      "Average loss at step 133500: 86.012448\n",
      "Average loss at step 133600: 80.219548\n",
      "Average loss at step 133700: 79.419117\n",
      "Average loss at step 133800: 85.893960\n",
      "Average loss at step 133900: 80.587706\n",
      "Average loss at step 134000: 84.970513\n",
      "Graph 134: 162 nodes\n",
      "Average loss at step 134100: 71.878515\n",
      "Average loss at step 134200: 68.700970\n",
      "Average loss at step 134300: 69.202421\n",
      "Average loss at step 134400: 66.065684\n",
      "Average loss at step 134500: 67.347253\n",
      "Average loss at step 134600: 65.791938\n",
      "Average loss at step 134700: 71.864352\n",
      "Average loss at step 134800: 65.833915\n",
      "Average loss at step 134900: 67.651424\n",
      "Average loss at step 135000: 66.576974\n",
      "Graph 135: 62 nodes\n",
      "Average loss at step 135100: 70.954789\n",
      "Average loss at step 135200: 64.617461\n",
      "Average loss at step 135300: 66.645719\n",
      "Average loss at step 135400: 66.418474\n",
      "Average loss at step 135500: 61.465777\n",
      "Average loss at step 135600: 60.217967\n",
      "Average loss at step 135700: 64.392665\n",
      "Average loss at step 135800: 64.134224\n",
      "Average loss at step 135900: 62.706284\n",
      "Average loss at step 136000: 59.443932\n",
      "Graph 136: 349 nodes\n",
      "Average loss at step 136100: 124.133334\n",
      "Average loss at step 136200: 105.697426\n",
      "Average loss at step 136300: 105.979652\n",
      "Average loss at step 136400: 101.918423\n",
      "Average loss at step 136500: 103.124315\n",
      "Average loss at step 136600: 103.521337\n",
      "Average loss at step 136700: 99.947603\n",
      "Average loss at step 136800: 101.192756\n",
      "Average loss at step 136900: 100.151476\n",
      "Average loss at step 137000: 100.845857\n",
      "Graph 137: 341 nodes\n",
      "Average loss at step 137100: 122.557994\n",
      "Average loss at step 137200: 103.344663\n",
      "Average loss at step 137300: 101.030180\n",
      "Average loss at step 137400: 100.414086\n",
      "Average loss at step 137500: 100.097510\n",
      "Average loss at step 137600: 95.549015\n",
      "Average loss at step 137700: 98.604553\n",
      "Average loss at step 137800: 99.845968\n",
      "Average loss at step 137900: 98.887622\n",
      "Average loss at step 138000: 103.677269\n",
      "Graph 138: 365 nodes\n",
      "Average loss at step 138100: 103.143719\n",
      "Average loss at step 138200: 95.856948\n",
      "Average loss at step 138300: 97.645838\n",
      "Average loss at step 138400: 89.230613\n",
      "Average loss at step 138500: 96.247012\n",
      "Average loss at step 138600: 92.152790\n",
      "Average loss at step 138700: 92.570597\n",
      "Average loss at step 138800: 96.086792\n",
      "Average loss at step 138900: 96.802592\n",
      "Average loss at step 139000: 92.596346\n",
      "Graph 139: 334 nodes\n",
      "Average loss at step 139100: 102.082558\n",
      "Average loss at step 139200: 97.764228\n",
      "Average loss at step 139300: 91.114922\n",
      "Average loss at step 139400: 91.790357\n",
      "Average loss at step 139500: 91.768011\n",
      "Average loss at step 139600: 89.635748\n",
      "Average loss at step 139700: 91.227331\n",
      "Average loss at step 139800: 92.463688\n",
      "Average loss at step 139900: 95.102826\n",
      "Average loss at step 140000: 94.796325\n",
      "Graph 140: 364 nodes\n",
      "Average loss at step 140100: 103.253617\n",
      "Average loss at step 140200: 101.762835\n",
      "Average loss at step 140300: 99.769117\n",
      "Average loss at step 140400: 99.245006\n",
      "Average loss at step 140500: 99.096670\n",
      "Average loss at step 140600: 95.482951\n",
      "Average loss at step 140700: 101.366029\n",
      "Average loss at step 140800: 99.463914\n",
      "Average loss at step 140900: 95.667283\n",
      "Average loss at step 141000: 96.292128\n",
      "Time: 50.2874381542\n",
      "Graph 141: 339 nodes\n",
      "Average loss at step 141100: 93.250197\n",
      "Average loss at step 141200: 93.103669\n",
      "Average loss at step 141300: 87.149317\n",
      "Average loss at step 141400: 88.221106\n",
      "Average loss at step 141500: 85.792378\n",
      "Average loss at step 141600: 92.352071\n",
      "Average loss at step 141700: 86.145821\n",
      "Average loss at step 141800: 86.385642\n",
      "Average loss at step 141900: 91.722064\n",
      "Average loss at step 142000: 85.886766\n",
      "Graph 142: 344 nodes\n",
      "Average loss at step 142100: 99.997726\n",
      "Average loss at step 142200: 93.464451\n",
      "Average loss at step 142300: 89.239500\n",
      "Average loss at step 142400: 88.346351\n",
      "Average loss at step 142500: 88.999774\n",
      "Average loss at step 142600: 87.470101\n",
      "Average loss at step 142700: 90.009532\n",
      "Average loss at step 142800: 87.385587\n",
      "Average loss at step 142900: 86.238692\n",
      "Average loss at step 143000: 87.879903\n",
      "Graph 143: 341 nodes\n",
      "Average loss at step 143100: 107.278894\n",
      "Average loss at step 143200: 93.621843\n",
      "Average loss at step 143300: 95.461971\n",
      "Average loss at step 143400: 93.175500\n",
      "Average loss at step 143500: 94.564783\n",
      "Average loss at step 143600: 95.171682\n",
      "Average loss at step 143700: 92.612707\n",
      "Average loss at step 143800: 96.455755\n",
      "Average loss at step 143900: 98.849625\n",
      "Average loss at step 144000: 97.267836\n",
      "Graph 144: 328 nodes\n",
      "Average loss at step 144100: 143.828593\n",
      "Average loss at step 144200: 100.666374\n",
      "Average loss at step 144300: 102.606978\n",
      "Average loss at step 144400: 96.218668\n",
      "Average loss at step 144500: 96.715848\n",
      "Average loss at step 144600: 96.303773\n",
      "Average loss at step 144700: 94.811170\n",
      "Average loss at step 144800: 93.747521\n",
      "Average loss at step 144900: 96.356012\n",
      "Average loss at step 145000: 96.719403\n",
      "Graph 145: 108 nodes\n",
      "Average loss at step 145100: 47.258458\n",
      "Average loss at step 145200: 40.920869\n",
      "Average loss at step 145300: 41.095406\n",
      "Average loss at step 145400: 39.647694\n",
      "Average loss at step 145500: 39.989508\n",
      "Average loss at step 145600: 40.016965\n",
      "Average loss at step 145700: 37.925715\n",
      "Average loss at step 145800: 43.491272\n",
      "Average loss at step 145900: 41.920076\n",
      "Average loss at step 146000: 41.976619\n",
      "Graph 146: 385 nodes\n",
      "Average loss at step 146100: 108.154495\n",
      "Average loss at step 146200: 100.127248\n",
      "Average loss at step 146300: 100.988609\n",
      "Average loss at step 146400: 100.314077\n",
      "Average loss at step 146500: 101.548650\n",
      "Average loss at step 146600: 100.138437\n",
      "Average loss at step 146700: 98.490199\n",
      "Average loss at step 146800: 96.633026\n",
      "Average loss at step 146900: 98.473969\n",
      "Average loss at step 147000: 99.140848\n",
      "Graph 147: 380 nodes\n",
      "Average loss at step 147100: 112.540924\n",
      "Average loss at step 147200: 97.364813\n",
      "Average loss at step 147300: 106.298169\n",
      "Average loss at step 147400: 99.285443\n",
      "Average loss at step 147500: 100.964534\n",
      "Average loss at step 147600: 101.200654\n",
      "Average loss at step 147700: 102.581727\n",
      "Average loss at step 147800: 100.300801\n",
      "Average loss at step 147900: 103.647743\n",
      "Average loss at step 148000: 104.320515\n",
      "Graph 148: 315 nodes\n",
      "Average loss at step 148100: 108.883033\n",
      "Average loss at step 148200: 101.581453\n",
      "Average loss at step 148300: 105.384893\n",
      "Average loss at step 148400: 99.373021\n",
      "Average loss at step 148500: 102.561608\n",
      "Average loss at step 148600: 104.160466\n",
      "Average loss at step 148700: 98.920622\n",
      "Average loss at step 148800: 102.466289\n",
      "Average loss at step 148900: 101.087066\n",
      "Average loss at step 149000: 102.268868\n",
      "Graph 149: 348 nodes\n",
      "Average loss at step 149100: 89.804400\n",
      "Average loss at step 149200: 87.188075\n",
      "Average loss at step 149300: 86.757219\n",
      "Average loss at step 149400: 82.793079\n",
      "Average loss at step 149500: 84.833189\n",
      "Average loss at step 149600: 84.961262\n",
      "Average loss at step 149700: 89.373148\n",
      "Average loss at step 149800: 91.936608\n",
      "Average loss at step 149900: 90.078994\n",
      "Average loss at step 150000: 85.116567\n",
      "Graph 150: 411 nodes\n",
      "Average loss at step 150100: 95.601366\n",
      "Average loss at step 150200: 91.621016\n",
      "Average loss at step 150300: 96.871219\n",
      "Average loss at step 150400: 90.543660\n",
      "Average loss at step 150500: 91.694848\n",
      "Average loss at step 150600: 94.782399\n",
      "Average loss at step 150700: 92.816538\n",
      "Average loss at step 150800: 97.272172\n",
      "Average loss at step 150900: 94.743331\n",
      "Average loss at step 151000: 92.786774\n",
      "Time: 50.7798600197\n",
      "Graph 151: 415 nodes\n",
      "Average loss at step 151100: 138.758564\n",
      "Average loss at step 151200: 104.061752\n",
      "Average loss at step 151300: 101.001047\n",
      "Average loss at step 151400: 99.754509\n",
      "Average loss at step 151500: 106.400087\n",
      "Average loss at step 151600: 101.548947\n",
      "Average loss at step 151700: 101.130713\n",
      "Average loss at step 151800: 100.687678\n",
      "Average loss at step 151900: 103.654248\n",
      "Average loss at step 152000: 100.804134\n",
      "Graph 152: 429 nodes\n",
      "Average loss at step 152100: 113.020180\n",
      "Average loss at step 152200: 94.373151\n",
      "Average loss at step 152300: 97.281285\n",
      "Average loss at step 152400: 97.340231\n",
      "Average loss at step 152500: 95.659368\n",
      "Average loss at step 152600: 94.070101\n",
      "Average loss at step 152700: 92.751291\n",
      "Average loss at step 152800: 94.084238\n",
      "Average loss at step 152900: 98.161030\n",
      "Average loss at step 153000: 98.441172\n",
      "Graph 153: 378 nodes\n",
      "Average loss at step 153100: 101.457729\n",
      "Average loss at step 153200: 84.230278\n",
      "Average loss at step 153300: 85.422888\n",
      "Average loss at step 153400: 81.568243\n",
      "Average loss at step 153500: 89.990316\n",
      "Average loss at step 153600: 86.101687\n",
      "Average loss at step 153700: 84.387158\n",
      "Average loss at step 153800: 83.355345\n",
      "Average loss at step 153900: 83.326304\n",
      "Average loss at step 154000: 83.283728\n",
      "Graph 154: 405 nodes\n",
      "Average loss at step 154100: 91.221040\n",
      "Average loss at step 154200: 88.145533\n",
      "Average loss at step 154300: 88.273032\n",
      "Average loss at step 154400: 85.901988\n",
      "Average loss at step 154500: 90.148909\n",
      "Average loss at step 154600: 85.136546\n",
      "Average loss at step 154700: 90.132655\n",
      "Average loss at step 154800: 85.290958\n",
      "Average loss at step 154900: 84.350812\n",
      "Average loss at step 155000: 87.121676\n",
      "Graph 155: 407 nodes\n",
      "Average loss at step 155100: 121.294944\n",
      "Average loss at step 155200: 112.759355\n",
      "Average loss at step 155300: 109.876676\n",
      "Average loss at step 155400: 115.005073\n",
      "Average loss at step 155500: 109.708013\n",
      "Average loss at step 155600: 110.593772\n",
      "Average loss at step 155700: 112.751012\n",
      "Average loss at step 155800: 110.004680\n",
      "Average loss at step 155900: 116.162403\n",
      "Average loss at step 156000: 109.661718\n",
      "Graph 156: 397 nodes\n",
      "Average loss at step 156100: 102.924188\n",
      "Average loss at step 156200: 104.649307\n",
      "Average loss at step 156300: 102.121648\n",
      "Average loss at step 156400: 100.950763\n",
      "Average loss at step 156500: 101.320626\n",
      "Average loss at step 156600: 96.799009\n",
      "Average loss at step 156700: 99.892905\n",
      "Average loss at step 156800: 99.843054\n",
      "Average loss at step 156900: 100.314924\n",
      "Average loss at step 157000: 102.037457\n",
      "Graph 157: 441 nodes\n",
      "Average loss at step 157100: 135.148854\n",
      "Average loss at step 157200: 96.066585\n",
      "Average loss at step 157300: 91.456370\n",
      "Average loss at step 157400: 96.376477\n",
      "Average loss at step 157500: 94.369844\n",
      "Average loss at step 157600: 97.880411\n",
      "Average loss at step 157700: 93.451009\n",
      "Average loss at step 157800: 91.129877\n",
      "Average loss at step 157900: 94.662363\n",
      "Average loss at step 158000: 96.558049\n",
      "Graph 158: 393 nodes\n",
      "Average loss at step 158100: 94.164558\n",
      "Average loss at step 158200: 83.173452\n",
      "Average loss at step 158300: 83.815163\n",
      "Average loss at step 158400: 84.509193\n",
      "Average loss at step 158500: 85.247335\n",
      "Average loss at step 158600: 85.087248\n",
      "Average loss at step 158700: 85.300758\n",
      "Average loss at step 158800: 81.987582\n",
      "Average loss at step 158900: 80.885231\n",
      "Average loss at step 159000: 84.351474\n",
      "Graph 159: 353 nodes\n",
      "Average loss at step 159100: 81.609929\n",
      "Average loss at step 159200: 69.402651\n",
      "Average loss at step 159300: 71.390548\n",
      "Average loss at step 159400: 70.212395\n",
      "Average loss at step 159500: 71.105642\n",
      "Average loss at step 159600: 71.213621\n",
      "Average loss at step 159700: 68.251406\n",
      "Average loss at step 159800: 68.474027\n",
      "Average loss at step 159900: 72.140574\n",
      "Average loss at step 160000: 72.475675\n",
      "Graph 160: 424 nodes\n",
      "Average loss at step 160100: 96.666484\n",
      "Average loss at step 160200: 90.480259\n",
      "Average loss at step 160300: 87.204905\n",
      "Average loss at step 160400: 89.607819\n",
      "Average loss at step 160500: 89.601994\n",
      "Average loss at step 160600: 85.508726\n",
      "Average loss at step 160700: 80.378817\n",
      "Average loss at step 160800: 88.711206\n",
      "Average loss at step 160900: 87.709580\n",
      "Average loss at step 161000: 86.391744\n",
      "Time: 52.3618810177\n",
      "Graph 161: 483 nodes\n",
      "Average loss at step 161100: 114.973454\n",
      "Average loss at step 161200: 111.924761\n",
      "Average loss at step 161300: 102.528224\n",
      "Average loss at step 161400: 102.617022\n",
      "Average loss at step 161500: 107.462157\n",
      "Average loss at step 161600: 103.853688\n",
      "Average loss at step 161700: 109.306453\n",
      "Average loss at step 161800: 106.237037\n",
      "Average loss at step 161900: 109.215563\n",
      "Average loss at step 162000: 104.280750\n",
      "Graph 162: 432 nodes\n",
      "Average loss at step 162100: 94.795909\n",
      "Average loss at step 162200: 98.385590\n",
      "Average loss at step 162300: 93.180541\n",
      "Average loss at step 162400: 92.583152\n",
      "Average loss at step 162500: 91.181100\n",
      "Average loss at step 162600: 93.033530\n",
      "Average loss at step 162700: 89.262410\n",
      "Average loss at step 162800: 95.162293\n",
      "Average loss at step 162900: 89.124324\n",
      "Average loss at step 163000: 90.057920\n",
      "Graph 163: 349 nodes\n",
      "Average loss at step 163100: 126.821286\n",
      "Average loss at step 163200: 99.957356\n",
      "Average loss at step 163300: 102.351074\n",
      "Average loss at step 163400: 104.313800\n",
      "Average loss at step 163500: 106.182917\n",
      "Average loss at step 163600: 102.691927\n",
      "Average loss at step 163700: 99.503465\n",
      "Average loss at step 163800: 98.454710\n",
      "Average loss at step 163900: 103.239873\n",
      "Average loss at step 164000: 106.240607\n",
      "Graph 164: 396 nodes\n",
      "Average loss at step 164100: 94.039042\n",
      "Average loss at step 164200: 86.433149\n",
      "Average loss at step 164300: 83.685820\n",
      "Average loss at step 164400: 85.058082\n",
      "Average loss at step 164500: 81.037517\n",
      "Average loss at step 164600: 78.766394\n",
      "Average loss at step 164700: 84.619782\n",
      "Average loss at step 164800: 84.313638\n",
      "Average loss at step 164900: 81.448891\n",
      "Average loss at step 165000: 83.690767\n",
      "Graph 165: 381 nodes\n",
      "Average loss at step 165100: 120.445397\n",
      "Average loss at step 165200: 103.180141\n",
      "Average loss at step 165300: 105.033399\n",
      "Average loss at step 165400: 101.213069\n",
      "Average loss at step 165500: 101.471036\n",
      "Average loss at step 165600: 98.615033\n",
      "Average loss at step 165700: 101.577906\n",
      "Average loss at step 165800: 102.818252\n",
      "Average loss at step 165900: 100.749466\n",
      "Average loss at step 166000: 98.164373\n",
      "Graph 166: 358 nodes\n",
      "Average loss at step 166100: 92.713799\n",
      "Average loss at step 166200: 89.656834\n",
      "Average loss at step 166300: 89.087017\n",
      "Average loss at step 166400: 83.686642\n",
      "Average loss at step 166500: 86.863149\n",
      "Average loss at step 166600: 84.375273\n",
      "Average loss at step 166700: 80.306822\n",
      "Average loss at step 166800: 84.336674\n",
      "Average loss at step 166900: 84.458217\n",
      "Average loss at step 167000: 82.946741\n",
      "Graph 167: 393 nodes\n",
      "Average loss at step 167100: 106.935693\n",
      "Average loss at step 167200: 97.680054\n",
      "Average loss at step 167300: 101.027568\n",
      "Average loss at step 167400: 103.201536\n",
      "Average loss at step 167500: 96.134351\n",
      "Average loss at step 167600: 96.256237\n",
      "Average loss at step 167700: 100.152655\n",
      "Average loss at step 167800: 102.510063\n",
      "Average loss at step 167900: 99.659388\n",
      "Average loss at step 168000: 97.838599\n",
      "Graph 168: 399 nodes\n",
      "Average loss at step 168100: 149.608866\n",
      "Average loss at step 168200: 108.082813\n",
      "Average loss at step 168300: 105.962018\n",
      "Average loss at step 168400: 104.494920\n",
      "Average loss at step 168500: 106.738484\n",
      "Average loss at step 168600: 107.381742\n",
      "Average loss at step 168700: 107.411738\n",
      "Average loss at step 168800: 108.097985\n",
      "Average loss at step 168900: 109.010098\n",
      "Average loss at step 169000: 104.380395\n",
      "Graph 169: 330 nodes\n",
      "Average loss at step 169100: 103.113431\n",
      "Average loss at step 169200: 94.972345\n",
      "Average loss at step 169300: 86.607845\n",
      "Average loss at step 169400: 91.395645\n",
      "Average loss at step 169500: 89.866187\n",
      "Average loss at step 169600: 90.051955\n",
      "Average loss at step 169700: 88.901210\n",
      "Average loss at step 169800: 89.891297\n",
      "Average loss at step 169900: 82.993385\n",
      "Average loss at step 170000: 86.078826\n",
      "Graph 170: 111 nodes\n",
      "Average loss at step 170100: 83.694169\n",
      "Average loss at step 170200: 80.930884\n",
      "Average loss at step 170300: 74.059865\n",
      "Average loss at step 170400: 74.284122\n",
      "Average loss at step 170500: 73.355494\n",
      "Average loss at step 170600: 73.722095\n",
      "Average loss at step 170700: 73.957422\n",
      "Average loss at step 170800: 77.793607\n",
      "Average loss at step 170900: 74.361919\n",
      "Average loss at step 171000: 72.493174\n",
      "Time: 50.3833739758\n",
      "Graph 171: 453 nodes\n",
      "Average loss at step 171100: 112.556848\n",
      "Average loss at step 171200: 101.271905\n",
      "Average loss at step 171300: 103.272629\n",
      "Average loss at step 171400: 103.977123\n",
      "Average loss at step 171500: 104.115255\n",
      "Average loss at step 171600: 101.766247\n",
      "Average loss at step 171700: 102.697351\n",
      "Average loss at step 171800: 102.237725\n",
      "Average loss at step 171900: 104.187562\n",
      "Average loss at step 172000: 102.729616\n",
      "Graph 172: 448 nodes\n",
      "Average loss at step 172100: 114.221492\n",
      "Average loss at step 172200: 121.429119\n",
      "Average loss at step 172300: 110.196362\n",
      "Average loss at step 172400: 113.938969\n",
      "Average loss at step 172500: 114.487895\n",
      "Average loss at step 172600: 116.525557\n",
      "Average loss at step 172700: 112.003995\n",
      "Average loss at step 172800: 114.672304\n",
      "Average loss at step 172900: 112.215205\n",
      "Average loss at step 173000: 112.169670\n",
      "Graph 173: 439 nodes\n",
      "Average loss at step 173100: 103.705904\n",
      "Average loss at step 173200: 95.612647\n",
      "Average loss at step 173300: 96.941348\n",
      "Average loss at step 173400: 100.985954\n",
      "Average loss at step 173500: 98.310137\n",
      "Average loss at step 173600: 93.762466\n",
      "Average loss at step 173700: 92.664236\n",
      "Average loss at step 173800: 96.412557\n",
      "Average loss at step 173900: 92.853052\n",
      "Average loss at step 174000: 97.195099\n",
      "Graph 174: 383 nodes\n",
      "Average loss at step 174100: 113.570586\n",
      "Average loss at step 174200: 101.589884\n",
      "Average loss at step 174300: 100.186178\n",
      "Average loss at step 174400: 99.475521\n",
      "Average loss at step 174500: 98.924822\n",
      "Average loss at step 174600: 100.594509\n",
      "Average loss at step 174700: 98.689695\n",
      "Average loss at step 174800: 101.547420\n",
      "Average loss at step 174900: 98.719125\n",
      "Average loss at step 175000: 98.760320\n",
      "Graph 175: 422 nodes\n",
      "Average loss at step 175100: 108.245944\n",
      "Average loss at step 175200: 99.821165\n",
      "Average loss at step 175300: 98.208414\n",
      "Average loss at step 175400: 98.252076\n",
      "Average loss at step 175500: 95.003560\n",
      "Average loss at step 175600: 99.999608\n",
      "Average loss at step 175700: 98.056079\n",
      "Average loss at step 175800: 99.232735\n",
      "Average loss at step 175900: 100.078890\n",
      "Average loss at step 176000: 98.484770\n",
      "Graph 176: 409 nodes\n",
      "Average loss at step 176100: 129.531926\n",
      "Average loss at step 176200: 122.161688\n",
      "Average loss at step 176300: 122.990505\n",
      "Average loss at step 176400: 122.920462\n",
      "Average loss at step 176500: 121.199192\n",
      "Average loss at step 176600: 124.338376\n",
      "Average loss at step 176700: 121.956946\n",
      "Average loss at step 176800: 122.767441\n",
      "Average loss at step 176900: 122.409484\n",
      "Average loss at step 177000: 123.226893\n",
      "Graph 177: 439 nodes\n",
      "Average loss at step 177100: 150.705607\n",
      "Average loss at step 177200: 113.885132\n",
      "Average loss at step 177300: 106.806169\n",
      "Average loss at step 177400: 109.596836\n",
      "Average loss at step 177500: 111.445261\n",
      "Average loss at step 177600: 110.953514\n",
      "Average loss at step 177700: 106.446839\n",
      "Average loss at step 177800: 111.315566\n",
      "Average loss at step 177900: 108.084702\n",
      "Average loss at step 178000: 111.725478\n",
      "Graph 178: 386 nodes\n",
      "Average loss at step 178100: 168.201823\n",
      "Average loss at step 178200: 113.131056\n",
      "Average loss at step 178300: 108.768879\n",
      "Average loss at step 178400: 109.768067\n",
      "Average loss at step 178500: 103.322710\n",
      "Average loss at step 178600: 107.820097\n",
      "Average loss at step 178700: 105.190132\n",
      "Average loss at step 178800: 109.836177\n",
      "Average loss at step 178900: 105.224861\n",
      "Average loss at step 179000: 106.020252\n",
      "Graph 179: 349 nodes\n",
      "Average loss at step 179100: 104.691202\n",
      "Average loss at step 179200: 98.177818\n",
      "Average loss at step 179300: 99.069742\n",
      "Average loss at step 179400: 96.750825\n",
      "Average loss at step 179500: 93.290456\n",
      "Average loss at step 179600: 99.686000\n",
      "Average loss at step 179700: 94.506317\n",
      "Average loss at step 179800: 94.462807\n",
      "Average loss at step 179900: 97.662817\n",
      "Average loss at step 180000: 96.148336\n",
      "Graph 180: 396 nodes\n",
      "Average loss at step 180100: 117.163028\n",
      "Average loss at step 180200: 98.208241\n",
      "Average loss at step 180300: 95.975250\n",
      "Average loss at step 180400: 98.893594\n",
      "Average loss at step 180500: 94.776449\n",
      "Average loss at step 180600: 93.083876\n",
      "Average loss at step 180700: 94.124274\n",
      "Average loss at step 180800: 97.522560\n",
      "Average loss at step 180900: 91.473924\n",
      "Average loss at step 181000: 92.962970\n",
      "Time: 51.5013189316\n",
      "Graph 181: 422 nodes\n",
      "Average loss at step 181100: 102.808134\n",
      "Average loss at step 181200: 98.640231\n",
      "Average loss at step 181300: 98.163265\n",
      "Average loss at step 181400: 98.311964\n",
      "Average loss at step 181500: 97.532467\n",
      "Average loss at step 181600: 98.708466\n",
      "Average loss at step 181700: 96.190915\n",
      "Average loss at step 181800: 96.098302\n",
      "Average loss at step 181900: 97.795203\n",
      "Average loss at step 182000: 95.273896\n",
      "Graph 182: 434 nodes\n",
      "Average loss at step 182100: 123.702135\n",
      "Average loss at step 182200: 103.981468\n",
      "Average loss at step 182300: 106.975715\n",
      "Average loss at step 182400: 109.204728\n",
      "Average loss at step 182500: 104.669468\n",
      "Average loss at step 182600: 109.940837\n",
      "Average loss at step 182700: 105.162358\n",
      "Average loss at step 182800: 106.953592\n",
      "Average loss at step 182900: 111.800994\n",
      "Average loss at step 183000: 107.040017\n",
      "Graph 183: 444 nodes\n",
      "Average loss at step 183100: 101.224793\n",
      "Average loss at step 183200: 97.110424\n",
      "Average loss at step 183300: 93.107151\n",
      "Average loss at step 183400: 96.439467\n",
      "Average loss at step 183500: 100.203828\n",
      "Average loss at step 183600: 94.299923\n",
      "Average loss at step 183700: 95.136047\n",
      "Average loss at step 183800: 97.905345\n",
      "Average loss at step 183900: 98.716297\n",
      "Average loss at step 184000: 96.656999\n",
      "Graph 184: 366 nodes\n",
      "Average loss at step 184100: 93.904025\n",
      "Average loss at step 184200: 90.175217\n",
      "Average loss at step 184300: 90.816229\n",
      "Average loss at step 184400: 88.058708\n",
      "Average loss at step 184500: 91.343534\n",
      "Average loss at step 184600: 93.939257\n",
      "Average loss at step 184700: 91.638577\n",
      "Average loss at step 184800: 91.943722\n",
      "Average loss at step 184900: 92.433058\n",
      "Average loss at step 185000: 91.734628\n",
      "Graph 185: 454 nodes\n",
      "Average loss at step 185100: 114.194885\n",
      "Average loss at step 185200: 112.951386\n",
      "Average loss at step 185300: 110.295172\n",
      "Average loss at step 185400: 107.568138\n",
      "Average loss at step 185500: 105.481823\n",
      "Average loss at step 185600: 109.071919\n",
      "Average loss at step 185700: 109.482091\n",
      "Average loss at step 185800: 107.137092\n",
      "Average loss at step 185900: 106.761850\n",
      "Average loss at step 186000: 104.345940\n",
      "Graph 186: 387 nodes\n",
      "Average loss at step 186100: 108.765510\n",
      "Average loss at step 186200: 110.225524\n",
      "Average loss at step 186300: 108.514781\n",
      "Average loss at step 186400: 106.368274\n",
      "Average loss at step 186500: 104.494230\n",
      "Average loss at step 186600: 100.111265\n",
      "Average loss at step 186700: 104.292804\n",
      "Average loss at step 186800: 102.806626\n",
      "Average loss at step 186900: 106.523924\n",
      "Average loss at step 187000: 103.733310\n",
      "Graph 187: 427 nodes\n",
      "Average loss at step 187100: 142.461006\n",
      "Average loss at step 187200: 121.538532\n",
      "Average loss at step 187300: 115.916638\n",
      "Average loss at step 187400: 116.125159\n",
      "Average loss at step 187500: 117.603025\n",
      "Average loss at step 187600: 117.799465\n",
      "Average loss at step 187700: 116.461309\n",
      "Average loss at step 187800: 117.352520\n",
      "Average loss at step 187900: 119.550322\n",
      "Average loss at step 188000: 117.135140\n",
      "Graph 188: 440 nodes\n",
      "Average loss at step 188100: 133.026677\n",
      "Average loss at step 188200: 121.147718\n",
      "Average loss at step 188300: 114.648997\n",
      "Average loss at step 188400: 117.438567\n",
      "Average loss at step 188500: 120.735201\n",
      "Average loss at step 188600: 117.544893\n",
      "Average loss at step 188700: 117.294775\n",
      "Average loss at step 188800: 118.013380\n",
      "Average loss at step 188900: 113.796545\n",
      "Average loss at step 189000: 117.179926\n",
      "Graph 189: 353 nodes\n",
      "Average loss at step 189100: 109.456251\n",
      "Average loss at step 189200: 105.079955\n",
      "Average loss at step 189300: 103.928835\n",
      "Average loss at step 189400: 104.223756\n",
      "Average loss at step 189500: 103.087019\n",
      "Average loss at step 189600: 102.479459\n",
      "Average loss at step 189700: 102.056230\n",
      "Average loss at step 189800: 104.789575\n",
      "Average loss at step 189900: 106.618889\n",
      "Average loss at step 190000: 103.885461\n",
      "Graph 190: 482 nodes\n",
      "Average loss at step 190100: 106.581034\n",
      "Average loss at step 190200: 101.402070\n",
      "Average loss at step 190300: 104.036869\n",
      "Average loss at step 190400: 97.391094\n",
      "Average loss at step 190500: 101.241562\n",
      "Average loss at step 190600: 98.660873\n",
      "Average loss at step 190700: 96.614192\n",
      "Average loss at step 190800: 97.874271\n",
      "Average loss at step 190900: 101.632934\n",
      "Average loss at step 191000: 102.035292\n",
      "Time: 52.6691710949\n",
      "Graph 191: 493 nodes\n",
      "Average loss at step 191100: 135.310565\n",
      "Average loss at step 191200: 111.535025\n",
      "Average loss at step 191300: 108.652208\n",
      "Average loss at step 191400: 109.925058\n",
      "Average loss at step 191500: 112.654180\n",
      "Average loss at step 191600: 109.962391\n",
      "Average loss at step 191700: 105.220664\n",
      "Average loss at step 191800: 109.902191\n",
      "Average loss at step 191900: 106.079549\n",
      "Average loss at step 192000: 109.931350\n",
      "Graph 192: 478 nodes\n",
      "Average loss at step 192100: 121.770595\n",
      "Average loss at step 192200: 117.305695\n",
      "Average loss at step 192300: 117.999617\n",
      "Average loss at step 192400: 114.975354\n",
      "Average loss at step 192500: 111.066001\n",
      "Average loss at step 192600: 118.853637\n",
      "Average loss at step 192700: 118.619255\n",
      "Average loss at step 192800: 114.354584\n",
      "Average loss at step 192900: 112.413157\n",
      "Average loss at step 193000: 109.723516\n",
      "Graph 193: 422 nodes\n",
      "Average loss at step 193100: 100.618073\n",
      "Average loss at step 193200: 90.557902\n",
      "Average loss at step 193300: 89.837322\n",
      "Average loss at step 193400: 88.234423\n",
      "Average loss at step 193500: 93.045221\n",
      "Average loss at step 193600: 91.211266\n",
      "Average loss at step 193700: 91.350178\n",
      "Average loss at step 193800: 92.312010\n",
      "Average loss at step 193900: 91.298977\n",
      "Average loss at step 194000: 89.139328\n",
      "Graph 194: 485 nodes\n",
      "Average loss at step 194100: 104.525796\n",
      "Average loss at step 194200: 93.883901\n",
      "Average loss at step 194300: 97.958451\n",
      "Average loss at step 194400: 103.273675\n",
      "Average loss at step 194500: 96.837699\n",
      "Average loss at step 194600: 93.742822\n",
      "Average loss at step 194700: 91.854757\n",
      "Average loss at step 194800: 94.642156\n",
      "Average loss at step 194900: 92.932261\n",
      "Average loss at step 195000: 94.032229\n",
      "Graph 195: 414 nodes\n",
      "Average loss at step 195100: 97.151295\n",
      "Average loss at step 195200: 92.065372\n",
      "Average loss at step 195300: 96.541420\n",
      "Average loss at step 195400: 91.689387\n",
      "Average loss at step 195500: 99.179974\n",
      "Average loss at step 195600: 93.414095\n",
      "Average loss at step 195700: 91.448241\n",
      "Average loss at step 195800: 95.501441\n",
      "Average loss at step 195900: 92.481516\n",
      "Average loss at step 196000: 93.024926\n",
      "Graph 196: 402 nodes\n",
      "Average loss at step 196100: 93.751644\n",
      "Average loss at step 196200: 96.914363\n",
      "Average loss at step 196300: 92.470772\n",
      "Average loss at step 196400: 99.650585\n",
      "Average loss at step 196500: 96.257962\n",
      "Average loss at step 196600: 95.381740\n",
      "Average loss at step 196700: 90.368012\n",
      "Average loss at step 196800: 93.223200\n",
      "Average loss at step 196900: 92.887546\n",
      "Average loss at step 197000: 95.853963\n",
      "Graph 197: 461 nodes\n",
      "Average loss at step 197100: 111.072288\n",
      "Average loss at step 197200: 106.641933\n",
      "Average loss at step 197300: 103.364485\n",
      "Average loss at step 197400: 103.297717\n",
      "Average loss at step 197500: 103.797884\n",
      "Average loss at step 197600: 102.568929\n",
      "Average loss at step 197700: 105.984474\n",
      "Average loss at step 197800: 104.570681\n",
      "Average loss at step 197900: 103.265905\n",
      "Average loss at step 198000: 106.873182\n",
      "Graph 198: 414 nodes\n",
      "Average loss at step 198100: 106.229271\n",
      "Average loss at step 198200: 103.043311\n",
      "Average loss at step 198300: 99.415411\n",
      "Average loss at step 198400: 100.768201\n",
      "Average loss at step 198500: 96.962322\n",
      "Average loss at step 198600: 98.712514\n",
      "Average loss at step 198700: 102.762646\n",
      "Average loss at step 198800: 95.547035\n",
      "Average loss at step 198900: 101.301509\n",
      "Average loss at step 199000: 101.447643\n",
      "Graph 199: 390 nodes\n",
      "Average loss at step 199100: 113.547629\n",
      "Average loss at step 199200: 101.582651\n",
      "Average loss at step 199300: 98.057240\n",
      "Average loss at step 199400: 100.308303\n",
      "Average loss at step 199500: 95.508782\n",
      "Average loss at step 199600: 101.256863\n",
      "Average loss at step 199700: 101.062872\n",
      "Average loss at step 199800: 99.813124\n",
      "Average loss at step 199900: 97.062304\n",
      "Average loss at step 200000: 99.805995\n",
      "Graph 200: 472 nodes\n",
      "Average loss at step 200100: 121.030512\n",
      "Average loss at step 200200: 109.523877\n",
      "Average loss at step 200300: 111.958199\n",
      "Average loss at step 200400: 114.657516\n",
      "Average loss at step 200500: 113.244399\n",
      "Average loss at step 200600: 115.762325\n",
      "Average loss at step 200700: 108.339731\n",
      "Average loss at step 200800: 108.370229\n",
      "Average loss at step 200900: 108.638272\n",
      "Average loss at step 201000: 110.372677\n",
      "Time: 53.5009160042\n",
      "Graph 201: 466 nodes\n",
      "Average loss at step 201100: 122.449557\n",
      "Average loss at step 201200: 115.828193\n",
      "Average loss at step 201300: 113.201660\n",
      "Average loss at step 201400: 114.468292\n",
      "Average loss at step 201500: 109.204741\n",
      "Average loss at step 201600: 111.721510\n",
      "Average loss at step 201700: 120.544619\n",
      "Average loss at step 201800: 117.553703\n",
      "Average loss at step 201900: 114.597087\n",
      "Average loss at step 202000: 109.988282\n",
      "Graph 202: 460 nodes\n",
      "Average loss at step 202100: 124.073567\n",
      "Average loss at step 202200: 117.950101\n",
      "Average loss at step 202300: 119.732009\n",
      "Average loss at step 202400: 118.018534\n",
      "Average loss at step 202500: 114.762262\n",
      "Average loss at step 202600: 113.043792\n",
      "Average loss at step 202700: 112.703610\n",
      "Average loss at step 202800: 115.123089\n",
      "Average loss at step 202900: 114.642237\n",
      "Average loss at step 203000: 110.515051\n",
      "Graph 203: 455 nodes\n",
      "Average loss at step 203100: 122.009522\n",
      "Average loss at step 203200: 101.185848\n",
      "Average loss at step 203300: 95.330252\n",
      "Average loss at step 203400: 97.492036\n",
      "Average loss at step 203500: 98.901069\n",
      "Average loss at step 203600: 94.769815\n",
      "Average loss at step 203700: 98.726001\n",
      "Average loss at step 203800: 92.770498\n",
      "Average loss at step 203900: 99.062371\n",
      "Average loss at step 204000: 96.699538\n",
      "Graph 204: 380 nodes\n",
      "Average loss at step 204100: 105.730092\n",
      "Average loss at step 204200: 91.644190\n",
      "Average loss at step 204300: 92.712029\n",
      "Average loss at step 204400: 91.388592\n",
      "Average loss at step 204500: 88.337424\n",
      "Average loss at step 204600: 88.880065\n",
      "Average loss at step 204700: 92.992471\n",
      "Average loss at step 204800: 93.046162\n",
      "Average loss at step 204900: 91.575381\n",
      "Average loss at step 205000: 92.866537\n",
      "Graph 205: 568 nodes\n",
      "Average loss at step 205100: 117.213048\n",
      "Average loss at step 205200: 115.267932\n",
      "Average loss at step 205300: 111.159840\n",
      "Average loss at step 205400: 109.165363\n",
      "Average loss at step 205500: 113.152181\n",
      "Average loss at step 205600: 104.429970\n",
      "Average loss at step 205700: 110.713317\n",
      "Average loss at step 205800: 111.818471\n",
      "Average loss at step 205900: 112.597055\n",
      "Average loss at step 206000: 113.557966\n",
      "Graph 206: 523 nodes\n",
      "Average loss at step 206100: 131.961674\n",
      "Average loss at step 206200: 115.521248\n",
      "Average loss at step 206300: 113.997840\n",
      "Average loss at step 206400: 111.391178\n",
      "Average loss at step 206500: 114.718111\n",
      "Average loss at step 206600: 113.893291\n",
      "Average loss at step 206700: 115.622935\n",
      "Average loss at step 206800: 110.872232\n",
      "Average loss at step 206900: 115.228544\n",
      "Average loss at step 207000: 115.846101\n",
      "Graph 207: 506 nodes\n",
      "Average loss at step 207100: 110.698992\n",
      "Average loss at step 207200: 104.862888\n",
      "Average loss at step 207300: 101.987974\n",
      "Average loss at step 207400: 105.697633\n",
      "Average loss at step 207500: 104.926678\n",
      "Average loss at step 207600: 107.521787\n",
      "Average loss at step 207700: 102.216889\n",
      "Average loss at step 207800: 107.505560\n",
      "Average loss at step 207900: 104.469700\n",
      "Average loss at step 208000: 105.756651\n",
      "Graph 208: 514 nodes\n",
      "Average loss at step 208100: 116.496238\n",
      "Average loss at step 208200: 101.313640\n",
      "Average loss at step 208300: 103.253806\n",
      "Average loss at step 208400: 102.694838\n",
      "Average loss at step 208500: 98.593968\n",
      "Average loss at step 208600: 96.515376\n",
      "Average loss at step 208700: 100.646362\n",
      "Average loss at step 208800: 100.536400\n",
      "Average loss at step 208900: 100.629660\n",
      "Average loss at step 209000: 105.610945\n",
      "Graph 209: 252 nodes\n",
      "Average loss at step 209100: 114.802305\n",
      "Average loss at step 209200: 104.505210\n",
      "Average loss at step 209300: 104.367693\n",
      "Average loss at step 209400: 108.614739\n",
      "Average loss at step 209500: 103.739540\n",
      "Average loss at step 209600: 102.057228\n",
      "Average loss at step 209700: 103.756343\n",
      "Average loss at step 209800: 105.656849\n",
      "Average loss at step 209900: 104.812821\n",
      "Average loss at step 210000: 100.692278\n",
      "Graph 210: 509 nodes\n",
      "Average loss at step 210100: 112.399602\n",
      "Average loss at step 210200: 106.777853\n",
      "Average loss at step 210300: 108.450048\n",
      "Average loss at step 210400: 108.039458\n",
      "Average loss at step 210500: 105.319284\n",
      "Average loss at step 210600: 110.372055\n",
      "Average loss at step 210700: 111.664704\n",
      "Average loss at step 210800: 109.171916\n",
      "Average loss at step 210900: 110.650098\n",
      "Average loss at step 211000: 104.265674\n",
      "Time: 52.7424049377\n",
      "Graph 211: 584 nodes\n",
      "Average loss at step 211100: 125.000081\n",
      "Average loss at step 211200: 117.129720\n",
      "Average loss at step 211300: 111.076746\n",
      "Average loss at step 211400: 115.626101\n",
      "Average loss at step 211500: 114.021331\n",
      "Average loss at step 211600: 111.202875\n",
      "Average loss at step 211700: 113.585039\n",
      "Average loss at step 211800: 110.841707\n",
      "Average loss at step 211900: 111.903592\n",
      "Average loss at step 212000: 110.196732\n",
      "Graph 212: 611 nodes\n",
      "Average loss at step 212100: 132.004918\n",
      "Average loss at step 212200: 106.422989\n",
      "Average loss at step 212300: 102.332341\n",
      "Average loss at step 212400: 105.171405\n",
      "Average loss at step 212500: 104.853832\n",
      "Average loss at step 212600: 101.563374\n",
      "Average loss at step 212700: 103.166214\n",
      "Average loss at step 212800: 103.527561\n",
      "Average loss at step 212900: 102.091828\n",
      "Average loss at step 213000: 103.978544\n",
      "Graph 213: 625 nodes\n",
      "Average loss at step 213100: 111.662993\n",
      "Average loss at step 213200: 104.091716\n",
      "Average loss at step 213300: 102.360225\n",
      "Average loss at step 213400: 98.961511\n",
      "Average loss at step 213500: 102.442900\n",
      "Average loss at step 213600: 101.412211\n",
      "Average loss at step 213700: 109.180050\n",
      "Average loss at step 213800: 103.181066\n",
      "Average loss at step 213900: 102.121278\n",
      "Average loss at step 214000: 99.175429\n",
      "Graph 214: 562 nodes\n",
      "Average loss at step 214100: 102.210687\n",
      "Average loss at step 214200: 100.895896\n",
      "Average loss at step 214300: 93.630458\n",
      "Average loss at step 214400: 94.826426\n",
      "Average loss at step 214500: 96.986257\n",
      "Average loss at step 214600: 91.781334\n",
      "Average loss at step 214700: 96.683928\n",
      "Average loss at step 214800: 93.261571\n",
      "Average loss at step 214900: 95.410129\n",
      "Average loss at step 215000: 94.122183\n",
      "Graph 215: 589 nodes\n",
      "Average loss at step 215100: 119.097637\n",
      "Average loss at step 215200: 106.063858\n",
      "Average loss at step 215300: 106.886093\n",
      "Average loss at step 215400: 103.597466\n",
      "Average loss at step 215500: 101.279090\n",
      "Average loss at step 215600: 103.477716\n",
      "Average loss at step 215700: 102.111003\n",
      "Average loss at step 215800: 103.528005\n",
      "Average loss at step 215900: 100.895686\n",
      "Average loss at step 216000: 110.296284\n",
      "Graph 216: 672 nodes\n",
      "Average loss at step 216100: 132.918890\n",
      "Average loss at step 216200: 127.547321\n",
      "Average loss at step 216300: 126.613343\n",
      "Average loss at step 216400: 122.639434\n",
      "Average loss at step 216500: 121.205368\n",
      "Average loss at step 216600: 120.900097\n",
      "Average loss at step 216700: 121.079382\n",
      "Average loss at step 216800: 118.151516\n",
      "Average loss at step 216900: 122.932006\n",
      "Average loss at step 217000: 120.872048\n",
      "Graph 217: 599 nodes\n",
      "Average loss at step 217100: 119.849789\n",
      "Average loss at step 217200: 112.980864\n",
      "Average loss at step 217300: 110.328475\n",
      "Average loss at step 217400: 109.351318\n",
      "Average loss at step 217500: 114.813007\n",
      "Average loss at step 217600: 108.897358\n",
      "Average loss at step 217700: 108.779260\n",
      "Average loss at step 217800: 111.536414\n",
      "Average loss at step 217900: 108.312875\n",
      "Average loss at step 218000: 110.983063\n",
      "Graph 218: 564 nodes\n",
      "Average loss at step 218100: 114.132073\n",
      "Average loss at step 218200: 109.340928\n",
      "Average loss at step 218300: 107.339123\n",
      "Average loss at step 218400: 108.175702\n",
      "Average loss at step 218500: 107.264304\n",
      "Average loss at step 218600: 105.541623\n",
      "Average loss at step 218700: 107.440747\n",
      "Average loss at step 218800: 106.232449\n",
      "Average loss at step 218900: 102.250336\n",
      "Average loss at step 219000: 107.288872\n",
      "Graph 219: 567 nodes\n",
      "Average loss at step 219100: 108.332081\n",
      "Average loss at step 219200: 97.268838\n",
      "Average loss at step 219300: 99.904636\n",
      "Average loss at step 219400: 98.515110\n",
      "Average loss at step 219500: 106.037388\n",
      "Average loss at step 219600: 101.917273\n",
      "Average loss at step 219700: 97.889923\n",
      "Average loss at step 219800: 98.381951\n",
      "Average loss at step 219900: 99.932953\n",
      "Average loss at step 220000: 97.824602\n",
      "Graph 220: 678 nodes\n",
      "Average loss at step 220100: 109.287088\n",
      "Average loss at step 220200: 109.876807\n",
      "Average loss at step 220300: 108.016755\n",
      "Average loss at step 220400: 108.767899\n",
      "Average loss at step 220500: 107.957380\n",
      "Average loss at step 220600: 107.710783\n",
      "Average loss at step 220700: 107.272619\n",
      "Average loss at step 220800: 107.363877\n",
      "Average loss at step 220900: 110.678956\n",
      "Average loss at step 221000: 104.459614\n",
      "Time: 53.0210812092\n",
      "Graph 221: 644 nodes\n",
      "Average loss at step 221100: 129.208361\n",
      "Average loss at step 221200: 123.742134\n",
      "Average loss at step 221300: 117.209371\n",
      "Average loss at step 221400: 127.565162\n",
      "Average loss at step 221500: 123.049475\n",
      "Average loss at step 221600: 122.447251\n",
      "Average loss at step 221700: 120.261724\n",
      "Average loss at step 221800: 123.501416\n",
      "Average loss at step 221900: 122.861632\n",
      "Average loss at step 222000: 125.249710\n",
      "Graph 222: 610 nodes\n",
      "Average loss at step 222100: 107.480294\n",
      "Average loss at step 222200: 100.749694\n",
      "Average loss at step 222300: 102.785925\n",
      "Average loss at step 222400: 101.256105\n",
      "Average loss at step 222500: 99.971192\n",
      "Average loss at step 222600: 98.693047\n",
      "Average loss at step 222700: 100.182165\n",
      "Average loss at step 222800: 99.043400\n",
      "Average loss at step 222900: 96.389379\n",
      "Average loss at step 223000: 100.798744\n",
      "Graph 223: 443 nodes\n",
      "Average loss at step 223100: 85.845072\n",
      "Average loss at step 223200: 79.490174\n",
      "Average loss at step 223300: 73.721585\n",
      "Average loss at step 223400: 79.904035\n",
      "Average loss at step 223500: 77.748327\n",
      "Average loss at step 223600: 72.423157\n",
      "Average loss at step 223700: 72.340175\n",
      "Average loss at step 223800: 73.000758\n",
      "Average loss at step 223900: 73.521690\n",
      "Average loss at step 224000: 76.429044\n",
      "Graph 224: 545 nodes\n",
      "Average loss at step 224100: 123.840041\n",
      "Average loss at step 224200: 108.329402\n",
      "Average loss at step 224300: 100.574176\n",
      "Average loss at step 224400: 96.223468\n",
      "Average loss at step 224500: 94.185637\n",
      "Average loss at step 224600: 97.936378\n",
      "Average loss at step 224700: 94.345996\n",
      "Average loss at step 224800: 95.768413\n",
      "Average loss at step 224900: 100.955771\n",
      "Average loss at step 225000: 97.225199\n",
      "Graph 225: 708 nodes\n",
      "Average loss at step 225100: 98.632696\n",
      "Average loss at step 225200: 91.544103\n",
      "Average loss at step 225300: 91.515985\n",
      "Average loss at step 225400: 89.888237\n",
      "Average loss at step 225500: 91.964413\n",
      "Average loss at step 225600: 89.874334\n",
      "Average loss at step 225700: 92.162075\n",
      "Average loss at step 225800: 89.836831\n",
      "Average loss at step 225900: 90.016387\n",
      "Average loss at step 226000: 88.867879\n",
      "Graph 226: 660 nodes\n",
      "Average loss at step 226100: 117.172196\n",
      "Average loss at step 226200: 109.593647\n",
      "Average loss at step 226300: 110.398613\n",
      "Average loss at step 226400: 106.078818\n",
      "Average loss at step 226500: 107.073470\n",
      "Average loss at step 226600: 110.104949\n",
      "Average loss at step 226700: 108.310504\n",
      "Average loss at step 226800: 104.891613\n",
      "Average loss at step 226900: 108.523449\n",
      "Average loss at step 227000: 105.600792\n",
      "Graph 227: 674 nodes\n",
      "Average loss at step 227100: 102.792702\n",
      "Average loss at step 227200: 99.902674\n",
      "Average loss at step 227300: 98.648847\n",
      "Average loss at step 227400: 96.972883\n",
      "Average loss at step 227500: 99.236353\n",
      "Average loss at step 227600: 96.833762\n",
      "Average loss at step 227700: 99.887366\n",
      "Average loss at step 227800: 98.026241\n",
      "Average loss at step 227900: 95.195593\n",
      "Average loss at step 228000: 99.946851\n",
      "Graph 228: 679 nodes\n",
      "Average loss at step 228100: 102.539362\n",
      "Average loss at step 228200: 96.001960\n",
      "Average loss at step 228300: 92.961758\n",
      "Average loss at step 228400: 101.138250\n",
      "Average loss at step 228500: 97.639783\n",
      "Average loss at step 228600: 94.191494\n",
      "Average loss at step 228700: 96.535913\n",
      "Average loss at step 228800: 98.039017\n",
      "Average loss at step 228900: 94.355605\n",
      "Average loss at step 229000: 92.386377\n",
      "Graph 229: 664 nodes\n",
      "Average loss at step 229100: 105.317973\n",
      "Average loss at step 229200: 104.311352\n",
      "Average loss at step 229300: 109.707488\n",
      "Average loss at step 229400: 103.155059\n",
      "Average loss at step 229500: 94.590734\n",
      "Average loss at step 229600: 100.017356\n",
      "Average loss at step 229700: 101.707129\n",
      "Average loss at step 229800: 99.572229\n",
      "Average loss at step 229900: 97.872025\n",
      "Average loss at step 230000: 97.140630\n",
      "Graph 230: 684 nodes\n",
      "Average loss at step 230100: 116.816519\n",
      "Average loss at step 230200: 113.728035\n",
      "Average loss at step 230300: 110.476285\n",
      "Average loss at step 230400: 109.739473\n",
      "Average loss at step 230500: 111.215695\n",
      "Average loss at step 230600: 109.021389\n",
      "Average loss at step 230700: 105.560258\n",
      "Average loss at step 230800: 109.652158\n",
      "Average loss at step 230900: 106.160737\n",
      "Average loss at step 231000: 109.956381\n",
      "Time: 56.5250668526\n",
      "Graph 231: 668 nodes\n",
      "Average loss at step 231100: 110.381336\n",
      "Average loss at step 231200: 97.847937\n",
      "Average loss at step 231300: 98.653997\n",
      "Average loss at step 231400: 96.640115\n",
      "Average loss at step 231500: 95.839300\n",
      "Average loss at step 231600: 96.218227\n",
      "Average loss at step 231700: 101.732597\n",
      "Average loss at step 231800: 93.435749\n",
      "Average loss at step 231900: 99.718327\n",
      "Average loss at step 232000: 102.245629\n",
      "Graph 232: 689 nodes\n",
      "Average loss at step 232100: 119.268334\n",
      "Average loss at step 232200: 104.376634\n",
      "Average loss at step 232300: 103.244057\n",
      "Average loss at step 232400: 105.573220\n",
      "Average loss at step 232500: 101.524532\n",
      "Average loss at step 232600: 102.200460\n",
      "Average loss at step 232700: 104.554388\n",
      "Average loss at step 232800: 103.120136\n",
      "Average loss at step 232900: 100.668920\n",
      "Average loss at step 233000: 102.401847\n",
      "Graph 233: 719 nodes\n",
      "Average loss at step 233100: 101.421371\n",
      "Average loss at step 233200: 93.869883\n",
      "Average loss at step 233300: 95.926812\n",
      "Average loss at step 233400: 96.483308\n",
      "Average loss at step 233500: 94.669364\n",
      "Average loss at step 233600: 92.421160\n",
      "Average loss at step 233700: 93.035267\n",
      "Average loss at step 233800: 95.175544\n",
      "Average loss at step 233900: 94.196189\n",
      "Average loss at step 234000: 94.860419\n",
      "Graph 234: 517 nodes\n",
      "Average loss at step 234100: 106.996306\n",
      "Average loss at step 234200: 100.359587\n",
      "Average loss at step 234300: 101.815724\n",
      "Average loss at step 234400: 100.109304\n",
      "Average loss at step 234500: 99.524588\n",
      "Average loss at step 234600: 98.759813\n",
      "Average loss at step 234700: 100.646592\n",
      "Average loss at step 234800: 97.669039\n",
      "Average loss at step 234900: 98.870210\n",
      "Average loss at step 235000: 98.082433\n",
      "Graph 235: 714 nodes\n",
      "Average loss at step 235100: 140.234877\n",
      "Average loss at step 235200: 130.303235\n",
      "Average loss at step 235300: 124.261570\n",
      "Average loss at step 235400: 122.989561\n",
      "Average loss at step 235500: 125.948009\n",
      "Average loss at step 235600: 125.879360\n",
      "Average loss at step 235700: 127.519861\n",
      "Average loss at step 235800: 122.516353\n",
      "Average loss at step 235900: 122.426510\n",
      "Average loss at step 236000: 123.453189\n",
      "Graph 236: 749 nodes\n",
      "Average loss at step 236100: 133.464393\n",
      "Average loss at step 236200: 117.084586\n",
      "Average loss at step 236300: 117.377488\n",
      "Average loss at step 236400: 115.072755\n",
      "Average loss at step 236500: 115.016511\n",
      "Average loss at step 236600: 116.917328\n",
      "Average loss at step 236700: 112.795840\n",
      "Average loss at step 236800: 114.462705\n",
      "Average loss at step 236900: 113.636632\n",
      "Average loss at step 237000: 113.674176\n",
      "Graph 237: 729 nodes\n",
      "Average loss at step 237100: 145.953581\n",
      "Average loss at step 237200: 133.278149\n",
      "Average loss at step 237300: 131.553781\n",
      "Average loss at step 237400: 129.208880\n",
      "Average loss at step 237500: 132.102223\n",
      "Average loss at step 237600: 130.291722\n",
      "Average loss at step 237700: 129.817879\n",
      "Average loss at step 237800: 130.853711\n",
      "Average loss at step 237900: 132.511669\n",
      "Average loss at step 238000: 128.810906\n",
      "Graph 238: 747 nodes\n",
      "Average loss at step 238100: 119.497573\n",
      "Average loss at step 238200: 114.706073\n",
      "Average loss at step 238300: 114.308455\n",
      "Average loss at step 238400: 115.775139\n",
      "Average loss at step 238500: 113.650427\n",
      "Average loss at step 238600: 114.005012\n",
      "Average loss at step 238700: 112.505615\n",
      "Average loss at step 238800: 111.371932\n",
      "Average loss at step 238900: 116.419807\n",
      "Average loss at step 239000: 110.517099\n",
      "Graph 239: 608 nodes\n",
      "Average loss at step 239100: 108.535175\n",
      "Average loss at step 239200: 103.101533\n",
      "Average loss at step 239300: 102.632235\n",
      "Average loss at step 239400: 104.785808\n",
      "Average loss at step 239500: 103.257690\n",
      "Average loss at step 239600: 100.068472\n",
      "Average loss at step 239700: 101.336534\n",
      "Average loss at step 239800: 104.222382\n",
      "Average loss at step 239900: 103.077967\n",
      "Average loss at step 240000: 101.908712\n",
      "Graph 240: 106 nodes\n",
      "Average loss at step 240100: 65.702025\n",
      "Average loss at step 240200: 41.037690\n",
      "Average loss at step 240300: 37.408740\n",
      "Average loss at step 240400: 33.176935\n",
      "Average loss at step 240500: 36.012787\n",
      "Average loss at step 240600: 34.104899\n",
      "Average loss at step 240700: 32.946116\n",
      "Average loss at step 240800: 34.448007\n",
      "Average loss at step 240900: 36.013185\n",
      "Average loss at step 241000: 34.557876\n",
      "Time: 43.4797558784\n",
      "Graph 241: 798 nodes\n",
      "Average loss at step 241100: 128.873158\n",
      "Average loss at step 241200: 126.225788\n",
      "Average loss at step 241300: 122.934133\n",
      "Average loss at step 241400: 120.670062\n",
      "Average loss at step 241500: 121.976345\n",
      "Average loss at step 241600: 121.616334\n",
      "Average loss at step 241700: 121.340696\n",
      "Average loss at step 241800: 124.500338\n",
      "Average loss at step 241900: 123.567523\n",
      "Average loss at step 242000: 121.961531\n",
      "Graph 242: 802 nodes\n",
      "Average loss at step 242100: 111.665373\n",
      "Average loss at step 242200: 102.010580\n",
      "Average loss at step 242300: 111.646829\n",
      "Average loss at step 242400: 106.246711\n",
      "Average loss at step 242500: 106.472053\n",
      "Average loss at step 242600: 107.633912\n",
      "Average loss at step 242700: 107.066207\n",
      "Average loss at step 242800: 107.139011\n",
      "Average loss at step 242900: 105.383044\n",
      "Average loss at step 243000: 104.086415\n",
      "Graph 243: 878 nodes\n",
      "Average loss at step 243100: 123.798448\n",
      "Average loss at step 243200: 119.485197\n",
      "Average loss at step 243300: 117.959777\n",
      "Average loss at step 243400: 113.725146\n",
      "Average loss at step 243500: 111.856309\n",
      "Average loss at step 243600: 116.724954\n",
      "Average loss at step 243700: 113.599260\n",
      "Average loss at step 243800: 116.540550\n",
      "Average loss at step 243900: 113.212367\n",
      "Average loss at step 244000: 114.579121\n",
      "Graph 244: 795 nodes\n",
      "Average loss at step 244100: 107.224673\n",
      "Average loss at step 244200: 97.170815\n",
      "Average loss at step 244300: 99.992415\n",
      "Average loss at step 244400: 103.128027\n",
      "Average loss at step 244500: 100.578930\n",
      "Average loss at step 244600: 98.254679\n",
      "Average loss at step 244700: 101.111793\n",
      "Average loss at step 244800: 97.492135\n",
      "Average loss at step 244900: 99.975364\n",
      "Average loss at step 245000: 95.675785\n",
      "Graph 245: 879 nodes\n",
      "Average loss at step 245100: 111.785641\n",
      "Average loss at step 245200: 112.625625\n",
      "Average loss at step 245300: 113.387528\n",
      "Average loss at step 245400: 110.045704\n",
      "Average loss at step 245500: 109.205276\n",
      "Average loss at step 245600: 114.856937\n",
      "Average loss at step 245700: 111.482880\n",
      "Average loss at step 245800: 108.738967\n",
      "Average loss at step 245900: 112.580416\n",
      "Average loss at step 246000: 107.504968\n",
      "Graph 246: 925 nodes\n",
      "Average loss at step 246100: 125.107046\n",
      "Average loss at step 246200: 121.427148\n",
      "Average loss at step 246300: 116.635952\n",
      "Average loss at step 246400: 121.069810\n",
      "Average loss at step 246500: 123.407209\n",
      "Average loss at step 246600: 120.791552\n",
      "Average loss at step 246700: 118.340664\n",
      "Average loss at step 246800: 117.236380\n",
      "Average loss at step 246900: 119.273027\n",
      "Average loss at step 247000: 115.007614\n",
      "Graph 247: 947 nodes\n",
      "Average loss at step 247100: 121.331950\n",
      "Average loss at step 247200: 113.223092\n",
      "Average loss at step 247300: 114.758587\n",
      "Average loss at step 247400: 113.679431\n",
      "Average loss at step 247500: 110.275972\n",
      "Average loss at step 247600: 110.158847\n",
      "Average loss at step 247700: 109.937723\n",
      "Average loss at step 247800: 112.346033\n",
      "Average loss at step 247900: 116.694063\n",
      "Average loss at step 248000: 113.848830\n",
      "Graph 248: 945 nodes\n",
      "Average loss at step 248100: 161.039067\n",
      "Average loss at step 248200: 124.615767\n",
      "Average loss at step 248300: 123.269855\n",
      "Average loss at step 248400: 121.223290\n",
      "Average loss at step 248500: 123.717889\n",
      "Average loss at step 248600: 121.689829\n",
      "Average loss at step 248700: 121.652532\n",
      "Average loss at step 248800: 124.328094\n",
      "Average loss at step 248900: 125.440192\n",
      "Average loss at step 249000: 121.215670\n",
      "Graph 249: 670 nodes\n",
      "Average loss at step 249100: 108.296670\n",
      "Average loss at step 249200: 101.521387\n",
      "Average loss at step 249300: 101.233145\n",
      "Average loss at step 249400: 98.874978\n",
      "Average loss at step 249500: 100.575252\n",
      "Average loss at step 249600: 99.283790\n",
      "Average loss at step 249700: 95.055563\n",
      "Average loss at step 249800: 97.227726\n",
      "Average loss at step 249900: 94.099354\n",
      "Average loss at step 250000: 100.804110\n",
      "Graph 250: 387 nodes\n",
      "Average loss at step 250100: 78.846876\n",
      "Average loss at step 250200: 78.840326\n",
      "Average loss at step 250300: 75.394686\n",
      "Average loss at step 250400: 77.737951\n",
      "Average loss at step 250500: 72.087623\n",
      "Average loss at step 250600: 73.537071\n",
      "Average loss at step 250700: 74.929460\n",
      "Average loss at step 250800: 77.631369\n",
      "Average loss at step 250900: 73.542878\n",
      "Average loss at step 251000: 74.848872\n",
      "Time: 56.8317210674\n",
      "Graph 251: 294 nodes\n",
      "Average loss at step 251100: 71.146368\n",
      "Average loss at step 251200: 73.095813\n",
      "Average loss at step 251300: 72.049741\n",
      "Average loss at step 251400: 67.578951\n",
      "Average loss at step 251500: 68.237421\n",
      "Average loss at step 251600: 71.723041\n",
      "Average loss at step 251700: 69.588652\n",
      "Average loss at step 251800: 71.456180\n",
      "Average loss at step 251900: 69.704059\n",
      "Average loss at step 252000: 68.395184\n",
      "Graph 252: 294 nodes\n",
      "Average loss at step 252100: 90.449910\n",
      "Average loss at step 252200: 84.330728\n",
      "Average loss at step 252300: 90.588636\n",
      "Average loss at step 252400: 90.487987\n",
      "Average loss at step 252500: 87.318274\n",
      "Average loss at step 252600: 91.509312\n",
      "Average loss at step 252700: 86.009607\n",
      "Average loss at step 252800: 85.659591\n",
      "Average loss at step 252900: 90.977918\n",
      "Average loss at step 253000: 86.322160\n",
      "Graph 253: 289 nodes\n",
      "Average loss at step 253100: 68.230355\n",
      "Average loss at step 253200: 62.740819\n",
      "Average loss at step 253300: 64.544721\n",
      "Average loss at step 253400: 64.229356\n",
      "Average loss at step 253500: 59.612224\n",
      "Average loss at step 253600: 65.506205\n",
      "Average loss at step 253700: 61.813963\n",
      "Average loss at step 253800: 62.101896\n",
      "Average loss at step 253900: 63.080588\n",
      "Average loss at step 254000: 61.170498\n",
      "Graph 254: 269 nodes\n",
      "Average loss at step 254100: 60.282466\n",
      "Average loss at step 254200: 57.508883\n",
      "Average loss at step 254300: 53.753790\n",
      "Average loss at step 254400: 55.467717\n",
      "Average loss at step 254500: 57.898663\n",
      "Average loss at step 254600: 58.444002\n",
      "Average loss at step 254700: 59.843795\n",
      "Average loss at step 254800: 55.746892\n",
      "Average loss at step 254900: 58.052074\n",
      "Average loss at step 255000: 54.919104\n",
      "Graph 255: 338 nodes\n",
      "Average loss at step 255100: 116.360710\n",
      "Average loss at step 255200: 98.099468\n",
      "Average loss at step 255300: 95.230242\n",
      "Average loss at step 255400: 90.143960\n",
      "Average loss at step 255500: 95.258745\n",
      "Average loss at step 255600: 93.561103\n",
      "Average loss at step 255700: 93.762720\n",
      "Average loss at step 255800: 94.440427\n",
      "Average loss at step 255900: 91.347234\n",
      "Average loss at step 256000: 90.467138\n",
      "Graph 256: 306 nodes\n",
      "Average loss at step 256100: 110.910933\n",
      "Average loss at step 256200: 96.892885\n",
      "Average loss at step 256300: 93.292621\n",
      "Average loss at step 256400: 96.616176\n",
      "Average loss at step 256500: 91.385128\n",
      "Average loss at step 256600: 93.976390\n",
      "Average loss at step 256700: 96.460801\n",
      "Average loss at step 256800: 93.662689\n",
      "Average loss at step 256900: 92.667744\n",
      "Average loss at step 257000: 94.948233\n",
      "Graph 257: 322 nodes\n",
      "Average loss at step 257100: 84.101679\n",
      "Average loss at step 257200: 77.976488\n",
      "Average loss at step 257300: 81.462575\n",
      "Average loss at step 257400: 78.129699\n",
      "Average loss at step 257500: 78.177894\n",
      "Average loss at step 257600: 76.783134\n",
      "Average loss at step 257700: 76.493965\n",
      "Average loss at step 257800: 77.828483\n",
      "Average loss at step 257900: 76.092735\n",
      "Average loss at step 258000: 77.602670\n",
      "Graph 258: 342 nodes\n",
      "Average loss at step 258100: 109.727965\n",
      "Average loss at step 258200: 77.224433\n",
      "Average loss at step 258300: 78.611142\n",
      "Average loss at step 258400: 72.374824\n",
      "Average loss at step 258500: 73.065731\n",
      "Average loss at step 258600: 74.994574\n",
      "Average loss at step 258700: 72.451794\n",
      "Average loss at step 258800: 71.492546\n",
      "Average loss at step 258900: 71.692170\n",
      "Average loss at step 259000: 73.976016\n",
      "Graph 259: 251 nodes\n",
      "Average loss at step 259100: 73.579863\n",
      "Average loss at step 259200: 66.130241\n",
      "Average loss at step 259300: 67.149081\n",
      "Average loss at step 259400: 66.881059\n",
      "Average loss at step 259500: 69.399089\n",
      "Average loss at step 259600: 67.739607\n",
      "Average loss at step 259700: 67.897780\n",
      "Average loss at step 259800: 68.768251\n",
      "Average loss at step 259900: 70.082068\n",
      "Average loss at step 260000: 68.614154\n",
      "Graph 260: 326 nodes\n",
      "Average loss at step 260100: 93.303479\n",
      "Average loss at step 260200: 84.264139\n",
      "Average loss at step 260300: 92.463275\n",
      "Average loss at step 260400: 87.504963\n",
      "Average loss at step 260500: 88.001089\n",
      "Average loss at step 260600: 85.817584\n",
      "Average loss at step 260700: 86.854011\n",
      "Average loss at step 260800: 84.914653\n",
      "Average loss at step 260900: 88.867816\n",
      "Average loss at step 261000: 89.038005\n",
      "Time: 47.9259231091\n",
      "Graph 261: 589 nodes\n",
      "Average loss at step 261100: 124.305264\n",
      "Average loss at step 261200: 88.732106\n",
      "Average loss at step 261300: 89.111342\n",
      "Average loss at step 261400: 85.301350\n",
      "Average loss at step 261500: 86.139262\n",
      "Average loss at step 261600: 87.851318\n",
      "Average loss at step 261700: 80.358686\n",
      "Average loss at step 261800: 88.227615\n",
      "Average loss at step 261900: 86.007096\n",
      "Average loss at step 262000: 91.119841\n",
      "Graph 262: 617 nodes\n",
      "Average loss at step 262100: 58.678700\n",
      "Average loss at step 262200: 57.124398\n",
      "Average loss at step 262300: 53.074610\n",
      "Average loss at step 262400: 56.342843\n",
      "Average loss at step 262500: 51.417831\n",
      "Average loss at step 262600: 56.266464\n",
      "Average loss at step 262700: 53.885106\n",
      "Average loss at step 262800: 52.299216\n",
      "Average loss at step 262900: 53.695107\n",
      "Average loss at step 263000: 52.920225\n",
      "Graph 263: 290 nodes\n",
      "Average loss at step 263100: 80.972875\n",
      "Average loss at step 263200: 77.030877\n",
      "Average loss at step 263300: 80.069028\n",
      "Average loss at step 263400: 76.302902\n",
      "Average loss at step 263500: 76.253808\n",
      "Average loss at step 263600: 80.572716\n",
      "Average loss at step 263700: 74.196926\n",
      "Average loss at step 263800: 77.372964\n",
      "Average loss at step 263900: 76.654530\n",
      "Average loss at step 264000: 80.949773\n",
      "Graph 264: 272 nodes\n",
      "Average loss at step 264100: 77.105505\n",
      "Average loss at step 264200: 66.322760\n",
      "Average loss at step 264300: 63.406079\n",
      "Average loss at step 264400: 65.596125\n",
      "Average loss at step 264500: 65.320133\n",
      "Average loss at step 264600: 63.187491\n",
      "Average loss at step 264700: 63.931227\n",
      "Average loss at step 264800: 65.904168\n",
      "Average loss at step 264900: 67.689427\n",
      "Average loss at step 265000: 63.951587\n",
      "Graph 265: 326 nodes\n",
      "Average loss at step 265100: 97.746220\n",
      "Average loss at step 265200: 91.442839\n",
      "Average loss at step 265300: 92.852716\n",
      "Average loss at step 265400: 93.518032\n",
      "Average loss at step 265500: 91.843748\n",
      "Average loss at step 265600: 93.407873\n",
      "Average loss at step 265700: 91.130696\n",
      "Average loss at step 265800: 92.456198\n",
      "Average loss at step 265900: 92.964637\n",
      "Average loss at step 266000: 90.633355\n",
      "Graph 266: 272 nodes\n",
      "Average loss at step 266100: 111.383463\n",
      "Average loss at step 266200: 108.855480\n",
      "Average loss at step 266300: 108.041497\n",
      "Average loss at step 266400: 108.877986\n",
      "Average loss at step 266500: 110.173156\n",
      "Average loss at step 266600: 108.367570\n",
      "Average loss at step 266700: 105.946426\n",
      "Average loss at step 266800: 113.153684\n",
      "Average loss at step 266900: 108.701992\n",
      "Average loss at step 267000: 108.974873\n",
      "Graph 267: 55 nodes\n",
      "Average loss at step 267100: 31.972918\n",
      "Average loss at step 267200: 29.921983\n",
      "Average loss at step 267300: 27.024336\n",
      "Average loss at step 267400: 29.466689\n",
      "Average loss at step 267500: 28.399636\n",
      "Average loss at step 267600: 28.900552\n",
      "Average loss at step 267700: 27.918118\n",
      "Average loss at step 267800: 26.280033\n",
      "Average loss at step 267900: 26.516512\n",
      "Average loss at step 268000: 26.090663\n",
      "Graph 268: 305 nodes\n",
      "Average loss at step 268100: 91.923819\n",
      "Average loss at step 268200: 87.929114\n",
      "Average loss at step 268300: 92.672838\n",
      "Average loss at step 268400: 88.831578\n",
      "Average loss at step 268500: 90.111587\n",
      "Average loss at step 268600: 88.479998\n",
      "Average loss at step 268700: 84.242479\n",
      "Average loss at step 268800: 84.346451\n",
      "Average loss at step 268900: 86.226924\n",
      "Average loss at step 269000: 84.291064\n",
      "Graph 269: 229 nodes\n",
      "Average loss at step 269100: 119.107164\n",
      "Average loss at step 269200: 96.190632\n",
      "Average loss at step 269300: 92.970049\n",
      "Average loss at step 269400: 96.736036\n",
      "Average loss at step 269500: 96.152843\n",
      "Average loss at step 269600: 96.509234\n",
      "Average loss at step 269700: 95.583621\n",
      "Average loss at step 269800: 95.197530\n",
      "Average loss at step 269900: 95.982066\n",
      "Average loss at step 270000: 94.635328\n",
      "Graph 270: 335 nodes\n",
      "Average loss at step 270100: 99.815739\n",
      "Average loss at step 270200: 86.221654\n",
      "Average loss at step 270300: 84.456394\n",
      "Average loss at step 270400: 85.175380\n",
      "Average loss at step 270500: 84.418813\n",
      "Average loss at step 270600: 81.321913\n",
      "Average loss at step 270700: 79.943422\n",
      "Average loss at step 270800: 81.426948\n",
      "Average loss at step 270900: 79.853300\n",
      "Average loss at step 271000: 85.418089\n",
      "Time: 51.8061161041\n",
      "Graph 271: 319 nodes\n",
      "Average loss at step 271100: 81.581838\n",
      "Average loss at step 271200: 79.660169\n",
      "Average loss at step 271300: 82.516410\n",
      "Average loss at step 271400: 81.068603\n",
      "Average loss at step 271500: 76.598192\n",
      "Average loss at step 271600: 79.398731\n",
      "Average loss at step 271700: 80.924082\n",
      "Average loss at step 271800: 78.174598\n",
      "Average loss at step 271900: 76.835943\n",
      "Average loss at step 272000: 78.721503\n",
      "Graph 272: 338 nodes\n",
      "Average loss at step 272100: 117.399227\n",
      "Average loss at step 272200: 109.037528\n",
      "Average loss at step 272300: 108.394496\n",
      "Average loss at step 272400: 108.482079\n",
      "Average loss at step 272500: 108.477493\n",
      "Average loss at step 272600: 103.434533\n",
      "Average loss at step 272700: 106.394758\n",
      "Average loss at step 272800: 107.607157\n",
      "Average loss at step 272900: 105.454313\n",
      "Average loss at step 273000: 108.726890\n",
      "Graph 273: 320 nodes\n",
      "Average loss at step 273100: 123.055230\n",
      "Average loss at step 273200: 101.117196\n",
      "Average loss at step 273300: 102.061634\n",
      "Average loss at step 273400: 104.370199\n",
      "Average loss at step 273500: 100.511002\n",
      "Average loss at step 273600: 102.611363\n",
      "Average loss at step 273700: 102.663707\n",
      "Average loss at step 273800: 102.348114\n",
      "Average loss at step 273900: 98.764494\n",
      "Average loss at step 274000: 102.745438\n",
      "Graph 274: 317 nodes\n",
      "Average loss at step 274100: 101.346536\n",
      "Average loss at step 274200: 95.637489\n",
      "Average loss at step 274300: 95.924836\n",
      "Average loss at step 274400: 93.559594\n",
      "Average loss at step 274500: 95.904096\n",
      "Average loss at step 274600: 96.222963\n",
      "Average loss at step 274700: 94.022240\n",
      "Average loss at step 274800: 93.114757\n",
      "Average loss at step 274900: 94.977183\n",
      "Average loss at step 275000: 97.592850\n",
      "Graph 275: 345 nodes\n",
      "Average loss at step 275100: 103.235494\n",
      "Average loss at step 275200: 89.999181\n",
      "Average loss at step 275300: 85.563224\n",
      "Average loss at step 275400: 87.548519\n",
      "Average loss at step 275500: 89.420564\n",
      "Average loss at step 275600: 88.804217\n",
      "Average loss at step 275700: 91.213036\n",
      "Average loss at step 275800: 85.512073\n",
      "Average loss at step 275900: 92.040263\n",
      "Average loss at step 276000: 87.363294\n",
      "Graph 276: 353 nodes\n",
      "Average loss at step 276100: 93.536374\n",
      "Average loss at step 276200: 86.492901\n",
      "Average loss at step 276300: 82.192627\n",
      "Average loss at step 276400: 82.084488\n",
      "Average loss at step 276500: 83.569061\n",
      "Average loss at step 276600: 86.599779\n",
      "Average loss at step 276700: 82.868167\n",
      "Average loss at step 276800: 83.928937\n",
      "Average loss at step 276900: 85.235072\n",
      "Average loss at step 277000: 84.024654\n",
      "Graph 277: 343 nodes\n",
      "Average loss at step 277100: 85.204492\n",
      "Average loss at step 277200: 81.963545\n",
      "Average loss at step 277300: 82.663560\n",
      "Average loss at step 277400: 76.228256\n",
      "Average loss at step 277500: 80.418193\n",
      "Average loss at step 277600: 80.175454\n",
      "Average loss at step 277700: 80.021604\n",
      "Average loss at step 277800: 77.668202\n",
      "Average loss at step 277900: 78.442583\n",
      "Average loss at step 278000: 77.171843\n",
      "Graph 278: 349 nodes\n",
      "Average loss at step 278100: 123.970570\n",
      "Average loss at step 278200: 113.256591\n",
      "Average loss at step 278300: 112.052844\n",
      "Average loss at step 278400: 112.393514\n",
      "Average loss at step 278500: 114.798428\n",
      "Average loss at step 278600: 111.884421\n",
      "Average loss at step 278700: 115.106571\n",
      "Average loss at step 278800: 114.072495\n",
      "Average loss at step 278900: 112.715870\n",
      "Average loss at step 279000: 109.540597\n",
      "Graph 279: 320 nodes\n",
      "Average loss at step 279100: 85.859806\n",
      "Average loss at step 279200: 79.816122\n",
      "Average loss at step 279300: 80.508531\n",
      "Average loss at step 279400: 82.677206\n",
      "Average loss at step 279500: 81.734975\n",
      "Average loss at step 279600: 79.811832\n",
      "Average loss at step 279700: 78.205217\n",
      "Average loss at step 279800: 80.054731\n",
      "Average loss at step 279900: 79.164319\n",
      "Average loss at step 280000: 79.939119\n",
      "Graph 280: 354 nodes\n",
      "Average loss at step 280100: 109.313478\n",
      "Average loss at step 280200: 97.702718\n",
      "Average loss at step 280300: 96.533006\n",
      "Average loss at step 280400: 95.475397\n",
      "Average loss at step 280500: 98.488348\n",
      "Average loss at step 280600: 96.784454\n",
      "Average loss at step 280700: 96.732890\n",
      "Average loss at step 280800: 95.523399\n",
      "Average loss at step 280900: 93.808617\n",
      "Average loss at step 281000: 94.315745\n",
      "Time: 52.2372601032\n",
      "Graph 281: 342 nodes\n",
      "Average loss at step 281100: 95.457146\n",
      "Average loss at step 281200: 87.869639\n",
      "Average loss at step 281300: 87.507467\n",
      "Average loss at step 281400: 89.467066\n",
      "Average loss at step 281500: 88.101230\n",
      "Average loss at step 281600: 94.744385\n",
      "Average loss at step 281700: 86.444333\n",
      "Average loss at step 281800: 87.880276\n",
      "Average loss at step 281900: 92.012533\n",
      "Average loss at step 282000: 86.539673\n",
      "Graph 282: 332 nodes\n",
      "Average loss at step 282100: 88.642659\n",
      "Average loss at step 282200: 87.214798\n",
      "Average loss at step 282300: 92.752888\n",
      "Average loss at step 282400: 86.457663\n",
      "Average loss at step 282500: 84.677472\n",
      "Average loss at step 282600: 87.727337\n",
      "Average loss at step 282700: 84.698394\n",
      "Average loss at step 282800: 88.384998\n",
      "Average loss at step 282900: 88.207293\n",
      "Average loss at step 283000: 86.961672\n",
      "Graph 283: 458 nodes\n",
      "Average loss at step 283100: 95.522721\n",
      "Average loss at step 283200: 95.037301\n",
      "Average loss at step 283300: 87.523146\n",
      "Average loss at step 283400: 93.113699\n",
      "Average loss at step 283500: 89.332125\n",
      "Average loss at step 283600: 86.676960\n",
      "Average loss at step 283700: 82.431959\n",
      "Average loss at step 283800: 87.392678\n",
      "Average loss at step 283900: 87.047199\n",
      "Average loss at step 284000: 90.781246\n",
      "Graph 284: 351 nodes\n",
      "Average loss at step 284100: 96.731084\n",
      "Average loss at step 284200: 93.514100\n",
      "Average loss at step 284300: 88.337342\n",
      "Average loss at step 284400: 92.195635\n",
      "Average loss at step 284500: 90.352025\n",
      "Average loss at step 284600: 91.412648\n",
      "Average loss at step 284700: 91.231000\n",
      "Average loss at step 284800: 93.868838\n",
      "Average loss at step 284900: 89.802723\n",
      "Average loss at step 285000: 86.309146\n",
      "Graph 285: 453 nodes\n",
      "Average loss at step 285100: 116.105716\n",
      "Average loss at step 285200: 106.360011\n",
      "Average loss at step 285300: 107.322588\n",
      "Average loss at step 285400: 106.980151\n",
      "Average loss at step 285500: 105.015324\n",
      "Average loss at step 285600: 111.366960\n",
      "Average loss at step 285700: 102.770065\n",
      "Average loss at step 285800: 109.532830\n",
      "Average loss at step 285900: 104.464589\n",
      "Average loss at step 286000: 105.092273\n",
      "Graph 286: 382 nodes\n",
      "Average loss at step 286100: 105.153991\n",
      "Average loss at step 286200: 95.041752\n",
      "Average loss at step 286300: 95.897550\n",
      "Average loss at step 286400: 92.656180\n",
      "Average loss at step 286500: 94.804076\n",
      "Average loss at step 286600: 94.731424\n",
      "Average loss at step 286700: 92.376410\n",
      "Average loss at step 286800: 92.148869\n",
      "Average loss at step 286900: 93.040199\n",
      "Average loss at step 287000: 91.796891\n",
      "Graph 287: 369 nodes\n",
      "Average loss at step 287100: 124.361749\n",
      "Average loss at step 287200: 108.127283\n",
      "Average loss at step 287300: 111.675596\n",
      "Average loss at step 287400: 111.331471\n",
      "Average loss at step 287500: 109.432118\n",
      "Average loss at step 287600: 105.766787\n",
      "Average loss at step 287700: 109.301748\n",
      "Average loss at step 287800: 108.774773\n",
      "Average loss at step 287900: 110.755541\n",
      "Average loss at step 288000: 109.331706\n",
      "Graph 288: 326 nodes\n",
      "Average loss at step 288100: 100.434289\n",
      "Average loss at step 288200: 93.090628\n",
      "Average loss at step 288300: 97.366099\n",
      "Average loss at step 288400: 92.689814\n",
      "Average loss at step 288500: 97.461015\n",
      "Average loss at step 288600: 93.602837\n",
      "Average loss at step 288700: 93.321492\n",
      "Average loss at step 288800: 94.141624\n",
      "Average loss at step 288900: 95.618752\n",
      "Average loss at step 289000: 93.190508\n",
      "Graph 289: 286 nodes\n",
      "Average loss at step 289100: 89.158503\n",
      "Average loss at step 289200: 83.840701\n",
      "Average loss at step 289300: 82.691496\n",
      "Average loss at step 289400: 81.716583\n",
      "Average loss at step 289500: 81.716723\n",
      "Average loss at step 289600: 83.168606\n",
      "Average loss at step 289700: 82.389735\n",
      "Average loss at step 289800: 78.094742\n",
      "Average loss at step 289900: 83.784657\n",
      "Average loss at step 290000: 81.024018\n",
      "Graph 290: 351 nodes\n",
      "Average loss at step 290100: 100.233895\n",
      "Average loss at step 290200: 94.516975\n",
      "Average loss at step 290300: 90.224542\n",
      "Average loss at step 290400: 92.851739\n",
      "Average loss at step 290500: 88.474821\n",
      "Average loss at step 290600: 95.775452\n",
      "Average loss at step 290700: 94.059282\n",
      "Average loss at step 290800: 93.957919\n",
      "Average loss at step 290900: 97.249050\n",
      "Average loss at step 291000: 95.811032\n",
      "Time: 49.6051061153\n",
      "Graph 291: 361 nodes\n",
      "Average loss at step 291100: 115.778374\n",
      "Average loss at step 291200: 103.106597\n",
      "Average loss at step 291300: 103.105350\n",
      "Average loss at step 291400: 96.931836\n",
      "Average loss at step 291500: 98.678316\n",
      "Average loss at step 291600: 104.336626\n",
      "Average loss at step 291700: 100.299408\n",
      "Average loss at step 291800: 97.297189\n",
      "Average loss at step 291900: 97.952441\n",
      "Average loss at step 292000: 94.940673\n",
      "Graph 292: 309 nodes\n",
      "Average loss at step 292100: 96.362705\n",
      "Average loss at step 292200: 90.449817\n",
      "Average loss at step 292300: 85.805661\n",
      "Average loss at step 292400: 86.213384\n",
      "Average loss at step 292500: 87.941188\n",
      "Average loss at step 292600: 86.088160\n",
      "Average loss at step 292700: 85.149638\n",
      "Average loss at step 292800: 85.672524\n",
      "Average loss at step 292900: 84.356422\n",
      "Average loss at step 293000: 85.792886\n",
      "Graph 293: 372 nodes\n",
      "Average loss at step 293100: 101.655226\n",
      "Average loss at step 293200: 99.860596\n",
      "Average loss at step 293300: 100.937489\n",
      "Average loss at step 293400: 102.007820\n",
      "Average loss at step 293500: 94.144032\n",
      "Average loss at step 293600: 100.538273\n",
      "Average loss at step 293700: 97.130367\n",
      "Average loss at step 293800: 95.140155\n",
      "Average loss at step 293900: 94.964646\n",
      "Average loss at step 294000: 97.128762\n",
      "Graph 294: 338 nodes\n",
      "Average loss at step 294100: 96.191806\n",
      "Average loss at step 294200: 89.065860\n",
      "Average loss at step 294300: 93.557757\n",
      "Average loss at step 294400: 90.463235\n",
      "Average loss at step 294500: 91.563878\n",
      "Average loss at step 294600: 90.129409\n",
      "Average loss at step 294700: 88.352079\n",
      "Average loss at step 294800: 88.841284\n",
      "Average loss at step 294900: 89.325941\n",
      "Average loss at step 295000: 91.316259\n",
      "Graph 295: 411 nodes\n",
      "Average loss at step 295100: 93.383708\n",
      "Average loss at step 295200: 88.947957\n",
      "Average loss at step 295300: 86.753113\n",
      "Average loss at step 295400: 88.518417\n",
      "Average loss at step 295500: 84.673106\n",
      "Average loss at step 295600: 91.153483\n",
      "Average loss at step 295700: 86.185370\n",
      "Average loss at step 295800: 82.807362\n",
      "Average loss at step 295900: 84.326230\n",
      "Average loss at step 296000: 85.058681\n",
      "Graph 296: 417 nodes\n",
      "Average loss at step 296100: 127.618389\n",
      "Average loss at step 296200: 108.414760\n",
      "Average loss at step 296300: 111.370585\n",
      "Average loss at step 296400: 112.761748\n",
      "Average loss at step 296500: 112.413602\n",
      "Average loss at step 296600: 110.320507\n",
      "Average loss at step 296700: 110.831806\n",
      "Average loss at step 296800: 113.380923\n",
      "Average loss at step 296900: 112.764752\n",
      "Average loss at step 297000: 111.869105\n",
      "Graph 297: 348 nodes\n",
      "Average loss at step 297100: 123.936678\n",
      "Average loss at step 297200: 91.218544\n",
      "Average loss at step 297300: 87.970814\n",
      "Average loss at step 297400: 85.516382\n",
      "Average loss at step 297500: 86.134328\n",
      "Average loss at step 297600: 83.017587\n",
      "Average loss at step 297700: 81.760452\n",
      "Average loss at step 297800: 85.030963\n",
      "Average loss at step 297900: 82.733202\n",
      "Average loss at step 298000: 83.452493\n",
      "Graph 298: 338 nodes\n",
      "Average loss at step 298100: 83.828456\n",
      "Average loss at step 298200: 84.529896\n",
      "Average loss at step 298300: 83.052417\n",
      "Average loss at step 298400: 83.738757\n",
      "Average loss at step 298500: 82.852265\n",
      "Average loss at step 298600: 83.664754\n",
      "Average loss at step 298700: 84.616434\n",
      "Average loss at step 298800: 81.377481\n",
      "Average loss at step 298900: 81.129087\n",
      "Average loss at step 299000: 83.638962\n",
      "Graph 299: 292 nodes\n",
      "Average loss at step 299100: 67.498182\n",
      "Average loss at step 299200: 61.757495\n",
      "Average loss at step 299300: 68.452229\n",
      "Average loss at step 299400: 64.571090\n",
      "Average loss at step 299500: 61.298369\n",
      "Average loss at step 299600: 65.554430\n",
      "Average loss at step 299700: 64.272878\n",
      "Average loss at step 299800: 69.614875\n",
      "Average loss at step 299900: 63.718915\n",
      "Average loss at step 300000: 65.174736\n",
      "Graph 300: 416 nodes\n",
      "Average loss at step 300100: 95.297460\n",
      "Average loss at step 300200: 95.148892\n",
      "Average loss at step 300300: 91.679476\n",
      "Average loss at step 300400: 89.918497\n",
      "Average loss at step 300500: 90.877426\n",
      "Average loss at step 300600: 97.370515\n",
      "Average loss at step 300700: 94.622205\n",
      "Average loss at step 300800: 91.395023\n",
      "Average loss at step 300900: 86.383182\n",
      "Average loss at step 301000: 94.017867\n",
      "Time: 51.3947429657\n",
      "Graph 301: 398 nodes\n",
      "Average loss at step 301100: 109.827081\n",
      "Average loss at step 301200: 102.084129\n",
      "Average loss at step 301300: 103.213932\n",
      "Average loss at step 301400: 98.694836\n",
      "Average loss at step 301500: 102.572373\n",
      "Average loss at step 301600: 100.368125\n",
      "Average loss at step 301700: 103.655293\n",
      "Average loss at step 301800: 100.989502\n",
      "Average loss at step 301900: 102.268451\n",
      "Average loss at step 302000: 103.021060\n",
      "Graph 302: 405 nodes\n",
      "Average loss at step 302100: 116.848897\n",
      "Average loss at step 302200: 93.181254\n",
      "Average loss at step 302300: 90.693310\n",
      "Average loss at step 302400: 92.896992\n",
      "Average loss at step 302500: 89.733288\n",
      "Average loss at step 302600: 89.807397\n",
      "Average loss at step 302700: 92.095198\n",
      "Average loss at step 302800: 93.432936\n",
      "Average loss at step 302900: 85.758536\n",
      "Average loss at step 303000: 91.020424\n",
      "Graph 303: 380 nodes\n",
      "Average loss at step 303100: 101.265348\n",
      "Average loss at step 303200: 98.196207\n",
      "Average loss at step 303300: 93.407192\n",
      "Average loss at step 303400: 100.235206\n",
      "Average loss at step 303500: 98.054955\n",
      "Average loss at step 303600: 95.227081\n",
      "Average loss at step 303700: 95.993956\n",
      "Average loss at step 303800: 95.144323\n",
      "Average loss at step 303900: 97.568600\n",
      "Average loss at step 304000: 92.767124\n",
      "Graph 304: 342 nodes\n",
      "Average loss at step 304100: 86.490524\n",
      "Average loss at step 304200: 87.744695\n",
      "Average loss at step 304300: 87.874851\n",
      "Average loss at step 304400: 88.023505\n",
      "Average loss at step 304500: 81.213688\n",
      "Average loss at step 304600: 86.379494\n",
      "Average loss at step 304700: 83.986667\n",
      "Average loss at step 304800: 89.533049\n",
      "Average loss at step 304900: 85.666688\n",
      "Average loss at step 305000: 85.259344\n",
      "Graph 305: 459 nodes\n",
      "Average loss at step 305100: 95.791778\n",
      "Average loss at step 305200: 85.811750\n",
      "Average loss at step 305300: 90.515133\n",
      "Average loss at step 305400: 91.883013\n",
      "Average loss at step 305500: 94.442744\n",
      "Average loss at step 305600: 86.563786\n",
      "Average loss at step 305700: 91.716539\n",
      "Average loss at step 305800: 86.271533\n",
      "Average loss at step 305900: 88.783555\n",
      "Average loss at step 306000: 89.048231\n",
      "Graph 306: 453 nodes\n",
      "Average loss at step 306100: 117.837810\n",
      "Average loss at step 306200: 105.514352\n",
      "Average loss at step 306300: 99.472207\n",
      "Average loss at step 306400: 103.552281\n",
      "Average loss at step 306500: 100.145048\n",
      "Average loss at step 306600: 96.455626\n",
      "Average loss at step 306700: 97.682599\n",
      "Average loss at step 306800: 100.261068\n",
      "Average loss at step 306900: 102.099885\n",
      "Average loss at step 307000: 104.739049\n",
      "Graph 307: 415 nodes\n",
      "Average loss at step 307100: 108.041104\n",
      "Average loss at step 307200: 106.620742\n",
      "Average loss at step 307300: 103.735335\n",
      "Average loss at step 307400: 107.463887\n",
      "Average loss at step 307500: 103.653704\n",
      "Average loss at step 307600: 103.425365\n",
      "Average loss at step 307700: 105.478453\n",
      "Average loss at step 307800: 101.319469\n",
      "Average loss at step 307900: 103.255583\n",
      "Average loss at step 308000: 107.617596\n",
      "Graph 308: 420 nodes\n",
      "Average loss at step 308100: 102.467638\n",
      "Average loss at step 308200: 97.707670\n",
      "Average loss at step 308300: 94.539827\n",
      "Average loss at step 308400: 98.161731\n",
      "Average loss at step 308500: 96.458952\n",
      "Average loss at step 308600: 93.174949\n",
      "Average loss at step 308700: 95.454985\n",
      "Average loss at step 308800: 97.840460\n",
      "Average loss at step 308900: 95.085432\n",
      "Average loss at step 309000: 94.754297\n",
      "Graph 309: 335 nodes\n",
      "Average loss at step 309100: 67.438389\n",
      "Average loss at step 309200: 65.646757\n",
      "Average loss at step 309300: 62.249154\n",
      "Average loss at step 309400: 63.609186\n",
      "Average loss at step 309500: 63.215743\n",
      "Average loss at step 309600: 66.160576\n",
      "Average loss at step 309700: 63.721167\n",
      "Average loss at step 309800: 65.202876\n",
      "Average loss at step 309900: 66.826576\n",
      "Average loss at step 310000: 65.105046\n",
      "Graph 310: 54 nodes\n",
      "Average loss at step 310100: 28.682700\n",
      "Average loss at step 310200: 28.669336\n",
      "Average loss at step 310300: 28.179006\n",
      "Average loss at step 310400: 29.324344\n",
      "Average loss at step 310500: 26.973954\n",
      "Average loss at step 310600: 27.226412\n",
      "Average loss at step 310700: 29.156551\n",
      "Average loss at step 310800: 25.871092\n",
      "Average loss at step 310900: 29.886643\n",
      "Average loss at step 311000: 28.837861\n",
      "Time: 42.8992609978\n",
      "Graph 311: 423 nodes\n",
      "Average loss at step 311100: 79.978833\n",
      "Average loss at step 311200: 76.431448\n",
      "Average loss at step 311300: 75.875166\n",
      "Average loss at step 311400: 76.906723\n",
      "Average loss at step 311500: 73.296408\n",
      "Average loss at step 311600: 74.541822\n",
      "Average loss at step 311700: 73.526738\n",
      "Average loss at step 311800: 77.578216\n",
      "Average loss at step 311900: 77.491912\n",
      "Average loss at step 312000: 70.246867\n",
      "Graph 312: 431 nodes\n",
      "Average loss at step 312100: 96.763164\n",
      "Average loss at step 312200: 94.835031\n",
      "Average loss at step 312300: 93.255598\n",
      "Average loss at step 312400: 92.163813\n",
      "Average loss at step 312500: 92.325918\n",
      "Average loss at step 312600: 93.989994\n",
      "Average loss at step 312700: 96.205750\n",
      "Average loss at step 312800: 90.223235\n",
      "Average loss at step 312900: 92.239360\n",
      "Average loss at step 313000: 93.756435\n",
      "Graph 313: 417 nodes\n",
      "Average loss at step 313100: 101.055373\n",
      "Average loss at step 313200: 93.327629\n",
      "Average loss at step 313300: 94.105670\n",
      "Average loss at step 313400: 93.893076\n",
      "Average loss at step 313500: 92.992564\n",
      "Average loss at step 313600: 91.487957\n",
      "Average loss at step 313700: 91.844219\n",
      "Average loss at step 313800: 93.939089\n",
      "Average loss at step 313900: 89.541517\n",
      "Average loss at step 314000: 92.727487\n",
      "Graph 314: 370 nodes\n",
      "Average loss at step 314100: 101.220414\n",
      "Average loss at step 314200: 96.557897\n",
      "Average loss at step 314300: 99.139207\n",
      "Average loss at step 314400: 93.082449\n",
      "Average loss at step 314500: 96.406753\n",
      "Average loss at step 314600: 93.747684\n",
      "Average loss at step 314700: 97.766602\n",
      "Average loss at step 314800: 97.513540\n",
      "Average loss at step 314900: 96.978287\n",
      "Average loss at step 315000: 99.504044\n",
      "Graph 315: 494 nodes\n",
      "Average loss at step 315100: 102.833054\n",
      "Average loss at step 315200: 96.755621\n",
      "Average loss at step 315300: 94.993435\n",
      "Average loss at step 315400: 94.266751\n",
      "Average loss at step 315500: 97.406287\n",
      "Average loss at step 315600: 96.657771\n",
      "Average loss at step 315700: 92.974147\n",
      "Average loss at step 315800: 96.472232\n",
      "Average loss at step 315900: 95.377520\n",
      "Average loss at step 316000: 93.075860\n",
      "Graph 316: 173 nodes\n",
      "Average loss at step 316100: 56.774799\n",
      "Average loss at step 316200: 52.388817\n",
      "Average loss at step 316300: 51.462016\n",
      "Average loss at step 316400: 52.171232\n",
      "Average loss at step 316500: 51.910614\n",
      "Average loss at step 316600: 54.477523\n",
      "Average loss at step 316700: 52.054707\n",
      "Average loss at step 316800: 50.175144\n",
      "Average loss at step 316900: 51.883550\n",
      "Average loss at step 317000: 51.269425\n",
      "Graph 317: 435 nodes\n",
      "Average loss at step 317100: 108.949867\n",
      "Average loss at step 317200: 110.307865\n",
      "Average loss at step 317300: 103.312719\n",
      "Average loss at step 317400: 105.925127\n",
      "Average loss at step 317500: 106.106088\n",
      "Average loss at step 317600: 103.181408\n",
      "Average loss at step 317700: 99.500662\n",
      "Average loss at step 317800: 104.398654\n",
      "Average loss at step 317900: 102.545276\n",
      "Average loss at step 318000: 100.090707\n",
      "Graph 318: 445 nodes\n",
      "Average loss at step 318100: 99.533697\n",
      "Average loss at step 318200: 94.407808\n",
      "Average loss at step 318300: 92.025291\n",
      "Average loss at step 318400: 94.304683\n",
      "Average loss at step 318500: 92.470364\n",
      "Average loss at step 318600: 97.338853\n",
      "Average loss at step 318700: 95.281386\n",
      "Average loss at step 318800: 94.712679\n",
      "Average loss at step 318900: 91.073881\n",
      "Average loss at step 319000: 94.136864\n",
      "Graph 319: 438 nodes\n",
      "Average loss at step 319100: 82.937146\n",
      "Average loss at step 319200: 80.887164\n",
      "Average loss at step 319300: 74.397906\n",
      "Average loss at step 319400: 76.563344\n",
      "Average loss at step 319500: 78.775143\n",
      "Average loss at step 319600: 77.557645\n",
      "Average loss at step 319700: 76.562744\n",
      "Average loss at step 319800: 76.547904\n",
      "Average loss at step 319900: 79.113827\n",
      "Average loss at step 320000: 76.192878\n",
      "Graph 320: 492 nodes\n",
      "Average loss at step 320100: 92.336256\n",
      "Average loss at step 320200: 86.140136\n",
      "Average loss at step 320300: 83.984950\n",
      "Average loss at step 320400: 89.047242\n",
      "Average loss at step 320500: 88.754480\n",
      "Average loss at step 320600: 89.671341\n",
      "Average loss at step 320700: 88.484286\n",
      "Average loss at step 320800: 89.098780\n",
      "Average loss at step 320900: 88.426205\n",
      "Average loss at step 321000: 86.842382\n",
      "Time: 53.365858078\n",
      "Graph 321: 534 nodes\n",
      "Average loss at step 321100: 104.906291\n",
      "Average loss at step 321200: 103.318300\n",
      "Average loss at step 321300: 103.078311\n",
      "Average loss at step 321400: 106.550629\n",
      "Average loss at step 321500: 102.288724\n",
      "Average loss at step 321600: 104.724363\n",
      "Average loss at step 321700: 100.580632\n",
      "Average loss at step 321800: 98.411595\n",
      "Average loss at step 321900: 100.976800\n",
      "Average loss at step 322000: 99.400723\n",
      "Graph 322: 584 nodes\n",
      "Average loss at step 322100: 111.067736\n",
      "Average loss at step 322200: 106.970931\n",
      "Average loss at step 322300: 103.565422\n",
      "Average loss at step 322400: 104.394498\n",
      "Average loss at step 322500: 107.371359\n",
      "Average loss at step 322600: 100.851051\n",
      "Average loss at step 322700: 106.778692\n",
      "Average loss at step 322800: 105.189343\n",
      "Average loss at step 322900: 103.728081\n",
      "Average loss at step 323000: 100.434079\n",
      "Graph 323: 496 nodes\n",
      "Average loss at step 323100: 98.999790\n",
      "Average loss at step 323200: 93.275889\n",
      "Average loss at step 323300: 92.423365\n",
      "Average loss at step 323400: 89.886247\n",
      "Average loss at step 323500: 90.872566\n",
      "Average loss at step 323600: 87.688944\n",
      "Average loss at step 323700: 90.107271\n",
      "Average loss at step 323800: 88.395081\n",
      "Average loss at step 323900: 91.835536\n",
      "Average loss at step 324000: 85.101547\n",
      "Graph 324: 508 nodes\n",
      "Average loss at step 324100: 90.206349\n",
      "Average loss at step 324200: 78.648684\n",
      "Average loss at step 324300: 73.080782\n",
      "Average loss at step 324400: 72.654628\n",
      "Average loss at step 324500: 70.328607\n",
      "Average loss at step 324600: 74.460293\n",
      "Average loss at step 324700: 73.888176\n",
      "Average loss at step 324800: 72.839175\n",
      "Average loss at step 324900: 75.212230\n",
      "Average loss at step 325000: 76.443674\n",
      "Graph 325: 580 nodes\n",
      "Average loss at step 325100: 108.749595\n",
      "Average loss at step 325200: 100.543893\n",
      "Average loss at step 325300: 96.091659\n",
      "Average loss at step 325400: 100.719734\n",
      "Average loss at step 325500: 99.102349\n",
      "Average loss at step 325600: 101.223315\n",
      "Average loss at step 325700: 100.116046\n",
      "Average loss at step 325800: 100.326220\n",
      "Average loss at step 325900: 99.453149\n",
      "Average loss at step 326000: 102.249382\n",
      "Graph 326: 690 nodes\n",
      "Average loss at step 326100: 111.449240\n",
      "Average loss at step 326200: 107.524038\n",
      "Average loss at step 326300: 109.157807\n",
      "Average loss at step 326400: 108.692812\n",
      "Average loss at step 326500: 108.784066\n",
      "Average loss at step 326600: 106.236003\n",
      "Average loss at step 326700: 110.521936\n",
      "Average loss at step 326800: 104.935990\n",
      "Average loss at step 326900: 109.121848\n",
      "Average loss at step 327000: 109.156291\n",
      "Graph 327: 672 nodes\n",
      "Average loss at step 327100: 125.120371\n",
      "Average loss at step 327200: 110.778261\n",
      "Average loss at step 327300: 107.002361\n",
      "Average loss at step 327400: 111.387704\n",
      "Average loss at step 327500: 111.729546\n",
      "Average loss at step 327600: 110.756246\n",
      "Average loss at step 327700: 108.921866\n",
      "Average loss at step 327800: 109.946480\n",
      "Average loss at step 327900: 113.709461\n",
      "Average loss at step 328000: 108.497988\n",
      "Graph 328: 709 nodes\n",
      "Average loss at step 328100: 130.048076\n",
      "Average loss at step 328200: 119.327396\n",
      "Average loss at step 328300: 113.898377\n",
      "Average loss at step 328400: 115.713637\n",
      "Average loss at step 328500: 117.999724\n",
      "Average loss at step 328600: 117.989656\n",
      "Average loss at step 328700: 110.011378\n",
      "Average loss at step 328800: 115.579594\n",
      "Average loss at step 328900: 117.742160\n",
      "Average loss at step 329000: 118.000277\n",
      "Graph 329: 615 nodes\n",
      "Average loss at step 329100: 107.757185\n",
      "Average loss at step 329200: 103.725915\n",
      "Average loss at step 329300: 100.566089\n",
      "Average loss at step 329400: 100.690132\n",
      "Average loss at step 329500: 103.501747\n",
      "Average loss at step 329600: 102.074017\n",
      "Average loss at step 329700: 99.910507\n",
      "Average loss at step 329800: 104.509216\n",
      "Average loss at step 329900: 100.517978\n",
      "Average loss at step 330000: 99.274759\n",
      "Graph 330: 715 nodes\n",
      "Average loss at step 330100: 137.895075\n",
      "Average loss at step 330200: 133.037078\n",
      "Average loss at step 330300: 132.420642\n",
      "Average loss at step 330400: 133.195778\n",
      "Average loss at step 330500: 133.933158\n",
      "Average loss at step 330600: 131.653587\n",
      "Average loss at step 330700: 131.155922\n",
      "Average loss at step 330800: 134.814132\n",
      "Average loss at step 330900: 131.561485\n",
      "Average loss at step 331000: 132.727632\n",
      "Time: 58.1656188965\n",
      "Graph 331: 716 nodes\n",
      "Average loss at step 331100: 133.243175\n",
      "Average loss at step 331200: 121.888554\n",
      "Average loss at step 331300: 122.804011\n",
      "Average loss at step 331400: 125.744047\n",
      "Average loss at step 331500: 119.628517\n",
      "Average loss at step 331600: 123.559548\n",
      "Average loss at step 331700: 126.448155\n",
      "Average loss at step 331800: 124.952820\n",
      "Average loss at step 331900: 124.609464\n",
      "Average loss at step 332000: 123.098627\n",
      "Graph 332: 624 nodes\n",
      "Average loss at step 332100: 127.210325\n",
      "Average loss at step 332200: 124.620031\n",
      "Average loss at step 332300: 124.050066\n",
      "Average loss at step 332400: 126.128363\n",
      "Average loss at step 332500: 123.482970\n",
      "Average loss at step 332600: 125.828454\n",
      "Average loss at step 332700: 120.673486\n",
      "Average loss at step 332800: 121.898227\n",
      "Average loss at step 332900: 123.044001\n",
      "Average loss at step 333000: 122.214364\n",
      "Graph 333: 620 nodes\n",
      "Average loss at step 333100: 108.612846\n",
      "Average loss at step 333200: 102.927318\n",
      "Average loss at step 333300: 101.130792\n",
      "Average loss at step 333400: 108.109429\n",
      "Average loss at step 333500: 105.744088\n",
      "Average loss at step 333600: 102.706377\n",
      "Average loss at step 333700: 101.573327\n",
      "Average loss at step 333800: 101.745985\n",
      "Average loss at step 333900: 104.240099\n",
      "Average loss at step 334000: 103.756508\n",
      "Graph 334: 594 nodes\n",
      "Average loss at step 334100: 110.493347\n",
      "Average loss at step 334200: 107.982003\n",
      "Average loss at step 334300: 105.530870\n",
      "Average loss at step 334400: 106.618324\n",
      "Average loss at step 334500: 106.805271\n",
      "Average loss at step 334600: 104.661321\n",
      "Average loss at step 334700: 104.695711\n",
      "Average loss at step 334800: 104.611664\n",
      "Average loss at step 334900: 104.553283\n",
      "Average loss at step 335000: 104.156305\n",
      "Graph 335: 715 nodes\n",
      "Average loss at step 335100: 134.152413\n",
      "Average loss at step 335200: 123.760078\n",
      "Average loss at step 335300: 125.077686\n",
      "Average loss at step 335400: 124.133619\n",
      "Average loss at step 335500: 120.751997\n",
      "Average loss at step 335600: 124.195233\n",
      "Average loss at step 335700: 122.031116\n",
      "Average loss at step 335800: 123.140210\n",
      "Average loss at step 335900: 126.713373\n",
      "Average loss at step 336000: 125.769974\n",
      "Graph 336: 770 nodes\n",
      "Average loss at step 336100: 122.766670\n",
      "Average loss at step 336200: 119.768627\n",
      "Average loss at step 336300: 120.614653\n",
      "Average loss at step 336400: 118.728599\n",
      "Average loss at step 336500: 120.435481\n",
      "Average loss at step 336600: 115.717430\n",
      "Average loss at step 336700: 120.798502\n",
      "Average loss at step 336800: 122.510830\n",
      "Average loss at step 336900: 118.079307\n",
      "Average loss at step 337000: 117.867404\n",
      "Graph 337: 742 nodes\n",
      "Average loss at step 337100: 113.033139\n",
      "Average loss at step 337200: 109.377478\n",
      "Average loss at step 337300: 108.642630\n",
      "Average loss at step 337400: 108.332380\n",
      "Average loss at step 337500: 109.463716\n",
      "Average loss at step 337600: 109.833931\n",
      "Average loss at step 337700: 108.132647\n",
      "Average loss at step 337800: 106.923409\n",
      "Average loss at step 337900: 106.647553\n",
      "Average loss at step 338000: 107.361356\n",
      "Graph 338: 707 nodes\n",
      "Average loss at step 338100: 119.325491\n",
      "Average loss at step 338200: 109.257412\n",
      "Average loss at step 338300: 108.894332\n",
      "Average loss at step 338400: 112.232248\n",
      "Average loss at step 338500: 106.720583\n",
      "Average loss at step 338600: 111.446878\n",
      "Average loss at step 338700: 110.664388\n",
      "Average loss at step 338800: 108.878999\n",
      "Average loss at step 338900: 110.277387\n",
      "Average loss at step 339000: 110.319531\n",
      "Graph 339: 724 nodes\n",
      "Average loss at step 339100: 106.312832\n",
      "Average loss at step 339200: 104.734548\n",
      "Average loss at step 339300: 101.432000\n",
      "Average loss at step 339400: 100.154288\n",
      "Average loss at step 339500: 103.296055\n",
      "Average loss at step 339600: 103.824532\n",
      "Average loss at step 339700: 100.843889\n",
      "Average loss at step 339800: 100.061220\n",
      "Average loss at step 339900: 100.997750\n",
      "Average loss at step 340000: 99.668544\n",
      "Graph 340: 1057 nodes\n",
      "Average loss at step 340100: 127.383263\n",
      "Average loss at step 340200: 117.011434\n",
      "Average loss at step 340300: 117.186489\n",
      "Average loss at step 340400: 114.114958\n",
      "Average loss at step 340500: 116.852983\n",
      "Average loss at step 340600: 114.653675\n",
      "Average loss at step 340700: 112.503093\n",
      "Average loss at step 340800: 108.694105\n",
      "Average loss at step 340900: 113.349538\n",
      "Average loss at step 341000: 116.364224\n",
      "Time: 54.6568698883\n",
      "Graph 341: 1055 nodes\n",
      "Average loss at step 341100: 124.859853\n",
      "Average loss at step 341200: 118.300133\n",
      "Average loss at step 341300: 119.258416\n",
      "Average loss at step 341400: 119.637070\n",
      "Average loss at step 341500: 120.885013\n",
      "Average loss at step 341600: 122.481072\n",
      "Average loss at step 341700: 116.897843\n",
      "Average loss at step 341800: 121.814060\n",
      "Average loss at step 341900: 120.593666\n",
      "Average loss at step 342000: 117.798223\n",
      "Graph 342: 1216 nodes\n",
      "Average loss at step 342100: 130.702303\n",
      "Average loss at step 342200: 125.580764\n",
      "Average loss at step 342300: 125.559984\n",
      "Average loss at step 342400: 124.838247\n",
      "Average loss at step 342500: 122.915460\n",
      "Average loss at step 342600: 125.812932\n",
      "Average loss at step 342700: 120.874451\n",
      "Average loss at step 342800: 123.397605\n",
      "Average loss at step 342900: 126.082088\n",
      "Average loss at step 343000: 123.400686\n",
      "Graph 343: 1426 nodes\n",
      "Average loss at step 343100: 170.304943\n",
      "Average loss at step 343200: 130.012173\n",
      "Average loss at step 343300: 130.616628\n",
      "Average loss at step 343400: 129.095335\n",
      "Average loss at step 343500: 127.567658\n",
      "Average loss at step 343600: 128.678849\n",
      "Average loss at step 343700: 131.748893\n",
      "Average loss at step 343800: 130.136822\n",
      "Average loss at step 343900: 124.957504\n",
      "Average loss at step 344000: 128.261259\n",
      "Graph 344: 1211 nodes\n",
      "Average loss at step 344100: 119.675342\n",
      "Average loss at step 344200: 122.968417\n",
      "Average loss at step 344300: 120.482952\n",
      "Average loss at step 344400: 119.611419\n",
      "Average loss at step 344500: 118.505384\n",
      "Average loss at step 344600: 117.505775\n",
      "Average loss at step 344700: 123.138133\n",
      "Average loss at step 344800: 121.239732\n",
      "Average loss at step 344900: 119.934858\n",
      "Average loss at step 345000: 122.344464\n",
      "Graph 345: 1410 nodes\n",
      "Average loss at step 345100: 138.570227\n",
      "Average loss at step 345200: 131.394810\n",
      "Average loss at step 345300: 130.991311\n",
      "Average loss at step 345400: 132.265242\n",
      "Average loss at step 345500: 130.897022\n",
      "Average loss at step 345600: 131.013326\n",
      "Average loss at step 345700: 133.799577\n",
      "Average loss at step 345800: 129.612569\n",
      "Average loss at step 345900: 135.840136\n",
      "Average loss at step 346000: 135.400192\n",
      "Graph 346: 1418 nodes\n",
      "Average loss at step 346100: 139.727803\n",
      "Average loss at step 346200: 130.631698\n",
      "Average loss at step 346300: 128.431210\n",
      "Average loss at step 346400: 127.917388\n",
      "Average loss at step 346500: 130.195940\n",
      "Average loss at step 346600: 130.730930\n",
      "Average loss at step 346700: 133.280084\n",
      "Average loss at step 346800: 128.420873\n",
      "Average loss at step 346900: 130.642751\n",
      "Average loss at step 347000: 129.949321\n",
      "Graph 347: 1457 nodes\n",
      "Average loss at step 347100: 134.155956\n",
      "Average loss at step 347200: 136.722290\n",
      "Average loss at step 347300: 131.088734\n",
      "Average loss at step 347400: 134.734648\n",
      "Average loss at step 347500: 132.238533\n",
      "Average loss at step 347600: 138.242226\n",
      "Average loss at step 347700: 132.479614\n",
      "Average loss at step 347800: 130.865730\n",
      "Average loss at step 347900: 130.588241\n",
      "Average loss at step 348000: 134.665268\n",
      "Graph 348: 1537 nodes\n",
      "Average loss at step 348100: 147.277833\n",
      "Average loss at step 348200: 144.064513\n",
      "Average loss at step 348300: 144.519925\n",
      "Average loss at step 348400: 142.511741\n",
      "Average loss at step 348500: 142.959526\n",
      "Average loss at step 348600: 140.845531\n",
      "Average loss at step 348700: 140.669088\n",
      "Average loss at step 348800: 147.367718\n",
      "Average loss at step 348900: 140.564705\n",
      "Average loss at step 349000: 138.953511\n",
      "Graph 349: 1374 nodes\n",
      "Average loss at step 349100: 168.539829\n",
      "Average loss at step 349200: 138.369854\n",
      "Average loss at step 349300: 134.756076\n",
      "Average loss at step 349400: 140.296352\n",
      "Average loss at step 349500: 135.902496\n",
      "Average loss at step 349600: 134.213500\n",
      "Average loss at step 349700: 139.162640\n",
      "Average loss at step 349800: 138.892769\n",
      "Average loss at step 349900: 133.265343\n",
      "Average loss at step 350000: 134.386929\n",
      "Graph 350: 1470 nodes\n",
      "Average loss at step 350100: 142.353348\n",
      "Average loss at step 350200: 130.859407\n",
      "Average loss at step 350300: 128.426932\n",
      "Average loss at step 350400: 133.234820\n",
      "Average loss at step 350500: 134.444779\n",
      "Average loss at step 350600: 131.934091\n",
      "Average loss at step 350700: 135.046682\n",
      "Average loss at step 350800: 125.072691\n",
      "Average loss at step 350900: 127.880413\n",
      "Average loss at step 351000: 133.842292\n",
      "Time: 61.0197689533\n",
      "Graph 351: 721 nodes\n",
      "Average loss at step 351100: 140.667538\n",
      "Average loss at step 351200: 125.907398\n",
      "Average loss at step 351300: 124.325619\n",
      "Average loss at step 351400: 129.156887\n",
      "Average loss at step 351500: 125.534544\n",
      "Average loss at step 351600: 121.998623\n",
      "Average loss at step 351700: 123.854310\n",
      "Average loss at step 351800: 124.221343\n",
      "Average loss at step 351900: 125.749297\n",
      "Average loss at step 352000: 125.393708\n",
      "Graph 352: 728 nodes\n",
      "Average loss at step 352100: 130.250868\n",
      "Average loss at step 352200: 124.348465\n",
      "Average loss at step 352300: 124.835968\n",
      "Average loss at step 352400: 118.891710\n",
      "Average loss at step 352500: 125.648836\n",
      "Average loss at step 352600: 126.526642\n",
      "Average loss at step 352700: 119.874522\n",
      "Average loss at step 352800: 122.170577\n",
      "Average loss at step 352900: 120.271500\n",
      "Average loss at step 353000: 122.539484\n",
      "Graph 353: 693 nodes\n",
      "Average loss at step 353100: 138.068269\n",
      "Average loss at step 353200: 125.367895\n",
      "Average loss at step 353300: 122.209637\n",
      "Average loss at step 353400: 121.789840\n",
      "Average loss at step 353500: 121.129461\n",
      "Average loss at step 353600: 121.507831\n",
      "Average loss at step 353700: 120.996463\n",
      "Average loss at step 353800: 117.137844\n",
      "Average loss at step 353900: 121.754625\n",
      "Average loss at step 354000: 119.822527\n",
      "Graph 354: 688 nodes\n",
      "Average loss at step 354100: 133.063581\n",
      "Average loss at step 354200: 121.903540\n",
      "Average loss at step 354300: 121.732988\n",
      "Average loss at step 354400: 125.635398\n",
      "Average loss at step 354500: 126.670923\n",
      "Average loss at step 354600: 121.607971\n",
      "Average loss at step 354700: 128.566137\n",
      "Average loss at step 354800: 122.328466\n",
      "Average loss at step 354900: 123.407788\n",
      "Average loss at step 355000: 122.753911\n",
      "Graph 355: 757 nodes\n",
      "Average loss at step 355100: 148.813683\n",
      "Average loss at step 355200: 143.361832\n",
      "Average loss at step 355300: 139.273436\n",
      "Average loss at step 355400: 137.004929\n",
      "Average loss at step 355500: 135.908548\n",
      "Average loss at step 355600: 138.227257\n",
      "Average loss at step 355700: 135.277356\n",
      "Average loss at step 355800: 130.972312\n",
      "Average loss at step 355900: 135.458341\n",
      "Average loss at step 356000: 135.497973\n",
      "Graph 356: 811 nodes\n",
      "Average loss at step 356100: 121.184920\n",
      "Average loss at step 356200: 119.401087\n",
      "Average loss at step 356300: 120.901028\n",
      "Average loss at step 356400: 119.903630\n",
      "Average loss at step 356500: 117.265911\n",
      "Average loss at step 356600: 113.531165\n",
      "Average loss at step 356700: 119.338484\n",
      "Average loss at step 356800: 115.675520\n",
      "Average loss at step 356900: 116.947306\n",
      "Average loss at step 357000: 114.683630\n",
      "Graph 357: 752 nodes\n",
      "Average loss at step 357100: 123.641897\n",
      "Average loss at step 357200: 116.919191\n",
      "Average loss at step 357300: 124.135583\n",
      "Average loss at step 357400: 116.158063\n",
      "Average loss at step 357500: 123.495666\n",
      "Average loss at step 357600: 123.926205\n",
      "Average loss at step 357700: 118.743274\n",
      "Average loss at step 357800: 121.109235\n",
      "Average loss at step 357900: 122.339620\n",
      "Average loss at step 358000: 122.069595\n",
      "Graph 358: 678 nodes\n",
      "Average loss at step 358100: 117.309146\n",
      "Average loss at step 358200: 109.762446\n",
      "Average loss at step 358300: 105.249401\n",
      "Average loss at step 358400: 112.435064\n",
      "Average loss at step 358500: 111.050522\n",
      "Average loss at step 358600: 106.909303\n",
      "Average loss at step 358700: 112.090038\n",
      "Average loss at step 358800: 107.885609\n",
      "Average loss at step 358900: 107.054917\n",
      "Average loss at step 359000: 110.599589\n",
      "Graph 359: 616 nodes\n",
      "Average loss at step 359100: 102.410534\n",
      "Average loss at step 359200: 108.565227\n",
      "Average loss at step 359300: 102.798525\n",
      "Average loss at step 359400: 99.611853\n",
      "Average loss at step 359500: 100.494138\n",
      "Average loss at step 359600: 99.860210\n",
      "Average loss at step 359700: 101.977030\n",
      "Average loss at step 359800: 101.209735\n",
      "Average loss at step 359900: 99.916095\n",
      "Average loss at step 360000: 102.731029\n",
      "Graph 360: 777 nodes\n",
      "Average loss at step 360100: 127.744186\n",
      "Average loss at step 360200: 123.916367\n",
      "Average loss at step 360300: 117.900552\n",
      "Average loss at step 360400: 122.878875\n",
      "Average loss at step 360500: 121.507060\n",
      "Average loss at step 360600: 121.818488\n",
      "Average loss at step 360700: 124.277526\n",
      "Average loss at step 360800: 128.268994\n",
      "Average loss at step 360900: 123.339519\n",
      "Average loss at step 361000: 121.905871\n",
      "Time: 53.0291619301\n",
      "Graph 361: 867 nodes\n",
      "Average loss at step 361100: 146.932772\n",
      "Average loss at step 361200: 137.449218\n",
      "Average loss at step 361300: 141.549779\n",
      "Average loss at step 361400: 140.461066\n",
      "Average loss at step 361500: 133.062551\n",
      "Average loss at step 361600: 131.946401\n",
      "Average loss at step 361700: 137.424268\n",
      "Average loss at step 361800: 133.029215\n",
      "Average loss at step 361900: 136.755800\n",
      "Average loss at step 362000: 134.272890\n",
      "Graph 362: 947 nodes\n",
      "Average loss at step 362100: 143.874543\n",
      "Average loss at step 362200: 127.360266\n",
      "Average loss at step 362300: 121.037528\n",
      "Average loss at step 362400: 124.166869\n",
      "Average loss at step 362500: 121.377644\n",
      "Average loss at step 362600: 125.380019\n",
      "Average loss at step 362700: 123.297643\n",
      "Average loss at step 362800: 123.568561\n",
      "Average loss at step 362900: 124.916676\n",
      "Average loss at step 363000: 120.442936\n",
      "Graph 363: 969 nodes\n",
      "Average loss at step 363100: 131.353205\n",
      "Average loss at step 363200: 131.253987\n",
      "Average loss at step 363300: 127.617771\n",
      "Average loss at step 363400: 126.694235\n",
      "Average loss at step 363500: 130.082736\n",
      "Average loss at step 363600: 127.628437\n",
      "Average loss at step 363700: 130.292856\n",
      "Average loss at step 363800: 131.221014\n",
      "Average loss at step 363900: 131.072356\n",
      "Average loss at step 364000: 129.180368\n",
      "Graph 364: 1080 nodes\n",
      "Average loss at step 364100: 120.527011\n",
      "Average loss at step 364200: 116.507265\n",
      "Average loss at step 364300: 115.471105\n",
      "Average loss at step 364400: 122.462264\n",
      "Average loss at step 364500: 118.764422\n",
      "Average loss at step 364600: 122.113464\n",
      "Average loss at step 364700: 122.338960\n",
      "Average loss at step 364800: 116.326939\n",
      "Average loss at step 364900: 118.680989\n",
      "Average loss at step 365000: 120.799802\n",
      "Graph 365: 1452 nodes\n",
      "Average loss at step 365100: 131.637871\n",
      "Average loss at step 365200: 128.303318\n",
      "Average loss at step 365300: 130.537731\n",
      "Average loss at step 365400: 126.069819\n",
      "Average loss at step 365500: 127.688063\n",
      "Average loss at step 365600: 125.340336\n",
      "Average loss at step 365700: 128.003823\n",
      "Average loss at step 365800: 122.849234\n",
      "Average loss at step 365900: 127.760681\n",
      "Average loss at step 366000: 131.754493\n",
      "Graph 366: 1425 nodes\n",
      "Average loss at step 366100: 141.149448\n",
      "Average loss at step 366200: 133.856597\n",
      "Average loss at step 366300: 131.877717\n",
      "Average loss at step 366400: 134.084838\n",
      "Average loss at step 366500: 136.390011\n",
      "Average loss at step 366600: 134.641971\n",
      "Average loss at step 366700: 139.995209\n",
      "Average loss at step 366800: 130.989985\n",
      "Average loss at step 366900: 136.243580\n",
      "Average loss at step 367000: 133.108655\n",
      "Graph 367: 1098 nodes\n",
      "Average loss at step 367100: 128.587597\n",
      "Average loss at step 367200: 122.838309\n",
      "Average loss at step 367300: 118.875634\n",
      "Average loss at step 367400: 122.279489\n",
      "Average loss at step 367500: 123.209176\n",
      "Average loss at step 367600: 126.778304\n",
      "Average loss at step 367700: 121.659482\n",
      "Average loss at step 367800: 119.810460\n",
      "Average loss at step 367900: 125.511337\n",
      "Average loss at step 368000: 118.930286\n",
      "Graph 368: 234 nodes\n",
      "Average loss at step 368100: 90.611157\n",
      "Average loss at step 368200: 83.368943\n",
      "Average loss at step 368300: 83.086636\n",
      "Average loss at step 368400: 82.482275\n",
      "Average loss at step 368500: 83.305156\n",
      "Average loss at step 368600: 83.231142\n",
      "Average loss at step 368700: 79.882900\n",
      "Average loss at step 368800: 83.654491\n",
      "Average loss at step 368900: 82.368800\n",
      "Average loss at step 369000: 81.274678\n",
      "Graph 369: 284 nodes\n",
      "Average loss at step 369100: 93.508465\n",
      "Average loss at step 369200: 93.885843\n",
      "Average loss at step 369300: 90.021017\n",
      "Average loss at step 369400: 87.450193\n",
      "Average loss at step 369500: 87.576541\n",
      "Average loss at step 369600: 87.189231\n",
      "Average loss at step 369700: 92.080899\n",
      "Average loss at step 369800: 90.062835\n",
      "Average loss at step 369900: 87.171095\n",
      "Average loss at step 370000: 87.181286\n",
      "Graph 370: 1449 nodes\n",
      "Average loss at step 370100: 137.219036\n",
      "Average loss at step 370200: 143.177055\n",
      "Average loss at step 370300: 134.089232\n",
      "Average loss at step 370400: 137.118432\n",
      "Average loss at step 370500: 131.357100\n",
      "Average loss at step 370600: 134.331415\n",
      "Average loss at step 370700: 130.432065\n",
      "Average loss at step 370800: 136.963335\n",
      "Average loss at step 370900: 137.995258\n",
      "Average loss at step 371000: 133.732657\n",
      "Time: 61.0557370186\n",
      "Graph 371: 1345 nodes\n",
      "Average loss at step 371100: 141.197493\n",
      "Average loss at step 371200: 141.482870\n",
      "Average loss at step 371300: 137.359304\n",
      "Average loss at step 371400: 138.113596\n",
      "Average loss at step 371500: 140.159390\n",
      "Average loss at step 371600: 135.296100\n",
      "Average loss at step 371700: 140.084627\n",
      "Average loss at step 371800: 138.684962\n",
      "Average loss at step 371900: 143.806481\n",
      "Average loss at step 372000: 136.397561\n",
      "Graph 372: 491 nodes\n",
      "Average loss at step 372100: 98.823778\n",
      "Average loss at step 372200: 95.233664\n",
      "Average loss at step 372300: 94.186743\n",
      "Average loss at step 372400: 102.301890\n",
      "Average loss at step 372500: 93.847874\n",
      "Average loss at step 372600: 96.291255\n",
      "Average loss at step 372700: 98.013931\n",
      "Average loss at step 372800: 97.886763\n",
      "Average loss at step 372900: 94.628860\n",
      "Average loss at step 373000: 92.423917\n",
      "Graph 373: 508 nodes\n",
      "Average loss at step 373100: 125.282241\n",
      "Average loss at step 373200: 108.967509\n",
      "Average loss at step 373300: 109.541201\n",
      "Average loss at step 373400: 106.070516\n",
      "Average loss at step 373500: 106.813121\n",
      "Average loss at step 373600: 106.094162\n",
      "Average loss at step 373700: 105.802374\n",
      "Average loss at step 373800: 106.304647\n",
      "Average loss at step 373900: 107.411083\n",
      "Average loss at step 374000: 99.961824\n",
      "Graph 374: 504 nodes\n",
      "Average loss at step 374100: 86.685719\n",
      "Average loss at step 374200: 84.718299\n",
      "Average loss at step 374300: 81.419277\n",
      "Average loss at step 374400: 80.182724\n",
      "Average loss at step 374500: 84.282193\n",
      "Average loss at step 374600: 83.258358\n",
      "Average loss at step 374700: 85.468911\n",
      "Average loss at step 374800: 85.425095\n",
      "Average loss at step 374900: 81.308471\n",
      "Average loss at step 375000: 85.016446\n",
      "Graph 375: 446 nodes\n",
      "Average loss at step 375100: 122.155451\n",
      "Average loss at step 375200: 116.120227\n",
      "Average loss at step 375300: 115.604524\n",
      "Average loss at step 375400: 118.193260\n",
      "Average loss at step 375500: 115.161835\n",
      "Average loss at step 375600: 112.788719\n",
      "Average loss at step 375700: 112.167075\n",
      "Average loss at step 375800: 113.729962\n",
      "Average loss at step 375900: 114.172375\n",
      "Average loss at step 376000: 113.606018\n",
      "Graph 376: 457 nodes\n",
      "Average loss at step 376100: 116.128899\n",
      "Average loss at step 376200: 105.290225\n",
      "Average loss at step 376300: 102.045634\n",
      "Average loss at step 376400: 101.677847\n",
      "Average loss at step 376500: 97.366462\n",
      "Average loss at step 376600: 96.922575\n",
      "Average loss at step 376700: 97.474804\n",
      "Average loss at step 376800: 99.133645\n",
      "Average loss at step 376900: 99.499651\n",
      "Average loss at step 377000: 102.699715\n",
      "Graph 377: 412 nodes\n",
      "Average loss at step 377100: 104.357868\n",
      "Average loss at step 377200: 97.757903\n",
      "Average loss at step 377300: 93.935153\n",
      "Average loss at step 377400: 97.458328\n",
      "Average loss at step 377500: 93.870434\n",
      "Average loss at step 377600: 96.767346\n",
      "Average loss at step 377700: 100.295993\n",
      "Average loss at step 377800: 95.510925\n",
      "Average loss at step 377900: 96.837867\n",
      "Average loss at step 378000: 99.253908\n",
      "Graph 378: 405 nodes\n",
      "Average loss at step 378100: 104.997903\n",
      "Average loss at step 378200: 92.001335\n",
      "Average loss at step 378300: 87.071458\n",
      "Average loss at step 378400: 91.937630\n",
      "Average loss at step 378500: 87.395152\n",
      "Average loss at step 378600: 88.568879\n",
      "Average loss at step 378700: 86.034517\n",
      "Average loss at step 378800: 86.718586\n",
      "Average loss at step 378900: 87.850066\n",
      "Average loss at step 379000: 88.099053\n",
      "Graph 379: 358 nodes\n",
      "Average loss at step 379100: 81.766566\n",
      "Average loss at step 379200: 81.244729\n",
      "Average loss at step 379300: 78.917308\n",
      "Average loss at step 379400: 78.902423\n",
      "Average loss at step 379500: 79.132453\n",
      "Average loss at step 379600: 76.468553\n",
      "Average loss at step 379700: 77.193888\n",
      "Average loss at step 379800: 77.740921\n",
      "Average loss at step 379900: 80.085157\n",
      "Average loss at step 380000: 79.693704\n",
      "Graph 380: 443 nodes\n",
      "Average loss at step 380100: 102.190940\n",
      "Average loss at step 380200: 96.663546\n",
      "Average loss at step 380300: 99.195464\n",
      "Average loss at step 380400: 95.032212\n",
      "Average loss at step 380500: 99.800895\n",
      "Average loss at step 380600: 95.326249\n",
      "Average loss at step 380700: 95.206925\n",
      "Average loss at step 380800: 92.843710\n",
      "Average loss at step 380900: 93.201887\n",
      "Average loss at step 381000: 96.647185\n",
      "Time: 47.9862420559\n",
      "Graph 381: 473 nodes\n",
      "Average loss at step 381100: 104.065586\n",
      "Average loss at step 381200: 90.135239\n",
      "Average loss at step 381300: 88.363421\n",
      "Average loss at step 381400: 91.548007\n",
      "Average loss at step 381500: 86.819342\n",
      "Average loss at step 381600: 85.537848\n",
      "Average loss at step 381700: 90.969055\n",
      "Average loss at step 381800: 88.858171\n",
      "Average loss at step 381900: 92.666312\n",
      "Average loss at step 382000: 90.050938\n",
      "Graph 382: 491 nodes\n",
      "Average loss at step 382100: 122.981816\n",
      "Average loss at step 382200: 111.224940\n",
      "Average loss at step 382300: 107.876375\n",
      "Average loss at step 382400: 103.921175\n",
      "Average loss at step 382500: 110.255149\n",
      "Average loss at step 382600: 106.300367\n",
      "Average loss at step 382700: 108.315505\n",
      "Average loss at step 382800: 105.412835\n",
      "Average loss at step 382900: 107.763236\n",
      "Average loss at step 383000: 107.133023\n",
      "Graph 383: 525 nodes\n",
      "Average loss at step 383100: 114.320861\n",
      "Average loss at step 383200: 117.370252\n",
      "Average loss at step 383300: 113.062982\n",
      "Average loss at step 383400: 113.976509\n",
      "Average loss at step 383500: 113.332718\n",
      "Average loss at step 383600: 114.275845\n",
      "Average loss at step 383700: 116.397924\n",
      "Average loss at step 383800: 115.610502\n",
      "Average loss at step 383900: 113.530622\n",
      "Average loss at step 384000: 114.900594\n",
      "Graph 384: 352 nodes\n",
      "Average loss at step 384100: 87.932706\n",
      "Average loss at step 384200: 87.890147\n",
      "Average loss at step 384300: 88.223468\n",
      "Average loss at step 384400: 88.424778\n",
      "Average loss at step 384500: 85.796096\n",
      "Average loss at step 384600: 86.264045\n",
      "Average loss at step 384700: 89.137602\n",
      "Average loss at step 384800: 90.110307\n",
      "Average loss at step 384900: 91.153797\n",
      "Average loss at step 385000: 80.358894\n",
      "Graph 385: 506 nodes\n",
      "Average loss at step 385100: 96.075492\n",
      "Average loss at step 385200: 95.127771\n",
      "Average loss at step 385300: 92.130233\n",
      "Average loss at step 385400: 93.569824\n",
      "Average loss at step 385500: 87.764532\n",
      "Average loss at step 385600: 92.355173\n",
      "Average loss at step 385700: 90.051384\n",
      "Average loss at step 385800: 90.724770\n",
      "Average loss at step 385900: 92.565386\n",
      "Average loss at step 386000: 88.888588\n",
      "Graph 386: 355 nodes\n",
      "Average loss at step 386100: 82.745800\n",
      "Average loss at step 386200: 75.296912\n",
      "Average loss at step 386300: 76.309844\n",
      "Average loss at step 386400: 70.927868\n",
      "Average loss at step 386500: 74.778670\n",
      "Average loss at step 386600: 74.925139\n",
      "Average loss at step 386700: 76.829700\n",
      "Average loss at step 386800: 74.915676\n",
      "Average loss at step 386900: 75.036308\n",
      "Average loss at step 387000: 77.828526\n",
      "Graph 387: 635 nodes\n",
      "Average loss at step 387100: 150.349436\n",
      "Average loss at step 387200: 107.781525\n",
      "Average loss at step 387300: 105.279208\n",
      "Average loss at step 387400: 102.524260\n",
      "Average loss at step 387500: 106.323210\n",
      "Average loss at step 387600: 101.393965\n",
      "Average loss at step 387700: 102.819721\n",
      "Average loss at step 387800: 104.385723\n",
      "Average loss at step 387900: 104.932006\n",
      "Average loss at step 388000: 106.319463\n",
      "Graph 388: 589 nodes\n",
      "Average loss at step 388100: 116.806872\n",
      "Average loss at step 388200: 111.274133\n",
      "Average loss at step 388300: 116.738261\n",
      "Average loss at step 388400: 112.430099\n",
      "Average loss at step 388500: 112.251600\n",
      "Average loss at step 388600: 116.857893\n",
      "Average loss at step 388700: 112.320000\n",
      "Average loss at step 388800: 107.512279\n",
      "Average loss at step 388900: 108.593476\n",
      "Average loss at step 389000: 110.819406\n",
      "Graph 389: 542 nodes\n",
      "Average loss at step 389100: 90.385314\n",
      "Average loss at step 389200: 92.722302\n",
      "Average loss at step 389300: 91.932672\n",
      "Average loss at step 389400: 87.772441\n",
      "Average loss at step 389500: 90.215228\n",
      "Average loss at step 389600: 87.419937\n",
      "Average loss at step 389700: 88.101069\n",
      "Average loss at step 389800: 86.053801\n",
      "Average loss at step 389900: 89.269496\n",
      "Average loss at step 390000: 87.466207\n",
      "Graph 390: 202 nodes\n",
      "Average loss at step 390100: 100.981791\n",
      "Average loss at step 390200: 91.790619\n",
      "Average loss at step 390300: 92.143320\n",
      "Average loss at step 390400: 90.079271\n",
      "Average loss at step 390500: 89.158514\n",
      "Average loss at step 390600: 90.385321\n",
      "Average loss at step 390700: 90.622758\n",
      "Average loss at step 390800: 94.106603\n",
      "Average loss at step 390900: 92.362294\n",
      "Average loss at step 391000: 93.424977\n",
      "Time: 46.9899330139\n",
      "Graph 391: 111 nodes\n",
      "Average loss at step 391100: 135.441461\n",
      "Average loss at step 391200: 127.234411\n",
      "Average loss at step 391300: 126.674795\n",
      "Average loss at step 391400: 127.334372\n",
      "Average loss at step 391500: 125.792532\n",
      "Average loss at step 391600: 129.123600\n",
      "Average loss at step 391700: 126.667930\n",
      "Average loss at step 391800: 124.250728\n",
      "Average loss at step 391900: 125.189663\n",
      "Average loss at step 392000: 127.009603\n",
      "Graph 392: 438 nodes\n",
      "Average loss at step 392100: 119.037471\n",
      "Average loss at step 392200: 107.612589\n",
      "Average loss at step 392300: 107.224484\n",
      "Average loss at step 392400: 107.151165\n",
      "Average loss at step 392500: 108.321713\n",
      "Average loss at step 392600: 107.306203\n",
      "Average loss at step 392700: 102.982021\n",
      "Average loss at step 392800: 103.911763\n",
      "Average loss at step 392900: 110.211522\n",
      "Average loss at step 393000: 106.960464\n",
      "Graph 393: 523 nodes\n",
      "Average loss at step 393100: 130.407930\n",
      "Average loss at step 393200: 121.334773\n",
      "Average loss at step 393300: 122.708855\n",
      "Average loss at step 393400: 123.944648\n",
      "Average loss at step 393500: 117.447282\n",
      "Average loss at step 393600: 121.243012\n",
      "Average loss at step 393700: 120.508981\n",
      "Average loss at step 393800: 119.921735\n",
      "Average loss at step 393900: 124.052084\n",
      "Average loss at step 394000: 119.067376\n",
      "Graph 394: 429 nodes\n",
      "Average loss at step 394100: 108.620656\n",
      "Average loss at step 394200: 104.123597\n",
      "Average loss at step 394300: 103.089166\n",
      "Average loss at step 394400: 104.725414\n",
      "Average loss at step 394500: 102.395614\n",
      "Average loss at step 394600: 103.137275\n",
      "Average loss at step 394700: 99.391742\n",
      "Average loss at step 394800: 101.395121\n",
      "Average loss at step 394900: 103.443636\n",
      "Average loss at step 395000: 103.214158\n",
      "Graph 395: 401 nodes\n",
      "Average loss at step 395100: 120.490267\n",
      "Average loss at step 395200: 103.523362\n",
      "Average loss at step 395300: 106.376143\n",
      "Average loss at step 395400: 107.244713\n",
      "Average loss at step 395500: 105.661010\n",
      "Average loss at step 395600: 102.159028\n",
      "Average loss at step 395700: 98.951550\n",
      "Average loss at step 395800: 102.815517\n",
      "Average loss at step 395900: 103.725731\n",
      "Average loss at step 396000: 102.328558\n",
      "Graph 396: 131 nodes\n",
      "Average loss at step 396100: 111.474971\n",
      "Average loss at step 396200: 103.703014\n",
      "Average loss at step 396300: 101.680334\n",
      "Average loss at step 396400: 100.735786\n",
      "Average loss at step 396500: 96.877845\n",
      "Average loss at step 396600: 100.051817\n",
      "Average loss at step 396700: 103.831516\n",
      "Average loss at step 396800: 100.081997\n",
      "Average loss at step 396900: 103.184444\n",
      "Average loss at step 397000: 98.101243\n",
      "Graph 397: 439 nodes\n",
      "Average loss at step 397100: 103.114171\n",
      "Average loss at step 397200: 102.894796\n",
      "Average loss at step 397300: 99.616012\n",
      "Average loss at step 397400: 104.390559\n",
      "Average loss at step 397500: 107.210012\n",
      "Average loss at step 397600: 101.912816\n",
      "Average loss at step 397700: 98.915251\n",
      "Average loss at step 397800: 101.734681\n",
      "Average loss at step 397900: 102.585111\n",
      "Average loss at step 398000: 102.583748\n",
      "Graph 398: 394 nodes\n",
      "Average loss at step 398100: 104.160892\n",
      "Average loss at step 398200: 99.202030\n",
      "Average loss at step 398300: 100.213736\n",
      "Average loss at step 398400: 101.107935\n",
      "Average loss at step 398500: 98.559403\n",
      "Average loss at step 398600: 97.618250\n",
      "Average loss at step 398700: 97.731541\n",
      "Average loss at step 398800: 97.770691\n",
      "Average loss at step 398900: 101.715864\n",
      "Average loss at step 399000: 98.407556\n",
      "Graph 399: 383 nodes\n",
      "Average loss at step 399100: 90.960610\n",
      "Average loss at step 399200: 84.039289\n",
      "Average loss at step 399300: 84.584241\n",
      "Average loss at step 399400: 86.888619\n",
      "Average loss at step 399500: 82.966785\n",
      "Average loss at step 399600: 87.230455\n",
      "Average loss at step 399700: 85.654355\n",
      "Average loss at step 399800: 85.940638\n",
      "Average loss at step 399900: 87.178977\n",
      "Average loss at step 400000: 83.961908\n",
      "Graph 400: 487 nodes\n",
      "Average loss at step 400100: 148.405271\n",
      "Average loss at step 400200: 138.526983\n",
      "Average loss at step 400300: 139.864543\n",
      "Average loss at step 400400: 141.682028\n",
      "Average loss at step 400500: 139.048775\n",
      "Average loss at step 400600: 138.166457\n",
      "Average loss at step 400700: 138.435755\n",
      "Average loss at step 400800: 135.143783\n",
      "Average loss at step 400900: 136.748127\n",
      "Average loss at step 401000: 140.495616\n",
      "Time: 55.8174951077\n",
      "Graph 401: 525 nodes\n",
      "Average loss at step 401100: 124.735334\n",
      "Average loss at step 401200: 116.312262\n",
      "Average loss at step 401300: 114.014368\n",
      "Average loss at step 401400: 118.088007\n",
      "Average loss at step 401500: 112.007255\n",
      "Average loss at step 401600: 119.491279\n",
      "Average loss at step 401700: 116.799090\n",
      "Average loss at step 401800: 118.292216\n",
      "Average loss at step 401900: 118.347414\n",
      "Average loss at step 402000: 118.020944\n",
      "Graph 402: 628 nodes\n",
      "Average loss at step 402100: 105.922964\n",
      "Average loss at step 402200: 98.788105\n",
      "Average loss at step 402300: 97.939875\n",
      "Average loss at step 402400: 98.716833\n",
      "Average loss at step 402500: 97.859283\n",
      "Average loss at step 402600: 97.054971\n",
      "Average loss at step 402700: 99.412694\n",
      "Average loss at step 402800: 99.972049\n",
      "Average loss at step 402900: 96.577972\n",
      "Average loss at step 403000: 98.909691\n",
      "Graph 403: 640 nodes\n",
      "Average loss at step 403100: 127.765015\n",
      "Average loss at step 403200: 131.657341\n",
      "Average loss at step 403300: 120.867565\n",
      "Average loss at step 403400: 129.324244\n",
      "Average loss at step 403500: 126.808971\n",
      "Average loss at step 403600: 128.524975\n",
      "Average loss at step 403700: 123.176427\n",
      "Average loss at step 403800: 121.558370\n",
      "Average loss at step 403900: 122.232469\n",
      "Average loss at step 404000: 126.346158\n",
      "Graph 404: 566 nodes\n",
      "Average loss at step 404100: 116.345424\n",
      "Average loss at step 404200: 100.814065\n",
      "Average loss at step 404300: 103.793206\n",
      "Average loss at step 404400: 102.010699\n",
      "Average loss at step 404500: 105.514848\n",
      "Average loss at step 404600: 104.828987\n",
      "Average loss at step 404700: 106.317471\n",
      "Average loss at step 404800: 102.158807\n",
      "Average loss at step 404900: 105.922276\n",
      "Average loss at step 405000: 102.722045\n",
      "Graph 405: 582 nodes\n",
      "Average loss at step 405100: 117.919639\n",
      "Average loss at step 405200: 117.389972\n",
      "Average loss at step 405300: 111.854639\n",
      "Average loss at step 405400: 114.724075\n",
      "Average loss at step 405500: 117.079563\n",
      "Average loss at step 405600: 117.100423\n",
      "Average loss at step 405700: 112.553849\n",
      "Average loss at step 405800: 112.365887\n",
      "Average loss at step 405900: 120.488521\n",
      "Average loss at step 406000: 113.732296\n",
      "Graph 406: 590 nodes\n",
      "Average loss at step 406100: 104.956582\n",
      "Average loss at step 406200: 98.435023\n",
      "Average loss at step 406300: 101.119694\n",
      "Average loss at step 406400: 102.720230\n",
      "Average loss at step 406500: 102.597495\n",
      "Average loss at step 406600: 90.640151\n",
      "Average loss at step 406700: 97.646117\n",
      "Average loss at step 406800: 100.199374\n",
      "Average loss at step 406900: 100.476785\n",
      "Average loss at step 407000: 98.230190\n",
      "Graph 407: 634 nodes\n",
      "Average loss at step 407100: 120.250096\n",
      "Average loss at step 407200: 118.830505\n",
      "Average loss at step 407300: 120.406922\n",
      "Average loss at step 407400: 118.048739\n",
      "Average loss at step 407500: 117.372161\n",
      "Average loss at step 407600: 117.313652\n",
      "Average loss at step 407700: 120.280514\n",
      "Average loss at step 407800: 118.386224\n",
      "Average loss at step 407900: 116.827848\n",
      "Average loss at step 408000: 119.952728\n",
      "Graph 408: 597 nodes\n",
      "Average loss at step 408100: 124.708461\n",
      "Average loss at step 408200: 121.254596\n",
      "Average loss at step 408300: 121.607848\n",
      "Average loss at step 408400: 120.655951\n",
      "Average loss at step 408500: 119.931708\n",
      "Average loss at step 408600: 122.792546\n",
      "Average loss at step 408700: 115.402173\n",
      "Average loss at step 408800: 117.991806\n",
      "Average loss at step 408900: 120.922635\n",
      "Average loss at step 409000: 119.743441\n",
      "Graph 409: 547 nodes\n",
      "Average loss at step 409100: 120.370967\n",
      "Average loss at step 409200: 113.437165\n",
      "Average loss at step 409300: 114.323127\n",
      "Average loss at step 409400: 117.809326\n",
      "Average loss at step 409500: 112.969911\n",
      "Average loss at step 409600: 111.813701\n",
      "Average loss at step 409700: 112.780242\n",
      "Average loss at step 409800: 112.472162\n",
      "Average loss at step 409900: 115.953028\n",
      "Average loss at step 410000: 113.092879\n",
      "Graph 410: 258 nodes\n",
      "Average loss at step 410100: 109.501736\n",
      "Average loss at step 410200: 104.795346\n",
      "Average loss at step 410300: 107.489802\n",
      "Average loss at step 410400: 108.108393\n",
      "Average loss at step 410500: 106.909641\n",
      "Average loss at step 410600: 105.656306\n",
      "Average loss at step 410700: 108.500862\n",
      "Average loss at step 410800: 106.110896\n",
      "Average loss at step 410900: 105.900686\n",
      "Average loss at step 411000: 103.683649\n",
      "Time: 47.8033549786\n",
      "Graph 411: 584 nodes\n",
      "Average loss at step 411100: 112.738276\n",
      "Average loss at step 411200: 107.366767\n",
      "Average loss at step 411300: 109.104560\n",
      "Average loss at step 411400: 111.547944\n",
      "Average loss at step 411500: 107.739187\n",
      "Average loss at step 411600: 107.268695\n",
      "Average loss at step 411700: 109.843109\n",
      "Average loss at step 411800: 108.978445\n",
      "Average loss at step 411900: 110.408515\n",
      "Average loss at step 412000: 108.086140\n",
      "Graph 412: 565 nodes\n",
      "Average loss at step 412100: 109.645393\n",
      "Average loss at step 412200: 101.158388\n",
      "Average loss at step 412300: 100.197951\n",
      "Average loss at step 412400: 97.310892\n",
      "Average loss at step 412500: 105.951640\n",
      "Average loss at step 412600: 102.557105\n",
      "Average loss at step 412700: 99.891312\n",
      "Average loss at step 412800: 98.852488\n",
      "Average loss at step 412900: 100.157479\n",
      "Average loss at step 413000: 103.133692\n",
      "Graph 413: 552 nodes\n",
      "Average loss at step 413100: 129.232380\n",
      "Average loss at step 413200: 118.664445\n",
      "Average loss at step 413300: 118.663230\n",
      "Average loss at step 413400: 118.282741\n",
      "Average loss at step 413500: 121.833262\n",
      "Average loss at step 413600: 122.731714\n",
      "Average loss at step 413700: 118.505652\n",
      "Average loss at step 413800: 123.369495\n",
      "Average loss at step 413900: 118.652342\n",
      "Average loss at step 414000: 115.910757\n",
      "Graph 414: 539 nodes\n",
      "Average loss at step 414100: 111.169420\n",
      "Average loss at step 414200: 105.601746\n",
      "Average loss at step 414300: 108.242890\n",
      "Average loss at step 414400: 108.586796\n",
      "Average loss at step 414500: 106.194407\n",
      "Average loss at step 414600: 107.268683\n",
      "Average loss at step 414700: 100.076798\n",
      "Average loss at step 414800: 107.825296\n",
      "Average loss at step 414900: 101.299460\n",
      "Average loss at step 415000: 106.874596\n",
      "Graph 415: 573 nodes\n",
      "Average loss at step 415100: 141.291293\n",
      "Average loss at step 415200: 131.863833\n",
      "Average loss at step 415300: 134.754512\n",
      "Average loss at step 415400: 131.812362\n",
      "Average loss at step 415500: 131.688449\n",
      "Average loss at step 415600: 129.342229\n",
      "Average loss at step 415700: 133.899548\n",
      "Average loss at step 415800: 130.779610\n",
      "Average loss at step 415900: 133.535950\n",
      "Average loss at step 416000: 130.319463\n",
      "Graph 416: 697 nodes\n",
      "Average loss at step 416100: 142.070786\n",
      "Average loss at step 416200: 139.911151\n",
      "Average loss at step 416300: 136.670597\n",
      "Average loss at step 416400: 135.716953\n",
      "Average loss at step 416500: 138.549408\n",
      "Average loss at step 416600: 135.926552\n",
      "Average loss at step 416700: 127.661202\n",
      "Average loss at step 416800: 130.594639\n",
      "Average loss at step 416900: 136.387884\n",
      "Average loss at step 417000: 134.658105\n",
      "Graph 417: 1771 nodes\n",
      "Average loss at step 417100: 43.229965\n",
      "Average loss at step 417200: 43.286512\n",
      "Average loss at step 417300: 43.222432\n",
      "Average loss at step 417400: 44.398990\n",
      "Average loss at step 417500: 41.863140\n",
      "Average loss at step 417600: 41.665361\n",
      "Average loss at step 417700: 43.199314\n",
      "Average loss at step 417800: 42.127648\n",
      "Average loss at step 417900: 41.841045\n",
      "Average loss at step 418000: 40.385923\n",
      "Graph 418: 590 nodes\n",
      "Average loss at step 418100: 145.740413\n",
      "Average loss at step 418200: 148.134942\n",
      "Average loss at step 418300: 147.944547\n",
      "Average loss at step 418400: 146.632040\n",
      "Average loss at step 418500: 148.386143\n",
      "Average loss at step 418600: 150.339152\n",
      "Average loss at step 418700: 149.443676\n",
      "Average loss at step 418800: 149.058310\n",
      "Average loss at step 418900: 147.113512\n",
      "Average loss at step 419000: 143.943483\n",
      "Graph 419: 542 nodes\n",
      "Average loss at step 419100: 151.771574\n",
      "Average loss at step 419200: 142.210652\n",
      "Average loss at step 419300: 135.986208\n",
      "Average loss at step 419400: 138.812490\n",
      "Average loss at step 419500: 143.671589\n",
      "Average loss at step 419600: 142.962623\n",
      "Average loss at step 419700: 141.795076\n",
      "Average loss at step 419800: 140.259975\n",
      "Average loss at step 419900: 142.348732\n",
      "Average loss at step 420000: 138.828672\n",
      "Graph 420: 585 nodes\n",
      "Average loss at step 420100: 148.830547\n",
      "Average loss at step 420200: 143.480142\n",
      "Average loss at step 420300: 142.533661\n",
      "Average loss at step 420400: 139.403363\n",
      "Average loss at step 420500: 140.349688\n",
      "Average loss at step 420600: 145.871516\n",
      "Average loss at step 420700: 140.017308\n",
      "Average loss at step 420800: 142.641680\n",
      "Average loss at step 420900: 146.401270\n",
      "Average loss at step 421000: 142.007561\n",
      "Time: 54.0975949764\n",
      "Graph 421: 637 nodes\n",
      "Average loss at step 421100: 150.360983\n",
      "Average loss at step 421200: 146.213942\n",
      "Average loss at step 421300: 142.780768\n",
      "Average loss at step 421400: 141.554482\n",
      "Average loss at step 421500: 139.087854\n",
      "Average loss at step 421600: 139.362543\n",
      "Average loss at step 421700: 140.801151\n",
      "Average loss at step 421800: 139.939867\n",
      "Average loss at step 421900: 146.991883\n",
      "Average loss at step 422000: 144.219396\n",
      "Graph 422: 638 nodes\n",
      "Average loss at step 422100: 175.689295\n",
      "Average loss at step 422200: 143.813992\n",
      "Average loss at step 422300: 150.934858\n",
      "Average loss at step 422400: 145.830743\n",
      "Average loss at step 422500: 143.874191\n",
      "Average loss at step 422600: 147.866446\n",
      "Average loss at step 422700: 141.891321\n",
      "Average loss at step 422800: 144.148458\n",
      "Average loss at step 422900: 141.539789\n",
      "Average loss at step 423000: 144.333925\n",
      "Graph 423: 241 nodes\n",
      "Average loss at step 423100: 103.393366\n",
      "Average loss at step 423200: 104.508855\n",
      "Average loss at step 423300: 99.407156\n",
      "Average loss at step 423400: 102.272000\n",
      "Average loss at step 423500: 100.503021\n",
      "Average loss at step 423600: 102.676778\n",
      "Average loss at step 423700: 102.061263\n",
      "Average loss at step 423800: 102.744708\n",
      "Average loss at step 423900: 99.179789\n",
      "Average loss at step 424000: 100.913175\n",
      "Graph 424: 150 nodes\n",
      "Average loss at step 424100: 105.091752\n",
      "Average loss at step 424200: 102.670787\n",
      "Average loss at step 424300: 99.664296\n",
      "Average loss at step 424400: 100.595678\n",
      "Average loss at step 424500: 103.643120\n",
      "Average loss at step 424600: 103.254434\n",
      "Average loss at step 424700: 104.036227\n",
      "Average loss at step 424800: 100.986178\n",
      "Average loss at step 424900: 100.900167\n",
      "Average loss at step 425000: 98.256067\n",
      "Graph 425: 175 nodes\n",
      "Average loss at step 425100: 119.423308\n",
      "Average loss at step 425200: 105.136563\n",
      "Average loss at step 425300: 104.278036\n",
      "Average loss at step 425400: 104.150047\n",
      "Average loss at step 425500: 102.889938\n",
      "Average loss at step 425600: 100.570926\n",
      "Average loss at step 425700: 102.063966\n",
      "Average loss at step 425800: 99.204297\n",
      "Average loss at step 425900: 103.466029\n",
      "Average loss at step 426000: 99.793720\n",
      "Graph 426: 223 nodes\n",
      "Average loss at step 426100: 129.770658\n",
      "Average loss at step 426200: 123.871872\n",
      "Average loss at step 426300: 119.396973\n",
      "Average loss at step 426400: 123.749191\n",
      "Average loss at step 426500: 121.419614\n",
      "Average loss at step 426600: 125.094334\n",
      "Average loss at step 426700: 125.503817\n",
      "Average loss at step 426800: 122.131458\n",
      "Average loss at step 426900: 123.326892\n",
      "Average loss at step 427000: 122.445151\n",
      "Graph 427: 210 nodes\n",
      "Average loss at step 427100: 132.244615\n",
      "Average loss at step 427200: 112.528213\n",
      "Average loss at step 427300: 111.315633\n",
      "Average loss at step 427400: 108.459829\n",
      "Average loss at step 427500: 107.580199\n",
      "Average loss at step 427600: 103.047085\n",
      "Average loss at step 427700: 108.656460\n",
      "Average loss at step 427800: 102.110513\n",
      "Average loss at step 427900: 108.876080\n",
      "Average loss at step 428000: 107.952608\n",
      "Graph 428: 196 nodes\n",
      "Average loss at step 428100: 120.350342\n",
      "Average loss at step 428200: 116.996787\n",
      "Average loss at step 428300: 113.399317\n",
      "Average loss at step 428400: 112.968588\n",
      "Average loss at step 428500: 116.320271\n",
      "Average loss at step 428600: 111.693399\n",
      "Average loss at step 428700: 119.383454\n",
      "Average loss at step 428800: 111.117657\n",
      "Average loss at step 428900: 107.755408\n",
      "Average loss at step 429000: 115.296493\n",
      "Graph 429: 149 nodes\n",
      "Average loss at step 429100: 98.217598\n",
      "Average loss at step 429200: 103.377840\n",
      "Average loss at step 429300: 96.797453\n",
      "Average loss at step 429400: 97.828076\n",
      "Average loss at step 429500: 99.138727\n",
      "Average loss at step 429600: 95.896358\n",
      "Average loss at step 429700: 98.098151\n",
      "Average loss at step 429800: 96.225586\n",
      "Average loss at step 429900: 97.549031\n",
      "Average loss at step 430000: 94.672224\n",
      "Graph 430: 39 nodes\n",
      "Average loss at step 430100: 62.953373\n",
      "Average loss at step 430200: 53.477869\n",
      "Average loss at step 430300: 53.139553\n",
      "Average loss at step 430400: 54.021429\n",
      "Average loss at step 430500: 57.608582\n",
      "Average loss at step 430600: 52.558821\n",
      "Average loss at step 430700: 53.300402\n",
      "Average loss at step 430800: 54.209854\n",
      "Average loss at step 430900: 55.911673\n",
      "Average loss at step 431000: 51.467243\n",
      "Time: 43.7242369652\n",
      "Graph 431: 196 nodes\n",
      "Average loss at step 431100: 108.387886\n",
      "Average loss at step 431200: 101.001823\n",
      "Average loss at step 431300: 102.785216\n",
      "Average loss at step 431400: 100.509119\n",
      "Average loss at step 431500: 97.119325\n",
      "Average loss at step 431600: 101.661118\n",
      "Average loss at step 431700: 104.775305\n",
      "Average loss at step 431800: 101.475604\n",
      "Average loss at step 431900: 101.465397\n",
      "Average loss at step 432000: 102.035271\n",
      "Graph 432: 154 nodes\n",
      "Average loss at step 432100: 120.881195\n",
      "Average loss at step 432200: 115.396763\n",
      "Average loss at step 432300: 117.834188\n",
      "Average loss at step 432400: 114.992756\n",
      "Average loss at step 432500: 112.744422\n",
      "Average loss at step 432600: 115.636442\n",
      "Average loss at step 432700: 116.080499\n",
      "Average loss at step 432800: 109.295525\n",
      "Average loss at step 432900: 111.080411\n",
      "Average loss at step 433000: 112.817385\n",
      "Graph 433: 165 nodes\n",
      "Average loss at step 433100: 91.410058\n",
      "Average loss at step 433200: 88.936911\n",
      "Average loss at step 433300: 87.883333\n",
      "Average loss at step 433400: 89.049849\n",
      "Average loss at step 433500: 84.785858\n",
      "Average loss at step 433600: 87.046655\n",
      "Average loss at step 433700: 83.532561\n",
      "Average loss at step 433800: 84.548164\n",
      "Average loss at step 433900: 89.765054\n",
      "Average loss at step 434000: 86.979145\n",
      "Graph 434: 183 nodes\n",
      "Average loss at step 434100: 123.458076\n",
      "Average loss at step 434200: 112.545306\n",
      "Average loss at step 434300: 114.786922\n",
      "Average loss at step 434400: 117.620809\n",
      "Average loss at step 434500: 114.486660\n",
      "Average loss at step 434600: 109.926308\n",
      "Average loss at step 434700: 112.670913\n",
      "Average loss at step 434800: 112.373099\n",
      "Average loss at step 434900: 106.502770\n",
      "Average loss at step 435000: 113.303613\n",
      "Graph 435: 220 nodes\n",
      "Average loss at step 435100: 126.599339\n",
      "Average loss at step 435200: 113.551652\n",
      "Average loss at step 435300: 120.441904\n",
      "Average loss at step 435400: 120.415997\n",
      "Average loss at step 435500: 113.318972\n",
      "Average loss at step 435600: 115.965395\n",
      "Average loss at step 435700: 117.181124\n",
      "Average loss at step 435800: 114.410519\n",
      "Average loss at step 435900: 122.483303\n",
      "Average loss at step 436000: 113.220434\n",
      "Graph 436: 188 nodes\n",
      "Average loss at step 436100: 119.732516\n",
      "Average loss at step 436200: 119.445357\n",
      "Average loss at step 436300: 114.855851\n",
      "Average loss at step 436400: 116.169034\n",
      "Average loss at step 436500: 120.043125\n",
      "Average loss at step 436600: 117.232844\n",
      "Average loss at step 436700: 121.613499\n",
      "Average loss at step 436800: 118.421837\n",
      "Average loss at step 436900: 118.204022\n",
      "Average loss at step 437000: 113.479122\n",
      "Graph 437: 206 nodes\n",
      "Average loss at step 437100: 123.679277\n",
      "Average loss at step 437200: 114.357777\n",
      "Average loss at step 437300: 114.742475\n",
      "Average loss at step 437400: 116.626352\n",
      "Average loss at step 437500: 112.683309\n",
      "Average loss at step 437600: 111.424452\n",
      "Average loss at step 437700: 111.075959\n",
      "Average loss at step 437800: 118.806185\n",
      "Average loss at step 437900: 116.543241\n",
      "Average loss at step 438000: 113.017797\n",
      "Graph 438: 203 nodes\n",
      "Average loss at step 438100: 136.022005\n",
      "Average loss at step 438200: 112.525379\n",
      "Average loss at step 438300: 111.842679\n",
      "Average loss at step 438400: 106.971614\n",
      "Average loss at step 438500: 108.279008\n",
      "Average loss at step 438600: 108.620875\n",
      "Average loss at step 438700: 103.995798\n",
      "Average loss at step 438800: 105.018696\n",
      "Average loss at step 438900: 106.509104\n",
      "Average loss at step 439000: 109.567424\n",
      "Graph 439: 163 nodes\n",
      "Average loss at step 439100: 138.726825\n",
      "Average loss at step 439200: 127.087876\n",
      "Average loss at step 439300: 129.495847\n",
      "Average loss at step 439400: 128.670172\n",
      "Average loss at step 439500: 129.256365\n",
      "Average loss at step 439600: 123.271457\n",
      "Average loss at step 439700: 127.823131\n",
      "Average loss at step 439800: 121.563107\n",
      "Average loss at step 439900: 128.149046\n",
      "Average loss at step 440000: 122.038310\n",
      "Graph 440: 149 nodes\n",
      "Average loss at step 440100: 152.717413\n",
      "Average loss at step 440200: 131.612154\n",
      "Average loss at step 440300: 125.599125\n",
      "Average loss at step 440400: 127.140337\n",
      "Average loss at step 440500: 123.329682\n",
      "Average loss at step 440600: 122.706602\n",
      "Average loss at step 440700: 124.442695\n",
      "Average loss at step 440800: 126.895416\n",
      "Average loss at step 440900: 128.491787\n",
      "Average loss at step 441000: 125.661034\n",
      "Time: 57.4582300186\n",
      "Graph 441: 142 nodes\n",
      "Average loss at step 441100: 146.848394\n",
      "Average loss at step 441200: 130.439968\n",
      "Average loss at step 441300: 127.734133\n",
      "Average loss at step 441400: 129.372630\n",
      "Average loss at step 441500: 122.368629\n",
      "Average loss at step 441600: 125.078063\n",
      "Average loss at step 441700: 126.509084\n",
      "Average loss at step 441800: 131.268262\n",
      "Average loss at step 441900: 126.987750\n",
      "Average loss at step 442000: 123.460121\n",
      "Graph 442: 159 nodes\n",
      "Average loss at step 442100: 133.694868\n",
      "Average loss at step 442200: 124.527655\n",
      "Average loss at step 442300: 120.067837\n",
      "Average loss at step 442400: 116.209461\n",
      "Average loss at step 442500: 116.640760\n",
      "Average loss at step 442600: 118.405322\n",
      "Average loss at step 442700: 116.803353\n",
      "Average loss at step 442800: 120.847868\n",
      "Average loss at step 442900: 116.250459\n",
      "Average loss at step 443000: 113.567531\n",
      "Graph 443: 181 nodes\n",
      "Average loss at step 443100: 124.317038\n",
      "Average loss at step 443200: 108.329986\n",
      "Average loss at step 443300: 113.430359\n",
      "Average loss at step 443400: 107.553778\n",
      "Average loss at step 443500: 107.313578\n",
      "Average loss at step 443600: 110.013809\n",
      "Average loss at step 443700: 107.176476\n",
      "Average loss at step 443800: 106.315271\n",
      "Average loss at step 443900: 104.861392\n",
      "Average loss at step 444000: 113.000995\n",
      "Graph 444: 172 nodes\n",
      "Average loss at step 444100: 151.754750\n",
      "Average loss at step 444200: 140.952470\n",
      "Average loss at step 444300: 147.110677\n",
      "Average loss at step 444400: 140.955783\n",
      "Average loss at step 444500: 140.471345\n",
      "Average loss at step 444600: 141.001245\n",
      "Average loss at step 444700: 144.820767\n",
      "Average loss at step 444800: 143.337272\n",
      "Average loss at step 444900: 148.023286\n",
      "Average loss at step 445000: 141.019468\n",
      "Graph 445: 112 nodes\n",
      "Average loss at step 445100: 113.860125\n",
      "Average loss at step 445200: 97.517125\n",
      "Average loss at step 445300: 94.458512\n",
      "Average loss at step 445400: 86.591844\n",
      "Average loss at step 445500: 91.273526\n",
      "Average loss at step 445600: 87.791632\n",
      "Average loss at step 445700: 85.478791\n",
      "Average loss at step 445800: 91.400764\n",
      "Average loss at step 445900: 86.202637\n",
      "Average loss at step 446000: 92.995650\n",
      "Graph 446: 163 nodes\n",
      "Average loss at step 446100: 106.884447\n",
      "Average loss at step 446200: 97.683602\n",
      "Average loss at step 446300: 104.584009\n",
      "Average loss at step 446400: 98.821795\n",
      "Average loss at step 446500: 103.325979\n",
      "Average loss at step 446600: 101.164461\n",
      "Average loss at step 446700: 102.392264\n",
      "Average loss at step 446800: 99.357386\n",
      "Average loss at step 446900: 100.523415\n",
      "Average loss at step 447000: 98.420252\n",
      "Graph 447: 127 nodes\n",
      "Average loss at step 447100: 109.797360\n",
      "Average loss at step 447200: 99.011054\n",
      "Average loss at step 447300: 101.802697\n",
      "Average loss at step 447400: 98.001123\n",
      "Average loss at step 447500: 96.364011\n",
      "Average loss at step 447600: 96.059323\n",
      "Average loss at step 447700: 95.731099\n",
      "Average loss at step 447800: 90.848407\n",
      "Average loss at step 447900: 96.049463\n",
      "Average loss at step 448000: 98.450056\n",
      "Graph 448: 157 nodes\n",
      "Average loss at step 448100: 106.540390\n",
      "Average loss at step 448200: 104.559374\n",
      "Average loss at step 448300: 104.389704\n",
      "Average loss at step 448400: 98.090571\n",
      "Average loss at step 448500: 98.874271\n",
      "Average loss at step 448600: 96.309563\n",
      "Average loss at step 448700: 104.058461\n",
      "Average loss at step 448800: 96.355199\n",
      "Average loss at step 448900: 96.252696\n",
      "Average loss at step 449000: 100.882369\n",
      "Graph 449: 117 nodes\n",
      "Average loss at step 449100: 108.650620\n",
      "Average loss at step 449200: 102.287728\n",
      "Average loss at step 449300: 104.300911\n",
      "Average loss at step 449400: 100.220288\n",
      "Average loss at step 449500: 96.604175\n",
      "Average loss at step 449600: 101.480710\n",
      "Average loss at step 449700: 101.004542\n",
      "Average loss at step 449800: 99.184731\n",
      "Average loss at step 449900: 101.877768\n",
      "Average loss at step 450000: 100.869082\n",
      "Graph 450: 121 nodes\n",
      "Average loss at step 450100: 112.906905\n",
      "Average loss at step 450200: 107.301641\n",
      "Average loss at step 450300: 103.990007\n",
      "Average loss at step 450400: 106.683175\n",
      "Average loss at step 450500: 104.929585\n",
      "Average loss at step 450600: 104.600072\n",
      "Average loss at step 450700: 102.015479\n",
      "Average loss at step 450800: 102.735970\n",
      "Average loss at step 450900: 102.735478\n",
      "Average loss at step 451000: 103.934991\n",
      "Time: 48.7479498386\n",
      "Graph 451: 140 nodes\n",
      "Average loss at step 451100: 105.352437\n",
      "Average loss at step 451200: 100.168134\n",
      "Average loss at step 451300: 96.866020\n",
      "Average loss at step 451400: 96.562509\n",
      "Average loss at step 451500: 99.387177\n",
      "Average loss at step 451600: 96.322575\n",
      "Average loss at step 451700: 96.109035\n",
      "Average loss at step 451800: 96.357451\n",
      "Average loss at step 451900: 98.750247\n",
      "Average loss at step 452000: 98.011600\n",
      "Graph 452: 162 nodes\n",
      "Average loss at step 452100: 110.130933\n",
      "Average loss at step 452200: 108.402828\n",
      "Average loss at step 452300: 99.211025\n",
      "Average loss at step 452400: 100.782546\n",
      "Average loss at step 452500: 105.263892\n",
      "Average loss at step 452600: 101.393969\n",
      "Average loss at step 452700: 101.876368\n",
      "Average loss at step 452800: 97.865003\n",
      "Average loss at step 452900: 103.677819\n",
      "Average loss at step 453000: 103.497686\n",
      "Graph 453: 137 nodes\n",
      "Average loss at step 453100: 144.676886\n",
      "Average loss at step 453200: 138.899066\n",
      "Average loss at step 453300: 137.359160\n",
      "Average loss at step 453400: 137.248561\n",
      "Average loss at step 453500: 138.324428\n",
      "Average loss at step 453600: 136.457351\n",
      "Average loss at step 453700: 137.057290\n",
      "Average loss at step 453800: 138.809219\n",
      "Average loss at step 453900: 133.136246\n",
      "Average loss at step 454000: 135.653370\n",
      "Graph 454: 116 nodes\n",
      "Average loss at step 454100: 144.140616\n",
      "Average loss at step 454200: 138.517969\n",
      "Average loss at step 454300: 136.901157\n",
      "Average loss at step 454400: 137.552138\n",
      "Average loss at step 454500: 134.537988\n",
      "Average loss at step 454600: 132.103531\n",
      "Average loss at step 454700: 134.817777\n",
      "Average loss at step 454800: 132.029468\n",
      "Average loss at step 454900: 133.230019\n",
      "Average loss at step 455000: 133.748050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AnonymousWalkEmbeddings.AWE at 0x1a28703110>"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'res_graphs'\n",
    "\n",
    "batch_size = 100\n",
    "window_size = 8\n",
    "embedding_size_w = 64\n",
    "embedding_size_d = 64\n",
    "num_samples = 128\n",
    "\n",
    "concat = False\n",
    "loss_type = 'sampled_softmax'\n",
    "optimize = 'Adagrad'\n",
    "learning_rate = 1.0\n",
    "root = '../enron/'\n",
    "ext = 'graphml'\n",
    "steps = 7\n",
    "epochs = 1\n",
    "batches_per_epoch = 1000\n",
    "candidate_func = 'uniform'\n",
    "graph_labels = None\n",
    "\n",
    "model = AnonymousWalkEmbeddings.AWE(dataset = dataset, batch_size = batch_size, window_size = window_size,\n",
    "                  embedding_size_w = embedding_size_w, embedding_size_d = embedding_size_d,\n",
    "                  num_samples = num_samples, concat = concat, loss_type = loss_type,\n",
    "                  optimize = optimize, learning_rate = learning_rate, root = root,\n",
    "                  ext = ext, steps = steps, epochs = epochs, batches_per_epoch = batches_per_epoch,\n",
    "                  candidate_func = candidate_func, graph_labels=graph_labels)\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Подгрузим разметку для графов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "labels = open('../enron/res_graphs/labels.txt')\n",
    "labels = labels.read()\n",
    "labels = np.array(map(lambda x: int(x), labels.strip().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels1 = open('../enron/parsed_graphs/labels.txt')\n",
    "labels1 = labels1.read()\n",
    "labels1 = np.array(map(lambda x: int(x), labels1.strip().split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### PCA approximation\n",
    "Здесь пробуем построить для части графов pca и потом посчитать проекции следующих эмбедингов на полученные направления. Нас интересует, как хорошо полученные проекции могут аппроксимировать сами эмбединги.\n",
    "\n",
    "Видим, что аутлаеры не особо выбиваются из общего паттерна. Дальше попробуем посмотреть, чем можно такое поведение объяснить. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a297ff0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca_comp_number = 300\n",
    "\n",
    "test_set = model.graph_embeddings[:pca_comp_number]\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(scale(test_set))\n",
    "\n",
    "projection_set = pca.components_[:]\n",
    "\n",
    "res = []\n",
    "for embedding in model.graph_embeddings[pca_comp_number:]:\n",
    "    proj = projection_on_set(embedding, projection_set)\n",
    "    res.append(np.linalg.norm(embedding - proj))\n",
    "res = np.array(res)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(np.where(labels[pca_comp_number:] == 0)[0]+pca_comp_number, \n",
    "            res[np.where(labels[pca_comp_number:] == 0)[0]], label='normal', c='b')\n",
    "plt.scatter(np.where(labels[pca_comp_number:] == 1)[0]+pca_comp_number, \n",
    "            res[np.where(labels[pca_comp_number:] == 1)[0]], label='outlier', c='r')\n",
    "plt.xlabel(\"days\")\n",
    "plt.ylabel(\"$||X - X_{approx}||$\")\n",
    "plt.title(\"PCA approximation quality on time\")\n",
    "plt.legend()\n",
    "plt.grid(ls='dashed')\n",
    "#fig.savefig('graph_series_without_norm.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Norm differences \n",
    "\n",
    "Посмотрим, как меняются векторы эмбедингов от времени. Для этого, например, можно порисовать норму разностей двух последующих векторов. Как видно из графиков какой-то хорошей шшеометрической структуры пока не получили."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEWCAYAAACT7WsrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD+HxE1v6nMVnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2819f610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i, label in zip(range(len(labels[:-1])), labels[:-1]):\n",
    "    if label == 0:\n",
    "        plt.scatter(i, np.linalg.norm(model.graph_embeddings[i+1] - model.graph_embeddings[i]), c='b')\n",
    "    else:\n",
    "        plt.scatter(i, np.linalg.norm(model.graph_embeddings[i+1] - model.graph_embeddings[i]), c='r')\n",
    "    \n",
    "plt.xlabel('days')\n",
    "plt.ylabel('$||X_{i+1} - X_{i}||$')\n",
    "plt.title(\"Norm of embedding differences on time\")\n",
    "plt.grid(alpha=0.6)\n",
    "#fig.savefig('difference_embedding.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Norm series \n",
    "\n",
    "Есть предположение о том, что аутлаеры сильно будут отличаться по норме от обычных векторов. Построим график зависимости норм векторов от времени. Получаем, что мало того, что аутлаеры не выбиваются из общей кучи, так еще необычное поведение с ростом нормы эмбедингов. Дальше попробуем разобраться, чем оно вызвано."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEWCAYAAACT7WsrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a285b6610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "norms = np.linalg.norm(model.graph_embeddings, axis=1)\n",
    "\n",
    "plt.scatter(np.where(labels == 0)[0], norms[np.where(labels == 0)[0]], label='normal', c='b')\n",
    "plt.scatter(np.where(labels == 1)[0], norms[np.where(labels == 1)[0]], label='outlier', c='r')\n",
    "\n",
    "plt.xlabel(\"days\")\n",
    "plt.ylabel(\"$||X||$\")\n",
    "plt.title(\"Norm of embedding on time\")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(ls='dashed')\n",
    "#fig.savefig('norms_series.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Norm growth\n",
    "\n",
    "Попробуем более отдельно рассмотреть вопрос с прошлого пункта. Интерсно, чем конкретно вызвано такое поведение у эмбедингов: либо это специфика модели, либо датасета. \n",
    "\n",
    "Чтобы проверить это предположение попробуем случайно помешать первые графы при обучении и снова отрисовать графики зависимости нормы от времени.\n",
    "\n",
    "Получаем, что на самом деле такой вид графика не зависит от датасета, а относится к самой модели. Плюс к этому, вид графика завист от парметра batches_per_epoch. Чем он больше, тем более гладким получается график. При совсем мелких значениях такая зависимость нормы от времени пропадает. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs: 637\n",
      "Number of words: 52\n",
      "Initialized\n",
      "Epoch: 0\n",
      "Graph 0: 20 nodes\n",
      "Time: 0.71936416626\n",
      "Graph 1: 277 nodes\n",
      "Graph 2: 274 nodes\n",
      "Graph 3: 278 nodes\n",
      "Graph 4: 293 nodes\n",
      "Graph 5: 262 nodes\n",
      "Graph 6: 9 nodes\n",
      "Graph 7: 8 nodes\n",
      "Graph 8: 31 nodes\n",
      "Graph 9: 32 nodes\n",
      "Average loss at step 100: 2627.964609\n",
      "Graph 10: 264 nodes\n",
      "Time: 0.589840173721\n",
      "Graph 11: 229 nodes\n",
      "Graph 12: 230 nodes\n",
      "Graph 13: 18 nodes\n",
      "Graph 14: 24 nodes\n",
      "Graph 15: 306 nodes\n",
      "Graph 16: 262 nodes\n",
      "Graph 17: 229 nodes\n",
      "Graph 18: 277 nodes\n",
      "Graph 19: 200 nodes\n",
      "Average loss at step 200: 606.774198\n",
      "Graph 20: 16 nodes\n",
      "Time: 0.440363883972\n",
      "Graph 21: 12 nodes\n",
      "Graph 22: 232 nodes\n",
      "Graph 23: 245 nodes\n",
      "Graph 24: 252 nodes\n",
      "Graph 25: 207 nodes\n",
      "Graph 26: 207 nodes\n",
      "Graph 27: 8 nodes\n",
      "Graph 28: 50 nodes\n",
      "Graph 29: 249 nodes\n",
      "Average loss at step 300: 235.295613\n",
      "Graph 30: 263 nodes\n",
      "Time: 0.569179058075\n",
      "Graph 31: 237 nodes\n",
      "Graph 32: 248 nodes\n",
      "Graph 33: 250 nodes\n",
      "Graph 34: 13 nodes\n",
      "Graph 35: 45 nodes\n",
      "Graph 36: 333 nodes\n",
      "Graph 37: 266 nodes\n",
      "Graph 38: 241 nodes\n",
      "Graph 39: 235 nodes\n",
      "Average loss at step 400: 211.649718\n",
      "Graph 40: 244 nodes\n",
      "Time: 0.718559026718\n",
      "Graph 41: 15 nodes\n",
      "Graph 42: 42 nodes\n",
      "Graph 43: 257 nodes\n",
      "Graph 44: 242 nodes\n",
      "Graph 45: 260 nodes\n",
      "Graph 46: 236 nodes\n",
      "Graph 47: 263 nodes\n",
      "Graph 48: 10 nodes\n",
      "Graph 49: 21 nodes\n",
      "Average loss at step 500: 148.818047\n",
      "Graph 50: 236 nodes\n",
      "Time: 0.46209192276\n",
      "Graph 51: 266 nodes\n",
      "Graph 52: 295 nodes\n",
      "Graph 53: 270 nodes\n",
      "Graph 54: 249 nodes\n",
      "Graph 55: 10 nodes\n",
      "Graph 56: 48 nodes\n",
      "Graph 57: 308 nodes\n",
      "Graph 58: 300 nodes\n",
      "Graph 59: 340 nodes\n",
      "Average loss at step 600: 132.938907\n",
      "Graph 60: 303 nodes\n",
      "Time: 0.599319934845\n",
      "Graph 61: 316 nodes\n",
      "Graph 62: 31 nodes\n",
      "Graph 63: 39 nodes\n",
      "Graph 64: 381 nodes\n",
      "Graph 65: 367 nodes\n",
      "Graph 66: 352 nodes\n",
      "Graph 67: 321 nodes\n",
      "Graph 68: 290 nodes\n",
      "Graph 69: 13 nodes\n",
      "Average loss at step 700: 113.251860\n",
      "Graph 70: 20 nodes\n",
      "Time: 0.801142930984\n",
      "Graph 71: 44 nodes\n",
      "Graph 72: 302 nodes\n",
      "Graph 73: 340 nodes\n",
      "Graph 74: 336 nodes\n",
      "Graph 75: 330 nodes\n",
      "Graph 76: 28 nodes\n",
      "Graph 77: 62 nodes\n",
      "Graph 78: 351 nodes\n",
      "Graph 79: 304 nodes\n",
      "Average loss at step 800: 130.317491\n",
      "Graph 80: 318 nodes\n",
      "Time: 0.592924118042\n",
      "Graph 81: 315 nodes\n",
      "Graph 82: 304 nodes\n",
      "Graph 83: 26 nodes\n",
      "Graph 84: 53 nodes\n",
      "Graph 85: 339 nodes\n",
      "Graph 86: 329 nodes\n",
      "Graph 87: 357 nodes\n",
      "Graph 88: 349 nodes\n",
      "Graph 89: 315 nodes\n",
      "Average loss at step 900: 120.218543\n",
      "Graph 90: 21 nodes\n",
      "Time: 0.376842021942\n",
      "Graph 91: 44 nodes\n",
      "Graph 92: 364 nodes\n",
      "Graph 93: 367 nodes\n",
      "Graph 94: 391 nodes\n",
      "Graph 95: 323 nodes\n",
      "Graph 96: 305 nodes\n",
      "Graph 97: 24 nodes\n",
      "Graph 98: 53 nodes\n",
      "Graph 99: 377 nodes\n",
      "Average loss at step 1000: 108.740857\n",
      "Graph 100: 355 nodes\n",
      "Time: 0.558574914932\n",
      "Graph 101: 328 nodes\n",
      "Graph 102: 308 nodes\n",
      "Graph 103: 290 nodes\n",
      "Graph 104: 28 nodes\n",
      "Graph 105: 68 nodes\n",
      "Graph 106: 356 nodes\n",
      "Graph 107: 380 nodes\n",
      "Graph 108: 386 nodes\n",
      "Graph 109: 397 nodes\n",
      "Average loss at step 1100: 109.482390\n",
      "Graph 110: 341 nodes\n",
      "Time: 0.65504193306\n",
      "Graph 111: 32 nodes\n",
      "Graph 112: 48 nodes\n",
      "Graph 113: 343 nodes\n",
      "Graph 114: 410 nodes\n",
      "Graph 115: 351 nodes\n",
      "Graph 116: 334 nodes\n",
      "Graph 117: 335 nodes\n",
      "Graph 118: 30 nodes\n",
      "Graph 119: 42 nodes\n",
      "Average loss at step 1200: 94.182399\n",
      "Graph 120: 392 nodes\n",
      "Time: 0.735352039337\n",
      "Graph 121: 440 nodes\n",
      "Graph 122: 439 nodes\n",
      "Graph 123: 396 nodes\n",
      "Graph 124: 423 nodes\n",
      "Graph 125: 29 nodes\n",
      "Graph 126: 77 nodes\n",
      "Graph 127: 423 nodes\n",
      "Graph 128: 407 nodes\n",
      "Graph 129: 484 nodes\n",
      "Average loss at step 1300: 122.873484\n",
      "Graph 130: 434 nodes\n",
      "Time: 0.734303951263\n",
      "Graph 131: 358 nodes\n",
      "Graph 132: 43 nodes\n",
      "Graph 133: 63 nodes\n",
      "Graph 134: 484 nodes\n",
      "Graph 135: 499 nodes\n",
      "Graph 136: 419 nodes\n",
      "Graph 137: 523 nodes\n",
      "Graph 138: 508 nodes\n",
      "Graph 139: 38 nodes\n",
      "Average loss at step 1400: 105.492258\n",
      "Graph 140: 110 nodes\n",
      "Time: 0.621059179306\n",
      "Graph 141: 588 nodes\n",
      "Graph 142: 563 nodes\n",
      "Graph 143: 564 nodes\n",
      "Graph 144: 514 nodes\n",
      "Graph 145: 420 nodes\n",
      "Graph 146: 64 nodes\n",
      "Graph 147: 105 nodes\n",
      "Graph 148: 506 nodes\n",
      "Graph 149: 480 nodes\n",
      "Average loss at step 1500: 95.783273\n",
      "Graph 150: 410 nodes\n",
      "Time: 0.86288690567\n",
      "Graph 151: 49 nodes\n",
      "Graph 152: 54 nodes\n",
      "Graph 153: 30 nodes\n",
      "Graph 154: 132 nodes\n",
      "Graph 155: 607 nodes\n",
      "Graph 156: 682 nodes\n",
      "Graph 157: 720 nodes\n",
      "Graph 158: 630 nodes\n",
      "Graph 159: 568 nodes\n",
      "Average loss at step 1600: 89.071948\n",
      "Graph 160: 62 nodes\n",
      "Time: 0.827445030212\n",
      "Graph 161: 131 nodes\n",
      "Graph 162: 689 nodes\n",
      "Graph 163: 623 nodes\n",
      "Graph 164: 707 nodes\n",
      "Graph 165: 650 nodes\n",
      "Graph 166: 625 nodes\n",
      "Graph 167: 73 nodes\n",
      "Graph 168: 171 nodes\n",
      "Graph 169: 808 nodes\n",
      "Average loss at step 1700: 93.597006\n",
      "Graph 170: 897 nodes\n",
      "Time: 0.880839109421\n",
      "Graph 171: 958 nodes\n",
      "Graph 172: 397 nodes\n",
      "Graph 173: 339 nodes\n",
      "Graph 174: 18 nodes\n",
      "Graph 175: 59 nodes\n",
      "Graph 176: 378 nodes\n",
      "Graph 177: 374 nodes\n",
      "Graph 178: 375 nodes\n",
      "Graph 179: 317 nodes\n",
      "Average loss at step 1800: 104.495161\n",
      "Graph 180: 244 nodes\n",
      "Time: 0.628254175186\n",
      "Graph 181: 17 nodes\n",
      "Graph 182: 10 nodes\n",
      "Graph 183: 19 nodes\n",
      "Graph 184: 90 nodes\n",
      "Graph 185: 210 nodes\n",
      "Graph 186: 226 nodes\n",
      "Graph 187: 162 nodes\n",
      "Graph 188: 10 nodes\n",
      "Graph 189: 7 nodes\n",
      "Average loss at step 1900: 60.784049\n",
      "Graph 190: 62 nodes\n",
      "Time: 0.643234014511\n",
      "Graph 191: 349 nodes\n",
      "Graph 192: 341 nodes\n",
      "Graph 193: 365 nodes\n",
      "Graph 194: 334 nodes\n",
      "Graph 195: 21 nodes\n",
      "Graph 196: 70 nodes\n",
      "Graph 197: 364 nodes\n",
      "Graph 198: 339 nodes\n",
      "Graph 199: 344 nodes\n",
      "Average loss at step 2000: 100.717502\n",
      "Graph 200: 341 nodes\n",
      "Time: 0.751102924347\n",
      "Graph 201: 328 nodes\n",
      "Graph 202: 56 nodes\n",
      "Graph 203: 37 nodes\n",
      "Graph 204: 108 nodes\n",
      "Graph 205: 385 nodes\n",
      "Graph 206: 380 nodes\n",
      "Graph 207: 315 nodes\n",
      "Graph 208: 348 nodes\n",
      "Graph 209: 44 nodes\n",
      "Average loss at step 2100: 88.565771\n",
      "Graph 210: 78 nodes\n",
      "Time: 0.62127494812\n",
      "Graph 211: 411 nodes\n",
      "Graph 212: 415 nodes\n",
      "Graph 213: 429 nodes\n",
      "Graph 214: 378 nodes\n",
      "Graph 215: 405 nodes\n",
      "Graph 216: 33 nodes\n",
      "Graph 217: 44 nodes\n",
      "Graph 218: 407 nodes\n",
      "Graph 219: 397 nodes\n",
      "Average loss at step 2200: 95.076512\n",
      "Graph 220: 441 nodes\n",
      "Time: 0.486532211304\n",
      "Graph 221: 393 nodes\n",
      "Graph 222: 353 nodes\n",
      "Graph 223: 29 nodes\n",
      "Graph 224: 79 nodes\n",
      "Graph 225: 424 nodes\n",
      "Graph 226: 483 nodes\n",
      "Graph 227: 432 nodes\n",
      "Graph 228: 349 nodes\n",
      "Graph 229: 396 nodes\n",
      "Average loss at step 2300: 101.686082\n",
      "Graph 230: 17 nodes\n",
      "Time: 0.555427074432\n",
      "Graph 231: 69 nodes\n",
      "Graph 232: 381 nodes\n",
      "Graph 233: 358 nodes\n",
      "Graph 234: 393 nodes\n",
      "Graph 235: 399 nodes\n",
      "Graph 236: 330 nodes\n",
      "Graph 237: 23 nodes\n",
      "Graph 238: 35 nodes\n",
      "Graph 239: 111 nodes\n",
      "Average loss at step 2400: 80.009502\n",
      "Graph 240: 453 nodes\n",
      "Time: 0.497457027435\n",
      "Graph 241: 448 nodes\n",
      "Graph 242: 439 nodes\n",
      "Graph 243: 383 nodes\n",
      "Graph 244: 19 nodes\n",
      "Graph 245: 76 nodes\n",
      "Graph 246: 422 nodes\n",
      "Graph 247: 409 nodes\n",
      "Graph 248: 439 nodes\n",
      "Graph 249: 386 nodes\n",
      "Average loss at step 2500: 103.459974\n",
      "Graph 250: 349 nodes\n",
      "Time: 0.536628007889\n",
      "Graph 251: 22 nodes\n",
      "Graph 252: 71 nodes\n",
      "Graph 253: 396 nodes\n",
      "Graph 254: 422 nodes\n",
      "Graph 255: 434 nodes\n",
      "Graph 256: 444 nodes\n",
      "Graph 257: 366 nodes\n",
      "Graph 258: 31 nodes\n",
      "Graph 259: 35 nodes\n",
      "Average loss at step 2600: 87.591544\n",
      "Graph 260: 454 nodes\n",
      "Time: 0.560186862946\n",
      "Graph 261: 387 nodes\n",
      "Graph 262: 427 nodes\n",
      "Graph 263: 440 nodes\n",
      "Graph 264: 353 nodes\n",
      "Graph 265: 19 nodes\n",
      "Graph 266: 77 nodes\n",
      "Graph 267: 482 nodes\n",
      "Graph 268: 493 nodes\n",
      "Graph 269: 478 nodes\n",
      "Average loss at step 2700: 108.250794\n",
      "Graph 270: 422 nodes\n",
      "Time: 1.15059494972\n",
      "Graph 271: 485 nodes\n",
      "Graph 272: 35 nodes\n",
      "Graph 273: 107 nodes\n",
      "Graph 274: 414 nodes\n",
      "Graph 275: 402 nodes\n",
      "Graph 276: 461 nodes\n",
      "Graph 277: 414 nodes\n",
      "Graph 278: 390 nodes\n",
      "Graph 279: 37 nodes\n",
      "Average loss at step 2800: 98.935818\n",
      "Graph 280: 52 nodes\n",
      "Time: 1.47071385384\n",
      "Graph 281: 472 nodes\n",
      "Graph 282: 466 nodes\n",
      "Graph 283: 460 nodes\n",
      "Graph 284: 455 nodes\n",
      "Graph 285: 380 nodes\n",
      "Graph 286: 35 nodes\n",
      "Graph 287: 68 nodes\n",
      "Graph 288: 568 nodes\n",
      "Graph 289: 523 nodes\n",
      "Average loss at step 2900: 92.158857\n",
      "Graph 290: 506 nodes\n",
      "Time: 1.54833102226\n",
      "Graph 291: 514 nodes\n",
      "Graph 292: 252 nodes\n",
      "Graph 293: 29 nodes\n",
      "Graph 294: 77 nodes\n",
      "Graph 295: 509 nodes\n",
      "Graph 296: 584 nodes\n",
      "Graph 297: 611 nodes\n",
      "Graph 298: 625 nodes\n",
      "Graph 299: 562 nodes\n",
      "Average loss at step 3000: 103.360489\n",
      "Graph 300: 59 nodes\n",
      "Time: 0.40024805069\n",
      "Graph 301: 83 nodes\n",
      "Graph 302: 589 nodes\n",
      "Graph 303: 672 nodes\n",
      "Graph 304: 599 nodes\n",
      "Graph 305: 564 nodes\n",
      "Graph 306: 567 nodes\n",
      "Graph 307: 68 nodes\n",
      "Graph 308: 114 nodes\n",
      "Graph 309: 678 nodes\n",
      "Average loss at step 3100: 98.025728\n",
      "Graph 310: 644 nodes\n",
      "Time: 0.89471912384\n",
      "Graph 311: 610 nodes\n",
      "Graph 312: 443 nodes\n",
      "Graph 313: 545 nodes\n",
      "Graph 314: 48 nodes\n",
      "Graph 315: 87 nodes\n",
      "Graph 316: 708 nodes\n",
      "Graph 317: 660 nodes\n",
      "Graph 318: 674 nodes\n",
      "Graph 319: 679 nodes\n",
      "Average loss at step 3200: 95.864210\n",
      "Graph 320: 664 nodes\n",
      "Time: 0.679609060287\n",
      "Graph 321: 52 nodes\n",
      "Graph 322: 94 nodes\n",
      "Graph 323: 684 nodes\n",
      "Graph 324: 668 nodes\n",
      "Graph 325: 689 nodes\n",
      "Graph 326: 719 nodes\n",
      "Graph 327: 517 nodes\n",
      "Graph 328: 50 nodes\n",
      "Graph 329: 91 nodes\n",
      "Average loss at step 3300: 84.806329\n",
      "Graph 330: 714 nodes\n",
      "Time: 0.853281021118\n",
      "Graph 331: 749 nodes\n",
      "Graph 332: 729 nodes\n",
      "Graph 333: 747 nodes\n",
      "Graph 334: 608 nodes\n",
      "Graph 335: 47 nodes\n",
      "Graph 336: 70 nodes\n",
      "Graph 337: 106 nodes\n",
      "Graph 338: 798 nodes\n",
      "Graph 339: 802 nodes\n",
      "Average loss at step 3400: 99.766628\n",
      "Graph 340: 878 nodes\n",
      "Time: 0.895530939102\n",
      "Graph 341: 795 nodes\n",
      "Graph 342: 88 nodes\n",
      "Graph 343: 130 nodes\n",
      "Graph 344: 879 nodes\n",
      "Graph 345: 925 nodes\n",
      "Graph 346: 947 nodes\n",
      "Graph 347: 945 nodes\n",
      "Graph 348: 670 nodes\n",
      "Graph 349: 22 nodes\n",
      "Average loss at step 3500: 98.129822\n",
      "Graph 350: 56 nodes\n",
      "Time: 0.522953987122\n",
      "Graph 351: 387 nodes\n",
      "Graph 352: 294 nodes\n",
      "Graph 353: 294 nodes\n",
      "Graph 354: 289 nodes\n",
      "Graph 355: 269 nodes\n",
      "Graph 356: 43 nodes\n",
      "Graph 357: 45 nodes\n",
      "Graph 358: 338 nodes\n",
      "Graph 359: 306 nodes\n",
      "Average loss at step 3600: 75.831922\n",
      "Graph 360: 322 nodes\n",
      "Time: 0.614063024521\n",
      "Graph 361: 342 nodes\n",
      "Graph 362: 251 nodes\n",
      "Graph 363: 16 nodes\n",
      "Graph 364: 35 nodes\n",
      "Graph 365: 326 nodes\n",
      "Graph 366: 589 nodes\n",
      "Graph 367: 617 nodes\n",
      "Graph 368: 290 nodes\n",
      "Graph 369: 272 nodes\n",
      "Average loss at step 3700: 80.276429\n",
      "Graph 370: 23 nodes\n",
      "Time: 0.377179861069\n",
      "Graph 371: 43 nodes\n",
      "Graph 372: 326 nodes\n",
      "Graph 373: 272 nodes\n",
      "Graph 374: 55 nodes\n",
      "Graph 375: 305 nodes\n",
      "Graph 376: 229 nodes\n",
      "Graph 377: 26 nodes\n",
      "Graph 378: 59 nodes\n",
      "Graph 379: 335 nodes\n",
      "Average loss at step 3800: 84.852488\n",
      "Graph 380: 319 nodes\n",
      "Time: 0.782419919968\n",
      "Graph 381: 338 nodes\n",
      "Graph 382: 320 nodes\n",
      "Graph 383: 317 nodes\n",
      "Graph 384: 21 nodes\n",
      "Graph 385: 29 nodes\n",
      "Graph 386: 345 nodes\n",
      "Graph 387: 353 nodes\n",
      "Graph 388: 343 nodes\n",
      "Graph 389: 349 nodes\n",
      "Average loss at step 3900: 90.215089\n",
      "Graph 390: 320 nodes\n",
      "Time: 0.605185985565\n",
      "Graph 391: 23 nodes\n",
      "Graph 392: 34 nodes\n",
      "Graph 393: 354 nodes\n",
      "Graph 394: 342 nodes\n",
      "Graph 395: 332 nodes\n",
      "Graph 396: 458 nodes\n",
      "Graph 397: 351 nodes\n",
      "Graph 398: 33 nodes\n",
      "Graph 399: 39 nodes\n",
      "Average loss at step 4000: 87.736741\n",
      "Graph 400: 453 nodes\n",
      "Time: 0.749502897263\n",
      "Graph 401: 382 nodes\n",
      "Graph 402: 369 nodes\n",
      "Graph 403: 326 nodes\n",
      "Graph 404: 286 nodes\n",
      "Graph 405: 12 nodes\n",
      "Graph 406: 32 nodes\n",
      "Graph 407: 351 nodes\n",
      "Graph 408: 361 nodes\n",
      "Graph 409: 309 nodes\n",
      "Average loss at step 4100: 89.353898\n",
      "Graph 410: 372 nodes\n",
      "Time: 1.13155508041\n",
      "Graph 411: 338 nodes\n",
      "Graph 412: 18 nodes\n",
      "Graph 413: 86 nodes\n",
      "Graph 414: 411 nodes\n",
      "Graph 415: 417 nodes\n",
      "Graph 416: 348 nodes\n",
      "Graph 417: 338 nodes\n",
      "Graph 418: 292 nodes\n",
      "Graph 419: 44 nodes\n",
      "Average loss at step 4200: 88.936861\n",
      "Graph 420: 54 nodes\n",
      "Time: 0.493660926819\n",
      "Graph 421: 416 nodes\n",
      "Graph 422: 398 nodes\n",
      "Graph 423: 405 nodes\n",
      "Graph 424: 380 nodes\n",
      "Graph 425: 342 nodes\n",
      "Graph 426: 45 nodes\n",
      "Graph 427: 56 nodes\n",
      "Graph 428: 459 nodes\n",
      "Graph 429: 453 nodes\n",
      "Average loss at step 4300: 96.200816\n",
      "Graph 430: 415 nodes\n",
      "Time: 0.490213155746\n",
      "Graph 431: 420 nodes\n",
      "Graph 432: 335 nodes\n",
      "Graph 433: 25 nodes\n",
      "Graph 434: 20 nodes\n",
      "Graph 435: 54 nodes\n",
      "Graph 436: 423 nodes\n",
      "Graph 437: 431 nodes\n",
      "Graph 438: 417 nodes\n",
      "Graph 439: 370 nodes\n",
      "Average loss at step 4400: 80.562219\n",
      "Graph 440: 42 nodes\n",
      "Time: 0.517857074738\n",
      "Graph 441: 37 nodes\n",
      "Graph 442: 494 nodes\n",
      "Graph 443: 173 nodes\n",
      "Graph 444: 435 nodes\n",
      "Graph 445: 445 nodes\n",
      "Graph 446: 438 nodes\n",
      "Graph 447: 52 nodes\n",
      "Graph 448: 52 nodes\n",
      "Graph 449: 492 nodes\n",
      "Average loss at step 4500: 77.752867\n",
      "Graph 450: 534 nodes\n",
      "Time: 0.969798088074\n",
      "Graph 451: 584 nodes\n",
      "Graph 452: 496 nodes\n",
      "Graph 453: 508 nodes\n",
      "Graph 454: 40 nodes\n",
      "Graph 455: 65 nodes\n",
      "Graph 456: 580 nodes\n",
      "Graph 457: 690 nodes\n",
      "Graph 458: 672 nodes\n",
      "Graph 459: 709 nodes\n",
      "Average loss at step 4600: 94.166192\n",
      "Graph 460: 615 nodes\n",
      "Time: 0.692560911179\n",
      "Graph 461: 39 nodes\n",
      "Graph 462: 81 nodes\n",
      "Graph 463: 715 nodes\n",
      "Graph 464: 716 nodes\n",
      "Graph 465: 624 nodes\n",
      "Graph 466: 620 nodes\n",
      "Graph 467: 594 nodes\n",
      "Graph 468: 46 nodes\n",
      "Graph 469: 90 nodes\n",
      "Average loss at step 4700: 93.458322\n",
      "Graph 470: 715 nodes\n",
      "Time: 0.962829113007\n",
      "Graph 471: 770 nodes\n",
      "Graph 472: 742 nodes\n",
      "Graph 473: 707 nodes\n",
      "Graph 474: 724 nodes\n",
      "Graph 475: 86 nodes\n",
      "Graph 476: 115 nodes\n",
      "Graph 477: 1057 nodes\n",
      "Graph 478: 1055 nodes\n",
      "Graph 479: 1216 nodes\n",
      "Average loss at step 4800: 114.784976\n",
      "Graph 480: 1426 nodes\n",
      "Time: 0.740460157394\n",
      "Graph 481: 1211 nodes\n",
      "Graph 482: 201 nodes\n",
      "Graph 483: 237 nodes\n",
      "Graph 484: 1410 nodes\n",
      "Graph 485: 1418 nodes\n",
      "Graph 486: 1457 nodes\n",
      "Graph 487: 1537 nodes\n",
      "Graph 488: 1374 nodes\n",
      "Graph 489: 233 nodes\n",
      "Average loss at step 4900: 119.002636\n",
      "Graph 490: 287 nodes\n",
      "Time: 0.510400772095\n",
      "Graph 491: 1470 nodes\n",
      "Graph 492: 721 nodes\n",
      "Graph 493: 728 nodes\n",
      "Graph 494: 693 nodes\n",
      "Graph 495: 688 nodes\n",
      "Graph 496: 78 nodes\n",
      "Graph 497: 81 nodes\n",
      "Graph 498: 757 nodes\n",
      "Graph 499: 811 nodes\n",
      "Average loss at step 5000: 117.423540\n",
      "Graph 500: 752 nodes\n",
      "Time: 0.552163124084\n",
      "Graph 501: 678 nodes\n",
      "Graph 502: 616 nodes\n",
      "Graph 503: 44 nodes\n",
      "Graph 504: 82 nodes\n",
      "Graph 505: 777 nodes\n",
      "Graph 506: 867 nodes\n",
      "Graph 507: 947 nodes\n",
      "Graph 508: 969 nodes\n",
      "Graph 509: 1080 nodes\n",
      "Average loss at step 5100: 113.398879\n",
      "Graph 510: 246 nodes\n",
      "Time: 0.634778022766\n",
      "Graph 511: 317 nodes\n",
      "Graph 512: 1452 nodes\n",
      "Graph 513: 1425 nodes\n",
      "Graph 514: 1098 nodes\n",
      "Graph 515: 234 nodes\n",
      "Graph 516: 284 nodes\n",
      "Graph 517: 179 nodes\n",
      "Graph 518: 309 nodes\n",
      "Graph 519: 1449 nodes\n",
      "Average loss at step 5200: 110.778055\n",
      "Graph 520: 1345 nodes\n",
      "Time: 0.786997795105\n",
      "Graph 521: 491 nodes\n",
      "Graph 522: 508 nodes\n",
      "Graph 523: 504 nodes\n",
      "Graph 524: 75 nodes\n",
      "Graph 525: 109 nodes\n",
      "Graph 526: 446 nodes\n",
      "Graph 527: 457 nodes\n",
      "Graph 528: 412 nodes\n",
      "Graph 529: 405 nodes\n",
      "Average loss at step 5300: 106.709942\n",
      "Graph 530: 358 nodes\n",
      "Time: 0.656394958496\n",
      "Graph 531: 43 nodes\n",
      "Graph 532: 88 nodes\n",
      "Graph 533: 443 nodes\n",
      "Graph 534: 473 nodes\n",
      "Graph 535: 491 nodes\n",
      "Graph 536: 525 nodes\n",
      "Graph 537: 352 nodes\n",
      "Graph 538: 55 nodes\n",
      "Graph 539: 61 nodes\n",
      "Average loss at step 5400: 82.328118\n",
      "Graph 540: 506 nodes\n",
      "Time: 0.54048705101\n",
      "Graph 541: 355 nodes\n",
      "Graph 542: 635 nodes\n",
      "Graph 543: 589 nodes\n",
      "Graph 544: 542 nodes\n",
      "Graph 545: 137 nodes\n",
      "Graph 546: 136 nodes\n",
      "Graph 547: 202 nodes\n",
      "Graph 548: 111 nodes\n",
      "Graph 549: 438 nodes\n",
      "Average loss at step 5500: 104.673115\n",
      "Graph 550: 523 nodes\n",
      "Time: 0.557321071625\n",
      "Graph 551: 429 nodes\n",
      "Graph 552: 149 nodes\n",
      "Graph 553: 142 nodes\n",
      "Graph 554: 401 nodes\n",
      "Graph 555: 131 nodes\n",
      "Graph 556: 439 nodes\n",
      "Graph 557: 394 nodes\n",
      "Graph 558: 383 nodes\n",
      "Graph 559: 83 nodes\n",
      "Average loss at step 5600: 100.776066\n",
      "Graph 560: 66 nodes\n",
      "Time: 0.542157888412\n",
      "Graph 561: 487 nodes\n",
      "Graph 562: 525 nodes\n",
      "Graph 563: 628 nodes\n",
      "Graph 564: 640 nodes\n",
      "Graph 565: 566 nodes\n",
      "Graph 566: 114 nodes\n",
      "Graph 567: 131 nodes\n",
      "Graph 568: 582 nodes\n",
      "Graph 569: 590 nodes\n",
      "Average loss at step 5700: 100.605415\n",
      "Graph 570: 634 nodes\n",
      "Time: 0.54877114296\n",
      "Graph 571: 597 nodes\n",
      "Graph 572: 547 nodes\n",
      "Graph 573: 82 nodes\n",
      "Graph 574: 115 nodes\n",
      "Graph 575: 258 nodes\n",
      "Graph 576: 584 nodes\n",
      "Graph 577: 565 nodes\n",
      "Graph 578: 552 nodes\n",
      "Graph 579: 539 nodes\n",
      "Average loss at step 5800: 109.905722\n",
      "Graph 580: 106 nodes\n",
      "Time: 0.623659849167\n",
      "Graph 581: 138 nodes\n",
      "Graph 582: 573 nodes\n",
      "Graph 583: 697 nodes\n",
      "Graph 584: 1771 nodes\n",
      "Graph 585: 590 nodes\n",
      "Graph 586: 542 nodes\n",
      "Graph 587: 87 nodes\n",
      "Graph 588: 124 nodes\n",
      "Graph 589: 585 nodes\n",
      "Average loss at step 5900: 108.129812\n",
      "Graph 590: 637 nodes\n",
      "Time: 0.708341121674\n",
      "Graph 591: 638 nodes\n",
      "Graph 592: 241 nodes\n",
      "Graph 593: 150 nodes\n",
      "Graph 594: 21 nodes\n",
      "Graph 595: 28 nodes\n",
      "Graph 596: 175 nodes\n",
      "Graph 597: 223 nodes\n",
      "Graph 598: 210 nodes\n",
      "Graph 599: 196 nodes\n",
      "Average loss at step 6000: 109.081691\n",
      "Graph 600: 149 nodes\n",
      "Time: 0.648394823074\n",
      "Graph 601: 10 nodes\n",
      "Graph 602: 20 nodes\n",
      "Graph 603: 39 nodes\n",
      "Graph 604: 196 nodes\n",
      "Graph 605: 154 nodes\n",
      "Graph 606: 165 nodes\n",
      "Graph 607: 183 nodes\n",
      "Graph 608: 16 nodes\n",
      "Graph 609: 37 nodes\n",
      "Average loss at step 6100: 69.550187\n",
      "Graph 610: 220 nodes\n",
      "Time: 0.669919967651\n",
      "Graph 611: 188 nodes\n",
      "Graph 612: 206 nodes\n",
      "Graph 613: 203 nodes\n",
      "Graph 614: 163 nodes\n",
      "Graph 615: 12 nodes\n",
      "Graph 616: 25 nodes\n",
      "Graph 617: 149 nodes\n",
      "Graph 618: 142 nodes\n",
      "Graph 619: 159 nodes\n",
      "Average loss at step 6200: 103.365427\n",
      "Graph 620: 181 nodes\n",
      "Time: 0.730714797974\n",
      "Graph 621: 172 nodes\n",
      "Graph 622: 10 nodes\n",
      "Graph 623: 30 nodes\n",
      "Graph 624: 112 nodes\n",
      "Graph 625: 163 nodes\n",
      "Graph 626: 127 nodes\n",
      "Graph 627: 157 nodes\n",
      "Graph 628: 117 nodes\n",
      "Graph 629: 10 nodes\n",
      "Average loss at step 6300: 78.685917\n",
      "Graph 630: 16 nodes\n",
      "Time: 0.677660942078\n",
      "Graph 631: 121 nodes\n",
      "Graph 632: 140 nodes\n",
      "Graph 633: 162 nodes\n",
      "Graph 634: 137 nodes\n",
      "Graph 635: 116 nodes\n",
      "Graph 636: 14 nodes\n",
      "Epoch: 1\n",
      "Graph 0: 20 nodes\n",
      "Time: 0.601312160492\n",
      "Graph 1: 277 nodes\n",
      "Graph 2: 274 nodes\n",
      "Average loss at step 6400: 91.855940\n",
      "Graph 3: 278 nodes\n",
      "Graph 4: 293 nodes\n",
      "Graph 5: 262 nodes\n",
      "Graph 6: 9 nodes\n",
      "Graph 7: 8 nodes\n",
      "Graph 8: 31 nodes\n",
      "Graph 9: 32 nodes\n",
      "Graph 10: 264 nodes\n",
      "Time: 1.01634001732\n",
      "Graph 11: 229 nodes\n",
      "Graph 12: 230 nodes\n",
      "Average loss at step 6500: 78.699862\n",
      "Graph 13: 18 nodes\n",
      "Graph 14: 24 nodes\n",
      "Graph 15: 306 nodes\n",
      "Graph 16: 262 nodes\n",
      "Graph 17: 229 nodes\n",
      "Graph 18: 277 nodes\n",
      "Graph 19: 200 nodes\n",
      "Graph 20: 16 nodes\n",
      "Time: 0.406750917435\n",
      "Graph 21: 12 nodes\n",
      "Graph 22: 232 nodes\n",
      "Average loss at step 6600: 79.328303\n",
      "Graph 23: 245 nodes\n",
      "Graph 24: 252 nodes\n",
      "Graph 25: 207 nodes\n",
      "Graph 26: 207 nodes\n",
      "Graph 27: 8 nodes\n",
      "Graph 28: 50 nodes\n",
      "Graph 29: 249 nodes\n",
      "Graph 30: 263 nodes\n",
      "Time: 0.488411903381\n",
      "Graph 31: 237 nodes\n",
      "Graph 32: 248 nodes\n",
      "Average loss at step 6700: 99.677965\n",
      "Graph 33: 250 nodes\n",
      "Graph 34: 13 nodes\n",
      "Graph 35: 45 nodes\n",
      "Graph 36: 333 nodes\n",
      "Graph 37: 266 nodes\n",
      "Graph 38: 241 nodes\n",
      "Graph 39: 235 nodes\n",
      "Graph 40: 244 nodes\n",
      "Time: 0.673891067505\n",
      "Graph 41: 15 nodes\n",
      "Graph 42: 42 nodes\n",
      "Average loss at step 6800: 86.292279\n",
      "Graph 43: 257 nodes\n",
      "Graph 44: 242 nodes\n",
      "Graph 45: 260 nodes\n",
      "Graph 46: 236 nodes\n",
      "Graph 47: 263 nodes\n",
      "Graph 48: 10 nodes\n",
      "Graph 49: 21 nodes\n",
      "Graph 50: 236 nodes\n",
      "Time: 0.835323095322\n",
      "Graph 51: 266 nodes\n",
      "Graph 52: 295 nodes\n",
      "Average loss at step 6900: 90.303076\n",
      "Graph 53: 270 nodes\n",
      "Graph 54: 249 nodes\n",
      "Graph 55: 10 nodes\n",
      "Graph 56: 48 nodes\n",
      "Graph 57: 308 nodes\n",
      "Graph 58: 300 nodes\n",
      "Graph 59: 340 nodes\n",
      "Graph 60: 303 nodes\n",
      "Time: 0.780642032623\n",
      "Graph 61: 316 nodes\n",
      "Graph 62: 31 nodes\n",
      "Average loss at step 7000: 83.722056\n",
      "Graph 63: 39 nodes\n",
      "Graph 64: 381 nodes\n",
      "Graph 65: 367 nodes\n",
      "Graph 66: 352 nodes\n",
      "Graph 67: 321 nodes\n",
      "Graph 68: 290 nodes\n",
      "Graph 69: 13 nodes\n",
      "Graph 70: 20 nodes\n",
      "Time: 1.15641188622\n",
      "Graph 71: 44 nodes\n",
      "Graph 72: 302 nodes\n",
      "Average loss at step 7100: 79.374839\n",
      "Graph 73: 340 nodes\n",
      "Graph 74: 336 nodes\n",
      "Graph 75: 330 nodes\n",
      "Graph 76: 28 nodes\n",
      "Graph 77: 62 nodes\n",
      "Graph 78: 351 nodes\n",
      "Graph 79: 304 nodes\n",
      "Graph 80: 318 nodes\n",
      "Time: 0.661153078079\n",
      "Graph 81: 315 nodes\n",
      "Graph 82: 304 nodes\n",
      "Average loss at step 7200: 104.585860\n",
      "Graph 83: 26 nodes\n",
      "Graph 84: 53 nodes\n",
      "Graph 85: 339 nodes\n",
      "Graph 86: 329 nodes\n",
      "Graph 87: 357 nodes\n",
      "Graph 88: 349 nodes\n",
      "Graph 89: 315 nodes\n",
      "Graph 90: 21 nodes\n",
      "Time: 0.527670860291\n",
      "Graph 91: 44 nodes\n",
      "Graph 92: 364 nodes\n",
      "Average loss at step 7300: 91.808390\n",
      "Graph 93: 367 nodes\n",
      "Graph 94: 391 nodes\n",
      "Graph 95: 323 nodes\n",
      "Graph 96: 305 nodes\n",
      "Graph 97: 24 nodes\n",
      "Graph 98: 53 nodes\n",
      "Graph 99: 377 nodes\n",
      "Graph 100: 355 nodes\n",
      "Time: 0.540710926056\n",
      "Graph 101: 328 nodes\n",
      "Graph 102: 308 nodes\n",
      "Average loss at step 7400: 92.118676\n",
      "Graph 103: 290 nodes\n",
      "Graph 104: 28 nodes\n",
      "Graph 105: 68 nodes\n",
      "Graph 106: 356 nodes\n",
      "Graph 107: 380 nodes\n",
      "Graph 108: 386 nodes\n",
      "Graph 109: 397 nodes\n",
      "Graph 110: 341 nodes\n",
      "Time: 1.34823513031\n",
      "Graph 111: 32 nodes\n",
      "Graph 112: 48 nodes\n",
      "Average loss at step 7500: 90.842282\n",
      "Graph 113: 343 nodes\n",
      "Graph 114: 410 nodes\n",
      "Graph 115: 351 nodes\n",
      "Graph 116: 334 nodes\n",
      "Graph 117: 335 nodes\n",
      "Graph 118: 30 nodes\n",
      "Graph 119: 42 nodes\n",
      "Graph 120: 392 nodes\n",
      "Time: 0.754309892654\n",
      "Graph 121: 440 nodes\n",
      "Graph 122: 439 nodes\n",
      "Average loss at step 7600: 93.817073\n",
      "Graph 123: 396 nodes\n",
      "Graph 124: 423 nodes\n",
      "Graph 125: 29 nodes\n",
      "Graph 126: 77 nodes\n",
      "Graph 127: 423 nodes\n",
      "Graph 128: 407 nodes\n",
      "Graph 129: 484 nodes\n",
      "Graph 130: 434 nodes\n",
      "Time: 0.559201955795\n",
      "Graph 131: 358 nodes\n",
      "Graph 132: 43 nodes\n",
      "Average loss at step 7700: 103.545417\n",
      "Graph 133: 63 nodes\n",
      "Graph 134: 484 nodes\n",
      "Graph 135: 499 nodes\n",
      "Graph 136: 419 nodes\n",
      "Graph 137: 523 nodes\n",
      "Graph 138: 508 nodes\n",
      "Graph 139: 38 nodes\n",
      "Graph 140: 110 nodes\n",
      "Time: 0.547811985016\n",
      "Graph 141: 588 nodes\n",
      "Graph 142: 563 nodes\n",
      "Average loss at step 7800: 96.585587\n",
      "Graph 143: 564 nodes\n",
      "Graph 144: 514 nodes\n",
      "Graph 145: 420 nodes\n",
      "Graph 146: 64 nodes\n",
      "Graph 147: 105 nodes\n",
      "Graph 148: 506 nodes\n",
      "Graph 149: 480 nodes\n",
      "Graph 150: 410 nodes\n",
      "Time: 0.65066409111\n",
      "Graph 151: 49 nodes\n",
      "Graph 152: 54 nodes\n",
      "Average loss at step 7900: 75.963042\n",
      "Graph 153: 30 nodes\n",
      "Graph 154: 132 nodes\n",
      "Graph 155: 607 nodes\n",
      "Graph 156: 682 nodes\n",
      "Graph 157: 720 nodes\n",
      "Graph 158: 630 nodes\n",
      "Graph 159: 568 nodes\n",
      "Graph 160: 62 nodes\n",
      "Time: 0.459021806717\n",
      "Graph 161: 131 nodes\n",
      "Graph 162: 689 nodes\n",
      "Average loss at step 8000: 92.103459\n",
      "Graph 163: 623 nodes\n",
      "Graph 164: 707 nodes\n",
      "Graph 165: 650 nodes\n",
      "Graph 166: 625 nodes\n",
      "Graph 167: 73 nodes\n",
      "Graph 168: 171 nodes\n",
      "Graph 169: 808 nodes\n",
      "Graph 170: 897 nodes\n",
      "Time: 0.876003026962\n",
      "Graph 171: 958 nodes\n",
      "Graph 172: 397 nodes\n",
      "Average loss at step 8100: 98.457473\n",
      "Graph 173: 339 nodes\n",
      "Graph 174: 18 nodes\n",
      "Graph 175: 59 nodes\n",
      "Graph 176: 378 nodes\n",
      "Graph 177: 374 nodes\n",
      "Graph 178: 375 nodes\n",
      "Graph 179: 317 nodes\n",
      "Graph 180: 244 nodes\n",
      "Time: 0.479350090027\n",
      "Graph 181: 17 nodes\n",
      "Graph 182: 10 nodes\n",
      "Average loss at step 8200: 76.067907\n",
      "Graph 183: 19 nodes\n",
      "Graph 184: 90 nodes\n",
      "Graph 185: 210 nodes\n",
      "Graph 186: 226 nodes\n",
      "Graph 187: 162 nodes\n",
      "Graph 188: 10 nodes\n",
      "Graph 189: 7 nodes\n",
      "Graph 190: 62 nodes\n",
      "Time: 0.4366979599\n",
      "Graph 191: 349 nodes\n",
      "Graph 192: 341 nodes\n",
      "Average loss at step 8300: 76.548908\n",
      "Graph 193: 365 nodes\n",
      "Graph 194: 334 nodes\n",
      "Graph 195: 21 nodes\n",
      "Graph 196: 70 nodes\n",
      "Graph 197: 364 nodes\n",
      "Graph 198: 339 nodes\n",
      "Graph 199: 344 nodes\n",
      "Graph 200: 341 nodes\n",
      "Time: 0.495707988739\n",
      "Graph 201: 328 nodes\n",
      "Graph 202: 56 nodes\n",
      "Average loss at step 8400: 91.463418\n",
      "Graph 203: 37 nodes\n",
      "Graph 204: 108 nodes\n",
      "Graph 205: 385 nodes\n",
      "Graph 206: 380 nodes\n",
      "Graph 207: 315 nodes\n",
      "Graph 208: 348 nodes\n",
      "Graph 209: 44 nodes\n",
      "Graph 210: 78 nodes\n",
      "Time: 0.499396085739\n",
      "Graph 211: 411 nodes\n",
      "Graph 212: 415 nodes\n",
      "Average loss at step 8500: 89.976723\n",
      "Graph 213: 429 nodes\n",
      "Graph 214: 378 nodes\n",
      "Graph 215: 405 nodes\n",
      "Graph 216: 33 nodes\n",
      "Graph 217: 44 nodes\n",
      "Graph 218: 407 nodes\n",
      "Graph 219: 397 nodes\n",
      "Graph 220: 441 nodes\n",
      "Time: 0.661988019943\n",
      "Graph 221: 393 nodes\n",
      "Graph 222: 353 nodes\n",
      "Average loss at step 8600: 89.363182\n",
      "Graph 223: 29 nodes\n",
      "Graph 224: 79 nodes\n",
      "Graph 225: 424 nodes\n",
      "Graph 226: 483 nodes\n",
      "Graph 227: 432 nodes\n",
      "Graph 228: 349 nodes\n",
      "Graph 229: 396 nodes\n",
      "Graph 230: 17 nodes\n",
      "Time: 0.425852060318\n",
      "Graph 231: 69 nodes\n",
      "Graph 232: 381 nodes\n",
      "Average loss at step 8700: 87.845108\n",
      "Graph 233: 358 nodes\n",
      "Graph 234: 393 nodes\n",
      "Graph 235: 399 nodes\n",
      "Graph 236: 330 nodes\n",
      "Graph 237: 23 nodes\n",
      "Graph 238: 35 nodes\n",
      "Graph 239: 111 nodes\n",
      "Graph 240: 453 nodes\n",
      "Time: 0.767635822296\n",
      "Graph 241: 448 nodes\n",
      "Graph 242: 439 nodes\n",
      "Average loss at step 8800: 91.955586\n",
      "Graph 243: 383 nodes\n",
      "Graph 244: 19 nodes\n",
      "Graph 245: 76 nodes\n",
      "Graph 246: 422 nodes\n",
      "Graph 247: 409 nodes\n",
      "Graph 248: 439 nodes\n",
      "Graph 249: 386 nodes\n",
      "Graph 250: 349 nodes\n",
      "Time: 0.654533863068\n",
      "Graph 251: 22 nodes\n",
      "Graph 252: 71 nodes\n",
      "Average loss at step 8900: 86.682747\n",
      "Graph 253: 396 nodes\n",
      "Graph 254: 422 nodes\n",
      "Graph 255: 434 nodes\n",
      "Graph 256: 444 nodes\n",
      "Graph 257: 366 nodes\n",
      "Graph 258: 31 nodes\n",
      "Graph 259: 35 nodes\n",
      "Graph 260: 454 nodes\n",
      "Time: 0.555490016937\n",
      "Graph 261: 387 nodes\n",
      "Graph 262: 427 nodes\n",
      "Average loss at step 9000: 94.211292\n",
      "Graph 263: 440 nodes\n",
      "Graph 264: 353 nodes\n",
      "Graph 265: 19 nodes\n",
      "Graph 266: 77 nodes\n",
      "Graph 267: 482 nodes\n",
      "Graph 268: 493 nodes\n",
      "Graph 269: 478 nodes\n",
      "Graph 270: 422 nodes\n",
      "Time: 0.599510908127\n",
      "Graph 271: 485 nodes\n",
      "Graph 272: 35 nodes\n",
      "Average loss at step 9100: 95.887218\n",
      "Graph 273: 107 nodes\n",
      "Graph 274: 414 nodes\n",
      "Graph 275: 402 nodes\n",
      "Graph 276: 461 nodes\n",
      "Graph 277: 414 nodes\n",
      "Graph 278: 390 nodes\n",
      "Graph 279: 37 nodes\n",
      "Graph 280: 52 nodes\n",
      "Time: 0.55246090889\n",
      "Graph 281: 472 nodes\n",
      "Graph 282: 466 nodes\n",
      "Average loss at step 9200: 96.880485\n",
      "Graph 283: 460 nodes\n",
      "Graph 284: 455 nodes\n",
      "Graph 285: 380 nodes\n",
      "Graph 286: 35 nodes\n",
      "Graph 287: 68 nodes\n",
      "Graph 288: 568 nodes\n",
      "Graph 289: 523 nodes\n",
      "Graph 290: 506 nodes\n",
      "Time: 0.788402080536\n",
      "Graph 291: 514 nodes\n",
      "Graph 292: 252 nodes\n",
      "Average loss at step 9300: 94.172949\n",
      "Graph 293: 29 nodes\n",
      "Graph 294: 77 nodes\n",
      "Graph 295: 509 nodes\n",
      "Graph 296: 584 nodes\n",
      "Graph 297: 611 nodes\n",
      "Graph 298: 625 nodes\n",
      "Graph 299: 562 nodes\n",
      "Graph 300: 59 nodes\n",
      "Time: 0.445019006729\n",
      "Graph 301: 83 nodes\n",
      "Graph 302: 589 nodes\n",
      "Average loss at step 9400: 87.220507\n",
      "Graph 303: 672 nodes\n",
      "Graph 304: 599 nodes\n",
      "Graph 305: 564 nodes\n",
      "Graph 306: 567 nodes\n",
      "Graph 307: 68 nodes\n",
      "Graph 308: 114 nodes\n",
      "Graph 309: 678 nodes\n",
      "Graph 310: 644 nodes\n",
      "Time: 0.937523841858\n",
      "Graph 311: 610 nodes\n",
      "Graph 312: 443 nodes\n",
      "Average loss at step 9500: 108.055434\n",
      "Graph 313: 545 nodes\n",
      "Graph 314: 48 nodes\n",
      "Graph 315: 87 nodes\n",
      "Graph 316: 708 nodes\n",
      "Graph 317: 660 nodes\n",
      "Graph 318: 674 nodes\n",
      "Graph 319: 679 nodes\n",
      "Graph 320: 664 nodes\n",
      "Time: 0.799067974091\n",
      "Graph 321: 52 nodes\n",
      "Graph 322: 94 nodes\n",
      "Average loss at step 9600: 85.867320\n",
      "Graph 323: 684 nodes\n",
      "Graph 324: 668 nodes\n",
      "Graph 325: 689 nodes\n",
      "Graph 326: 719 nodes\n",
      "Graph 327: 517 nodes\n",
      "Graph 328: 50 nodes\n",
      "Graph 329: 91 nodes\n",
      "Graph 330: 714 nodes\n",
      "Time: 0.707864999771\n",
      "Graph 331: 749 nodes\n",
      "Graph 332: 729 nodes\n",
      "Average loss at step 9700: 99.805317\n",
      "Graph 333: 747 nodes\n",
      "Graph 334: 608 nodes\n",
      "Graph 335: 47 nodes\n",
      "Graph 336: 70 nodes\n",
      "Graph 337: 106 nodes\n",
      "Graph 338: 798 nodes\n",
      "Graph 339: 802 nodes\n",
      "Graph 340: 878 nodes\n",
      "Time: 0.862045049667\n",
      "Graph 341: 795 nodes\n",
      "Graph 342: 88 nodes\n",
      "Average loss at step 9800: 82.518393\n",
      "Graph 343: 130 nodes\n",
      "Graph 344: 879 nodes\n",
      "Graph 345: 925 nodes\n",
      "Graph 346: 947 nodes\n",
      "Graph 347: 945 nodes\n",
      "Graph 348: 670 nodes\n",
      "Graph 349: 22 nodes\n",
      "Graph 350: 56 nodes\n",
      "Time: 0.705442905426\n",
      "Graph 351: 387 nodes\n",
      "Graph 352: 294 nodes\n",
      "Average loss at step 9900: 88.244320\n",
      "Graph 353: 294 nodes\n",
      "Graph 354: 289 nodes\n",
      "Graph 355: 269 nodes\n",
      "Graph 356: 43 nodes\n",
      "Graph 357: 45 nodes\n",
      "Graph 358: 338 nodes\n",
      "Graph 359: 306 nodes\n",
      "Graph 360: 322 nodes\n",
      "Time: 0.647174835205\n",
      "Graph 361: 342 nodes\n",
      "Graph 362: 251 nodes\n",
      "Average loss at step 10000: 81.276769\n",
      "Graph 363: 16 nodes\n",
      "Graph 364: 35 nodes\n",
      "Graph 365: 326 nodes\n",
      "Graph 366: 589 nodes\n",
      "Graph 367: 617 nodes\n",
      "Graph 368: 290 nodes\n",
      "Graph 369: 272 nodes\n",
      "Graph 370: 23 nodes\n",
      "Time: 0.626009941101\n",
      "Graph 371: 43 nodes\n",
      "Graph 372: 326 nodes\n",
      "Average loss at step 10100: 70.526676\n",
      "Graph 373: 272 nodes\n",
      "Graph 374: 55 nodes\n",
      "Graph 375: 305 nodes\n",
      "Graph 376: 229 nodes\n",
      "Graph 377: 26 nodes\n",
      "Graph 378: 59 nodes\n",
      "Graph 379: 335 nodes\n",
      "Graph 380: 319 nodes\n",
      "Time: 0.613540172577\n",
      "Graph 381: 338 nodes\n",
      "Graph 382: 320 nodes\n",
      "Average loss at step 10200: 93.332070\n",
      "Graph 383: 317 nodes\n",
      "Graph 384: 21 nodes\n",
      "Graph 385: 29 nodes\n",
      "Graph 386: 345 nodes\n",
      "Graph 387: 353 nodes\n",
      "Graph 388: 343 nodes\n",
      "Graph 389: 349 nodes\n",
      "Graph 390: 320 nodes\n",
      "Time: 0.648753881454\n",
      "Graph 391: 23 nodes\n",
      "Graph 392: 34 nodes\n",
      "Average loss at step 10300: 81.022673\n",
      "Graph 393: 354 nodes\n",
      "Graph 394: 342 nodes\n",
      "Graph 395: 332 nodes\n",
      "Graph 396: 458 nodes\n",
      "Graph 397: 351 nodes\n",
      "Graph 398: 33 nodes\n",
      "Graph 399: 39 nodes\n",
      "Graph 400: 453 nodes\n",
      "Time: 0.658799886703\n",
      "Graph 401: 382 nodes\n",
      "Graph 402: 369 nodes\n",
      "Average loss at step 10400: 96.574331\n",
      "Graph 403: 326 nodes\n",
      "Graph 404: 286 nodes\n",
      "Graph 405: 12 nodes\n",
      "Graph 406: 32 nodes\n",
      "Graph 407: 351 nodes\n",
      "Graph 408: 361 nodes\n",
      "Graph 409: 309 nodes\n",
      "Graph 410: 372 nodes\n",
      "Time: 0.829944849014\n",
      "Graph 411: 338 nodes\n",
      "Graph 412: 18 nodes\n",
      "Average loss at step 10500: 78.813106\n",
      "Graph 413: 86 nodes\n",
      "Graph 414: 411 nodes\n",
      "Graph 415: 417 nodes\n",
      "Graph 416: 348 nodes\n",
      "Graph 417: 338 nodes\n",
      "Graph 418: 292 nodes\n",
      "Graph 419: 44 nodes\n",
      "Graph 420: 54 nodes\n",
      "Time: 0.561131000519\n",
      "Graph 421: 416 nodes\n",
      "Graph 422: 398 nodes\n",
      "Average loss at step 10600: 90.746623\n",
      "Graph 423: 405 nodes\n",
      "Graph 424: 380 nodes\n",
      "Graph 425: 342 nodes\n",
      "Graph 426: 45 nodes\n",
      "Graph 427: 56 nodes\n",
      "Graph 428: 459 nodes\n",
      "Graph 429: 453 nodes\n",
      "Graph 430: 415 nodes\n",
      "Time: 0.63062286377\n",
      "Graph 431: 420 nodes\n",
      "Graph 432: 335 nodes\n",
      "Average loss at step 10700: 94.873144\n",
      "Graph 433: 25 nodes\n",
      "Graph 434: 20 nodes\n",
      "Graph 435: 54 nodes\n",
      "Graph 436: 423 nodes\n",
      "Graph 437: 431 nodes\n",
      "Graph 438: 417 nodes\n",
      "Graph 439: 370 nodes\n",
      "Graph 440: 42 nodes\n",
      "Time: 0.440535068512\n",
      "Graph 441: 37 nodes\n",
      "Graph 442: 494 nodes\n",
      "Average loss at step 10800: 66.155149\n",
      "Graph 443: 173 nodes\n",
      "Graph 444: 435 nodes\n",
      "Graph 445: 445 nodes\n",
      "Graph 446: 438 nodes\n",
      "Graph 447: 52 nodes\n",
      "Graph 448: 52 nodes\n",
      "Graph 449: 492 nodes\n",
      "Graph 450: 534 nodes\n",
      "Time: 0.738555908203\n",
      "Graph 451: 584 nodes\n",
      "Graph 452: 496 nodes\n",
      "Average loss at step 10900: 90.426680\n",
      "Graph 453: 508 nodes\n",
      "Graph 454: 40 nodes\n",
      "Graph 455: 65 nodes\n",
      "Graph 456: 580 nodes\n",
      "Graph 457: 690 nodes\n",
      "Graph 458: 672 nodes\n",
      "Graph 459: 709 nodes\n",
      "Graph 460: 615 nodes\n",
      "Time: 0.811681032181\n",
      "Graph 461: 39 nodes\n",
      "Graph 462: 81 nodes\n",
      "Average loss at step 11000: 81.433410\n",
      "Graph 463: 715 nodes\n",
      "Graph 464: 716 nodes\n",
      "Graph 465: 624 nodes\n",
      "Graph 466: 620 nodes\n",
      "Graph 467: 594 nodes\n",
      "Graph 468: 46 nodes\n",
      "Graph 469: 90 nodes\n",
      "Graph 470: 715 nodes\n",
      "Time: 0.742980003357\n",
      "Graph 471: 770 nodes\n",
      "Graph 472: 742 nodes\n",
      "Average loss at step 11100: 110.327756\n",
      "Graph 473: 707 nodes\n",
      "Graph 474: 724 nodes\n",
      "Graph 475: 86 nodes\n",
      "Graph 476: 115 nodes\n",
      "Graph 477: 1057 nodes\n",
      "Graph 478: 1055 nodes\n",
      "Graph 479: 1216 nodes\n",
      "Graph 480: 1426 nodes\n",
      "Time: 0.800853967667\n",
      "Graph 481: 1211 nodes\n",
      "Graph 482: 201 nodes\n",
      "Average loss at step 11200: 106.425568\n",
      "Graph 483: 237 nodes\n",
      "Graph 484: 1410 nodes\n",
      "Graph 485: 1418 nodes\n",
      "Graph 486: 1457 nodes\n",
      "Graph 487: 1537 nodes\n",
      "Graph 488: 1374 nodes\n",
      "Graph 489: 233 nodes\n",
      "Graph 490: 287 nodes\n",
      "Time: 0.613966941833\n",
      "Graph 491: 1470 nodes\n",
      "Graph 492: 721 nodes\n",
      "Average loss at step 11300: 118.064921\n",
      "Graph 493: 728 nodes\n",
      "Graph 494: 693 nodes\n",
      "Graph 495: 688 nodes\n",
      "Graph 496: 78 nodes\n",
      "Graph 497: 81 nodes\n",
      "Graph 498: 757 nodes\n",
      "Graph 499: 811 nodes\n",
      "Graph 500: 752 nodes\n",
      "Time: 0.694382190704\n",
      "Graph 501: 678 nodes\n",
      "Graph 502: 616 nodes\n",
      "Average loss at step 11400: 112.099416\n",
      "Graph 503: 44 nodes\n",
      "Graph 504: 82 nodes\n",
      "Graph 505: 777 nodes\n",
      "Graph 506: 867 nodes\n",
      "Graph 507: 947 nodes\n",
      "Graph 508: 969 nodes\n",
      "Graph 509: 1080 nodes\n",
      "Graph 510: 246 nodes\n",
      "Time: 0.512779951096\n",
      "Graph 511: 317 nodes\n",
      "Graph 512: 1452 nodes\n",
      "Average loss at step 11500: 105.543008\n",
      "Graph 513: 1425 nodes\n",
      "Graph 514: 1098 nodes\n",
      "Graph 515: 234 nodes\n",
      "Graph 516: 284 nodes\n",
      "Graph 517: 179 nodes\n",
      "Graph 518: 309 nodes\n",
      "Graph 519: 1449 nodes\n",
      "Graph 520: 1345 nodes\n",
      "Time: 0.893393039703\n",
      "Graph 521: 491 nodes\n",
      "Graph 522: 508 nodes\n",
      "Average loss at step 11600: 113.832037\n",
      "Graph 523: 504 nodes\n",
      "Graph 524: 75 nodes\n",
      "Graph 525: 109 nodes\n",
      "Graph 526: 446 nodes\n",
      "Graph 527: 457 nodes\n",
      "Graph 528: 412 nodes\n",
      "Graph 529: 405 nodes\n",
      "Graph 530: 358 nodes\n",
      "Time: 0.617276906967\n",
      "Graph 531: 43 nodes\n",
      "Graph 532: 88 nodes\n",
      "Average loss at step 11700: 89.110350\n",
      "Graph 533: 443 nodes\n",
      "Graph 534: 473 nodes\n",
      "Graph 535: 491 nodes\n",
      "Graph 536: 525 nodes\n",
      "Graph 537: 352 nodes\n",
      "Graph 538: 55 nodes\n",
      "Graph 539: 61 nodes\n",
      "Graph 540: 506 nodes\n",
      "Time: 0.576679944992\n",
      "Graph 541: 355 nodes\n",
      "Graph 542: 635 nodes\n",
      "Average loss at step 11800: 90.860578\n",
      "Graph 543: 589 nodes\n",
      "Graph 544: 542 nodes\n",
      "Graph 545: 137 nodes\n",
      "Graph 546: 136 nodes\n",
      "Graph 547: 202 nodes\n",
      "Graph 548: 111 nodes\n",
      "Graph 549: 438 nodes\n",
      "Graph 550: 523 nodes\n",
      "Time: 0.636262893677\n",
      "Graph 551: 429 nodes\n",
      "Graph 552: 149 nodes\n",
      "Average loss at step 11900: 105.247316\n",
      "Graph 553: 142 nodes\n",
      "Graph 554: 401 nodes\n",
      "Graph 555: 131 nodes\n",
      "Graph 556: 439 nodes\n",
      "Graph 557: 394 nodes\n",
      "Graph 558: 383 nodes\n",
      "Graph 559: 83 nodes\n",
      "Graph 560: 66 nodes\n",
      "Time: 0.510829925537\n",
      "Graph 561: 487 nodes\n",
      "Graph 562: 525 nodes\n",
      "Average loss at step 12000: 100.595610\n",
      "Graph 563: 628 nodes\n",
      "Graph 564: 640 nodes\n",
      "Graph 565: 566 nodes\n",
      "Graph 566: 114 nodes\n",
      "Graph 567: 131 nodes\n",
      "Graph 568: 582 nodes\n",
      "Graph 569: 590 nodes\n",
      "Graph 570: 634 nodes\n",
      "Time: 0.85432100296\n",
      "Graph 571: 597 nodes\n",
      "Graph 572: 547 nodes\n",
      "Average loss at step 12100: 102.319884\n",
      "Graph 573: 82 nodes\n",
      "Graph 574: 115 nodes\n",
      "Graph 575: 258 nodes\n",
      "Graph 576: 584 nodes\n",
      "Graph 577: 565 nodes\n",
      "Graph 578: 552 nodes\n",
      "Graph 579: 539 nodes\n",
      "Graph 580: 106 nodes\n",
      "Time: 0.772296905518\n",
      "Graph 581: 138 nodes\n",
      "Graph 582: 573 nodes\n",
      "Average loss at step 12200: 100.304422\n",
      "Graph 583: 697 nodes\n",
      "Graph 584: 1771 nodes\n",
      "Graph 585: 590 nodes\n",
      "Graph 586: 542 nodes\n",
      "Graph 587: 87 nodes\n",
      "Graph 588: 124 nodes\n",
      "Graph 589: 585 nodes\n",
      "Graph 590: 637 nodes\n",
      "Time: 0.704403162003\n",
      "Graph 591: 638 nodes\n",
      "Graph 592: 241 nodes\n",
      "Average loss at step 12300: 114.708639\n",
      "Graph 593: 150 nodes\n",
      "Graph 594: 21 nodes\n",
      "Graph 595: 28 nodes\n",
      "Graph 596: 175 nodes\n",
      "Graph 597: 223 nodes\n",
      "Graph 598: 210 nodes\n",
      "Graph 599: 196 nodes\n",
      "Graph 600: 149 nodes\n",
      "Time: 0.711974143982\n",
      "Graph 601: 10 nodes\n",
      "Graph 602: 20 nodes\n",
      "Average loss at step 12400: 82.410767\n",
      "Graph 603: 39 nodes\n",
      "Graph 604: 196 nodes\n",
      "Graph 605: 154 nodes\n",
      "Graph 606: 165 nodes\n",
      "Graph 607: 183 nodes\n",
      "Graph 608: 16 nodes\n",
      "Graph 609: 37 nodes\n",
      "Graph 610: 220 nodes\n",
      "Time: 0.60608792305\n",
      "Graph 611: 188 nodes\n",
      "Graph 612: 206 nodes\n",
      "Average loss at step 12500: 90.571790\n",
      "Graph 613: 203 nodes\n",
      "Graph 614: 163 nodes\n",
      "Graph 615: 12 nodes\n",
      "Graph 616: 25 nodes\n",
      "Graph 617: 149 nodes\n",
      "Graph 618: 142 nodes\n",
      "Graph 619: 159 nodes\n",
      "Graph 620: 181 nodes\n",
      "Time: 0.632217168808\n",
      "Graph 621: 172 nodes\n",
      "Graph 622: 10 nodes\n",
      "Average loss at step 12600: 90.271416\n",
      "Graph 623: 30 nodes\n",
      "Graph 624: 112 nodes\n",
      "Graph 625: 163 nodes\n",
      "Graph 626: 127 nodes\n",
      "Graph 627: 157 nodes\n",
      "Graph 628: 117 nodes\n",
      "Graph 629: 10 nodes\n",
      "Graph 630: 16 nodes\n",
      "Time: 0.560750961304\n",
      "Graph 631: 121 nodes\n",
      "Graph 632: 140 nodes\n",
      "Average loss at step 12700: 73.792502\n",
      "Graph 633: 162 nodes\n",
      "Graph 634: 137 nodes\n",
      "Graph 635: 116 nodes\n",
      "Graph 636: 14 nodes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AnonymousWalkEmbeddings.AWE at 0x1a329599d0>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'parsed_graphs'\n",
    "\n",
    "batch_size = 100\n",
    "window_size = 10\n",
    "embedding_size_w = 64\n",
    "embedding_size_d = 2\n",
    "num_samples = 32\n",
    "\n",
    "concat = False\n",
    "loss_type = 'sampled_softmax'\n",
    "optimize = 'Adagrad'\n",
    "learning_rate = 1.0\n",
    "root = '../enron/'\n",
    "ext = 'graphml'\n",
    "steps = 5\n",
    "epochs = 2\n",
    "batches_per_epoch = 10\n",
    "candidate_func = None\n",
    "graph_labels = None\n",
    "\n",
    "model2 = AnonymousWalkEmbeddings.AWE(dataset = dataset, batch_size = batch_size, window_size = window_size,\n",
    "                  embedding_size_w = embedding_size_w, embedding_size_d = embedding_size_d,\n",
    "                  num_samples = num_samples, concat = concat, loss_type = loss_type,\n",
    "                  optimize = optimize, learning_rate = learning_rate, root = root,\n",
    "                  ext = ext, steps = steps, epochs = epochs, batches_per_epoch = batches_per_epoch,\n",
    "                  candidate_func = candidate_func, graph_labels=graph_labels)\n",
    "\n",
    "model2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEWCAYAAABi5jCmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1c06da90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shuffles = ['timestep_3.graphml', 'timestep_7.graphml', 'timestep_9.graphml',\n",
    "            'timestep_4.graphml', 'timestep_8.graphml', 'timestep_1.graphml', \n",
    "            'timestep_5.graphml', 'timestep_2.graphml', 'timestep_0.graphml', \n",
    "            'timestep_6.graphml']\n",
    "\n",
    "shuffles = map(lambda x: int(x[:-8].split('_')[1]), shuffles)\n",
    "\n",
    "fig = plt.figure()\n",
    "right_order_ge = np.concatenate((model2.graph_embeddings[shuffles], model2.graph_embeddings[10:]))\n",
    "norms = np.linalg.norm(right_order_ge, axis=1)\n",
    "\n",
    "plt.scatter(np.where(labels == 0)[0], norms[np.where(labels == 0)[0]], label='normal', c='b')\n",
    "plt.scatter(np.where(labels == 1)[0], norms[np.where(labels == 1)[0]], label='outlier', c='r')\n",
    "\n",
    "plt.xlabel(\"days\")\n",
    "plt.ylabel(\"$||X||$\")\n",
    "plt.title(\"Norm of embedding on time\")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(ls='dashed')\n",
    "#fig.savefig('norms_series_shuffled.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Matrix norm \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Посмотрим, что происходит с нормой матрицы слов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Embeddings characteristics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One class SVM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Попробуем поискать выбросы, не учитывая то, что в задаче имеется временная зависимость. Тут пробуем одноклассовый svm, в следующем пункте пробуем isolation forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([122, 343, 345, 365, 412, 417, 420]),)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(labels == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2e7dba90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start, stop = 1, 500\n",
    "fig = plt.figure()\n",
    "cls = OneClassSVM(kernel='rbf', gamma=1.4)\n",
    "cls.fit(model.graph_embeddings[np.where(labels == 0)[0]][start:stop])\n",
    "plt.scatter(np.where(labels==0), \n",
    "            cls.decision_function(model.graph_embeddings)[np.where(labels==0)], c='b', label='normal')\n",
    "plt.scatter(np.where(labels==1), \n",
    "            cls.decision_function(model.graph_embeddings)[np.where(labels==1)], c='r', label='outlier')\n",
    "plt.grid()\n",
    "plt.title(\"One class SVM outlier score\")\n",
    "plt.ylabel('score')\n",
    "plt.xlabel('days')\n",
    "plt.legend()\n",
    "fig.savefig('oneclass_svm.pdf', format='pdf')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Isolation forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEWCAYAAABBvWFzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2e924fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "cls = IsolationForest(n_estimators=200)\n",
    "cls.fit(model.graph_embeddings[np.where(labels == 0)[0]][:])\n",
    "plt.scatter(np.where(labels==0), \n",
    "            cls.decision_function(model.graph_embeddings)[np.where(labels==0)], c='b', label='normal')\n",
    "plt.scatter(np.where(labels==1), \n",
    "            cls.decision_function(model.graph_embeddings)[np.where(labels==1)], c='r', label='outlier')\n",
    "\n",
    "plt.title(\"Isolation forest outlier score\")\n",
    "plt.ylabel('score')\n",
    "plt.xlabel('days')\n",
    "plt.grid()\n",
    "fig.savefig('isolation_forest.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Всякие разные вопросы, возникшие по ходу \n",
    "\n",
    "* можно ли считать AUC для такой задачи, чтобы сравнивать модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEICAYAAABLdt/UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnX2YX1V1779rJhOHJIzgjFXHyARvqZEkY4AANVrxlqiY\nqi2+FOlIQ0cdQ6qXeaq9rQ2+VVPbq9eGe32hsU3EzKikVKy1GCVari8BNBGcEBhRSwIRFSdAA4QY\nJln3j/M7mTNn9j5n7332eZ31eZ7zJPP7nd8+e5+zz9prr7X22sTMEARBEJpDW9kVEARBEPwigl0Q\nBKFhiGAXBEFoGCLYBUEQGoYIdkEQhIYhgl0QBKFhiGAXBAeIaB8RrfJU1meI6EMJ3zMR/Wbr/9cQ\n0Xt8XFdoLiLYhWkQ0WOR4zgRPRH5e4CITiGizUT0CyJ6lIjuIaK/iPyeiWgPEbVFPvsQEX2m9f9F\nrXMeix2XlNDc2sHMa5n5g2XXQ6g2c8qugFAtmHlB+H8i2gfgLcy8I/LZFgDzATwfwH8B+C0AS2PF\n9AJ4I4DPJVzqFGae9FRtQRAiiMYu2HIugM8x88PMfJyZx5n5+tg5/wvAB4gos+JARL1E9GUieoiI\nfkJEb418934i2kZEn23NHvYS0YqEshYT0U2tsn5ERH8Y+e4zRPRJIvpqawbxXSJ6JhFtJKKHiWic\niM6K3wsiuqv1/RYi6oyU9yoiuoOIHiGinUTUH/nuLCL6QavO1wHojBZKRH9ORD8nogeIaDD23Qmz\nDRG9lIgOENE7iejB1m/+JHJuNxH9GxEdIqLvt2ZO32l9R0T0963f/RcRjRFRfIAWaooIdsGWWwFs\nIKI/IaIzNOd8EcAhAJd7uN7nARxAMAt4PYC/IaILI9+/BsAXAJwC4MsAPq4qhIjmA7gJwSziNwBc\nCuCTRLQkctofArgKQA+AXwO4BcAPWn9fD+BjsWIHALwCwH9DMHO5qnWtswFsBvA2AN0A/gHAl4no\nKUQ0F8CXAGwF8DQA/wzgdZF6XgTgXQBeBuAMAGl2/GcCeCqAZwN4M4BPENGpre8+AeDx1jlrWkfI\nywG8pFXvUwBcAuBgyrWEmiCCXbDlHQBGAbwdwF0tLfqVsXMYwHsAvJeInqIpZ6KlzYbH8+MnENFz\nALwYwF8w8xFmvgPAPwK4LHLad5j5RmY+hkBYvkBzvVcB2MfMW5h5kpl/AOBfEAwWITcw825mPgLg\nBgBHmPmzrbKvAxDX2D/OzPcz80MANiAYLADgrQD+gZlvY+ZjzHwtgoHit1tHB4CNzPxka7bz/UiZ\nfwhgCzPfycyPA3i/pj0hTwL461ZZNwJ4DMDziKgdwYDxPmY+zMx3Abg29ruTASwGQMx8NzP/POVa\nQk0QwS5YwcxPMPPfMPM5CLTRbQD+mYieFjvvRgD3ARjSFNXDzKdEjrsV5/QCeIiZH418th+Bdhry\ni8j/DwPo1JiA+gCcHx1MEGjcz4yc88vI/59Q/L0A07k/Vq/eyLXeGbvWc1rf9wL4GU/Pvrc/8v9e\nRblJHIz5Kg636vl0BD60aFkn/s/M30Qwu/kEgF8S0SYi6kq5llATRLALzjDzIQB/g8CZerrilKsA\nrAcwz/ESDwB4GhGdHPnsNAA/cyjrfgD/LzaYLGDmKxzrBgTCOlqvByLX2hC71jxm/jyAnwN4NhFR\n7LchP1eU68KvAEwCWKipL5j5/7QG6CUITDJ/7ngtoWKIYBesIKL3ENG5RDS35Sy8EsAjAH4UP5eZ\nbwawB9Ntu8Yw8/0AdgL4MBF1thyQb0ZgCrLlKwB+i4guI6KO1nGuygRkwZ8S0cLWbOWvEJhrAODT\nANYS0fktJ+V8Ivq91gB1CwKB+z+IaA4RvRbAeZEytwG4nIjOJKJ5AN7nUrGW+eiLAN5PRPOIaDGA\nPw6/b7X9fCLqQGCHPwLgmMu1hOohgl2whQFsATCBQEN9GYDfY+bHNOdfhcBJGOcRmh7H/mea318K\nYFHrWjcgsBnfZF3pwJzzcgRhmA8gMOH8HQCdD8CEzwH4OoD/bB0fal1rFwI7+8cBPAzgJ2g5kpn5\nKIDXtv5+GIHT8ouRen4VwEYA32z97psZ6vd2BI7VXyDwP3wega0fALoQDEAPIzD3HATw0QzXEioE\nyUYbgjA7IKK/A/BMZnaaQQn1QTR2QWgorbj9/pY56DwEZqwbyq6XkD+y8lQQmsvJCMwvvQAeBPC/\nAfxrqTUSCkFMMYIgCA1DTDGCIAgNoxRTTE9PDy9atAhHjhxBZ2dn+g9qRNPaJO2pPk1rU9PaA/hr\n0+7duyeY+elp55Ui2BctWoRdu3Zhz549WLZsWRlVyI2mtUnaU32a1qamtQfw1yYiSluJDEBMMYIg\nCI1DBLsgCELDEMEuCILQMCSOXRCE0njyySdx4MABHDly5MRnx48fx913q5J91hfbNnV2dmLhwoXo\n6Ohwup4IdkEQSuPAgQM4+eSTsWjRIoQJLw8fPox581wTglYTmzYxMw4ePIgDBw7g9NNVSVPTEVOM\nIAilceTIEXR3d58Q6gJAROju7p42i7Els2BvpVP9HhH9kII9Jz+QtUxh9jA6CixaBLS1Bf+OuiTk\nFWqNCPWZZL0nPkwxvwbwu8z8WCu383eI6KvMfKuHsoUGMzoKDA0Bhw8Hf+/fH/wNAAMD5dVLEOpO\nZo2dA8Jc3B2tQxLQCKmsXz8l1EMOHw4+T0K0fKEpvPSlL8WuXbu8l+vFxk5E7UR0B4IMcjcx820+\nyhWazX332X0OTGn5+/cDzFNavgh3oWgmJyfTTyoJL1ExrW24lhPRKQBuIKKlzHxn9BwiGkJrY+Pe\n3l7s2bMHExMT2LNnj48qVIamtSnP9lx5JXDo0MzPu7oA3SV37QLe+Eb15/396dds2vMB6t2m48eP\n43Bs2jY5OTnjs5DrrmvH+97XgQMHCAsXMj7wgSdxySXuO/rt378fF198MV74whfitttuw7Oe9Sxs\n27YN99xzD6688kocPnwYz33uc/GpT30Kp556Ki666CKcf/75uPXWW7F69Wrs3bsXJ510Eu655x7c\nd999uOaaazA6Oorvfe97WLFiBTZt2gQAeMc73oHbb78dR44cwR/8wR/gqquuOtH+I0eOKNt79OhR\n9+fKzF4PBHs0vivpnHPOOYeZmcfGxrhpNK1NebZnZIR53jzmQPcOjnnzgs91EE0/PzyIzK7ZtOfD\nXO823XXXXTM+e/zxx5XnuvSXNO69915ub2/n22+/nZmZ3/CGN/DWrVt52bJlfPPNNzMz83ve8x6+\n8sormZn5ggsu4CuuuOLE79esWcOXXHIJHz9+nL/0pS/xySefzGNjY3zs2DE+++yzT5R7//33MzPz\n5OQkX3DBBfzDH/7wRHnf//73lXVT3RsAu9hADvuIinl6S1MHEZ0EYBWA8azlCs1nYADYtAno6wOI\ngn83bUp2nJ52mt3nQnNw9cmkcfrpp2P58uUAgHPOOQc//elP8cgjj+CCCy4AAKxZswbf+ta3Tpx/\nySWXTPv9q1/9ahARli1bhmc84xlYtmwZ2trasGTJEuzbtw8A8MUvfhFnn302zjrrLOzduxd33XVX\ntkqn4MMU8ywA1xJROwKb/TZm/oqHcoVZwMCAXQTMhg3TI2kAYN684HOh2bj4ZEx4ylOm9jNvb2/H\nI488knj+/Pnzlb9va2ubVlZbWxsmJydx77334uqrr8auXbtw6qmn4vLLL88Uo26Cj6iYMWY+i5n7\nmXkpM/+1j4oJggoXLV9oBkXN1p761Kfi1FNPxbe//W0AwNatW09o7y4cOnQI8+bNw1Of+lT88pe/\nxFe/+lVfVdUiKQWE2mGr5QvNoMjZ2rXXXou1a9eecJ5u2bLFuawXvOAFeMELXoAlS5bguc99Ll70\nohd5rKkGE0O870Ocp/VhtrRnZIS5ry9wwvb1ZXPIFU2dn5GN85S5vs8pqU06sjhPRWMXZj2yArY+\nyGzNDEkCJsx68oq2EISyEMEuzHryirYQhLIQwS7MeoqOjZdcN0LeiGAXZj0bNgTRFXEee8y/0JVc\nN0IRiGAXZj1hbHx39/TPDx70L3SLsufLrGB2I4JdOMFsFgYDA8CCBTM/9y10i7Dny6wgPz7zmc/g\ngQceOPF3NO3u6tWrU1etFoUIdgGAXhiMz6KsP0UI3SLs+XnMCmbzoB8lLtij3HjjjTjllFOMyzp2\nzD0rZRoi2AUAemGwc2c59SmDIoSuyp7ve/Wk7wGqUjOAHEaYj33sY1i6dCmWLl2KjRs3Yt++fVi6\ndOmJ7z/60Y/i/e9/P66//nrs2rULAwMDWL58OZ544olp5SxatAgTExMAgJGREZx33nlYvnw53va2\nt50Q4gsWLMB73/tenH/++bjlllsy112HCHYBgP6lV+VLbypFCN0ict34HqAqE+efwwize/dubNmy\nBbfddhtuvfVWfPrTn8bDDz+sPPf1r389VqxYgdHRUdxxxx046aSTlOfdfffduO666/Dd734Xd9xx\nB9rb2/GFL3wBAPD4449j6dKluO222/DiF7/Yud5piGCvMT6VF91L39XlXmbdKCrB2MAAsG8fcPx4\n8K/v8n0PUJWJ889hhPnOd76Diy++GPPnz8eCBQvw2te+9kTyL1e+8Y1vYPfu3Tj33HOxfPlyfOMb\n3ziRvre9vR2ve93rMpVvgqQUqCm+l8HrEiytXJm9rnWiCUvWw/qvXx8I39NOC56va7tOOy3oX6rP\nCyWHESZIvzKdRx55BMePHz/xt22KXWbGmjVr8OEPf/jEZ+EOSZ2dnWhvb3esrTmisdcU38qLTlsF\n/MwKxPlWLD5nBUWYqIzIwQnykpe8BF/60pdw+PBhPP7447jhhhvwyle+Eg8++CAOHjyIX//61/jK\nV6a2lzj55JPx6KOPJpZ54YUX4vrrr8eDDz4IAHjooYdwX8HTGxHsNSWP6XFcGADAjh3ZTZqVcr41\niHCw3Lgx38GyMjnwcxhhzj77bFx++eU477zzcP755+Mtb3kLzj333BMOzle96lVYvHjxifMvv/xy\nrF27Vuk8DTnzzDPxoQ99CC9/+cvR39+Pl73sZfjFL37hXEcnTFJA+j4kbW92+vrUe3/29fm9xuDg\nWOZrFFHXOLr0rk3pc9H9P8NnlHX/zzKwTdtb17y9RaftFY29plQ5bC5udlHZZ03KcUU1Q7jsskDb\n3Ly5GTOFykSqGODVDJe357khiPO0pvh2kKlwMWmqnLpEgYC1KScLKqEXXv/QoWbkWq9MpEoKkuu+\nHERjrzFFhM3NiQ39abMCnVAlsisnC2nCraqarQ1Jg26VHNUmMwtWjfqznKz3RAS7oGVgAFi1ys5p\nphOqzMU530xmAlXTbG3RmeJWr66WozptZtHZ2YmDBw+KcI/AzDh48CA6OzudyxBTTA0ZHc3XBBNl\n8eKpCBkTdDHPfX125WRBFZMfhznQZvO8d3kSNcUBwf3dsCFZQy6jnWkx8AsXLsSBAwfwq1/96sR3\nR48exdy5cwuqYTHYtqmzsxMLFy50v6CJh9X3IVEx7kSjIcLDZzREPOhg2za79hRdP1254XlAcG5Y\nl3iUTx0jSeJE+1y0rdGDqJy6ufQHkQt6UFRUDBE9h4j+g4juJqK9RHRl1jIFPXlGQ6iiSXbssJvG\n5xnzbBMPH/ofmIGtW4N6qGiCvT1K0btBpVGZGPhZhg8b+ySAdzLz8wH8NoA/JaIzPZQrKMgzGkI1\naExO2gs+E6eui4PPdVAL6xN34IYk3bsqOSJNqMwq0QgSoVg8mQU7M/+cmX/Q+v+jAO4G8Oys5Qpq\n8tTIigqhc12JmrV+tvdu3bog/r0qjkgTREMWAIDYozeaiBYB+BaApcx8KPbdEIAhAOjt7T1n+/bt\nmJiYQE9Pj7frV4G82zQ+HphHJienPpszJ4heiax8duKaa4B4vqMlSybw05/2YO3abGVH2bxZnQ64\nqwsYHPT/u5DxceBnP5vAnj1Tz0d378bHge3b1eWYXq8omvYeNa09gL829ff372bmFaknmhjiTQ4A\nCwDsBvDatHOb7jzNe9Vz1vJ1v+/unul0Gxwc4+5uv/V0dfD5cMxu2zZmdO90aRCi9azK6vamvUdN\naw9z8c5TX0K9A8DXAPyZyflNFuzbto3lGhWSlSThqBK4g4NjThEVSdfJkjsmqzA17XO6wSesZ97R\nPzbo2lSVgceWJsqF2gl2AATgswA2mv6myYJ9eHhm0qy8E17ZkCRUVd8NDo451T3pOmUKRdM+p6s/\nUfbByRRTwaxqU5UGHluaKBdqF+4I4EUALgPwu0R0R+tY7aHcWqLbSq4qKx2THJCqiIo5c9wiKpKu\nU4aDzzbFrepeEAFr1wb1zNvRnDXVcZ2ShAn+8REV8x1mJmbuZ+blreNGH5WrI7qt5NraqhFNkRQZ\nohK4q1a5Cdy0CJRoCFy4YjKvkMKokATMhKTqXmzdCnzyk9PbEcdXvHhWwVyXJGF5UbcwVe+YqPW+\njyabYlQ29ipNhW2n6K7PyPQ6RZgMomaT6MrTLGaTvOtt42BWPaMycuD7IqtcqKIZqnY2dpejyYI9\njIppb6/ui2XjVMvyjEyuU4QA0qUUyLrMPg/nZJL9XndfstjYq+hg1bXHtJ5VHNREsNecsE1Vy9nh\nSl7PaGREHV6Zx33KQ2PPA5UwNtE6XaNiitBsXQaOeHts61nFd6+OzlNBQdVydlSJ0dFggc/Bg/pz\nfN6nKi6zV6Gyq4e4OJjTlvLn7WD1tdetbT3l3ZN87LlRdWFSpnNp/Xrg6FH9977vU9QRClR3mb3O\nsUmUT46VvB2svgYO23pW/d0rAhHsOVHlnB2+NClX0gTHmjX+71OovQ4PVzcRVdGaZt7X8zVw2Naz\nyu9eUYhgz5GqZbULtfQ3vancGOc0wXFjAcGyec5YXMsuWtPM+3q+Bg6Xelbt3SscE0O872M2OE+r\nRppjziaUzkdd5s7N7jh1dczl6TTMWrYPZ6NtffOKinG9F1mjYqqIRMXUnKq2KSmEzjaUzgcjI8xt\nbeb1UP3eVWjkGQ5XRqhdVfscc/EDVVWRqBghF9LsmtGpbdSUsHlzPrb3gQHgs59NnmInmTSSHHNp\nppA8nYazfcVnnFlvEikJEeyzhCS7ZtS5FHesHjqUn2M1ycmV5uDVCcrwvCTHsO5etLVlt7kX7QAd\nHQ0G3zovnY8PxOPjZdeoAZio9b4PMcUUj6npIm5KCBf02JgSfNhD00wauu91K37DnPI6G7vpYiCT\nthe1nD28VnTRVV1Wl4ao7tfQ0Fil6ugDsbHXnCLa5PqimvwuvmovFBo2Dk0fgi1t9aDuOknCemRk\n6vmkrXzNYhcvSpCGg1tUsMfrXcW8KVF8poquMiLYa07ebcr7Rc2qsftyHpqUoxKgaXlWos8nzaFc\n9fQP4eAXF+zRelcxb0oUn5u7VBlxnuZEU9J45r0MPGtssy/noUk9VI65pHrG65BWp6ovQTex52d9\nHuvWBTn5iYJ/162zq2Masvw/H2aFYC97pWVSvUwHm/DcMKd4HF9RF3GHZleX3ao9Xy+q6+rBgQGg\nu9usDkl1qsMSdJPBL8vzWLcO+NSngGPHgr+PHQv+9incfW7uIkQwUet9H0WbYnxNR01sp6ZtsjGp\nmDj78ppa2z4jVV3D6XZRjrukexttj+6+dndP1TMve7mvckdGgu0Y88jgqHNEt7e71TWpDdF7sW2b\nmGh1QGzsU/hI42n6gmTdU7O9PT1SJX7k6QxzeUZRW3f83vuoq4lQ1J2jSgkbntfdHRzhb664Ih9/\nhm8/SdozUt0Lk3uY1OfyRHxvekSwR/ChsZuWYdom3WCjesmTzs1bC87yjPJw3GUVikm5y3UzDd+z\nI9/3xcesSnUPi9LY44hg12Mq2GeFjd1HsiPfKwqTbJxxZ6ju3L6+fFbz+Vp5anvPTHwOeTmPVeUy\nq8+1febxduXtJ0nD9B4ODal/r/u8LjQlkCIRE+nv+ygj3DGrTdO3xp5mN4+aicpY9BJeZ3BwzPpa\nLtu7mbYxq1ktbmMP+0SS2SGLZm0zEwgXUaWVF+/Htu+RyRqB8BoLFkyd394emKfyJk+5UFZcv5hi\nKopvG3tYpuneqEUveokKdhthljZg6V4i04EzqxkjukApzSGtEsK2QsAk+Vp4zJ2bXLauD9o6G5Pu\nYRUWNOWZ3bGsuP5aCnYAmwE8COBOk/PrKNiZ/UbFRMss+0WKknXlaZqmrmuXqSauu19XXGH24ofP\nx0Tg2pSrw+dsQFfn4WF/fa4KC5qy7nmaRFn7odZVsL8EwNlNF+wmZIkiyVsbN7lOVo3d9cWxESjx\ndADz58/M75628XOSwPX5HGw09rT7pKvz4KC/PleFjaDj75DPwWa2aOxenKfM/C0AD/koazbiI7Vp\nmkPIdJFWVkez64IY2+s+8cTU/x9/fOYeqmkO1SSHtM8Us7p2mS6iMvmuq8u+Xro+V8WVoD4DF2bL\nfqgUDAIeCiJaBOArzLxU8/0QgCEA6O3tPWf79u2YmJhAT0+Pl+tXhTLaND4O7NgBTE5OfTZnDrBq\nFbB4cfD35s1BCt44XV3A4ODM8nbuDM4/66wJPOMZPSfK8VGXpN+G1+3qAlauVP9G1xYVw8PT/w6f\nT5Z62qJqF2B/fV2dX/GKCZxxhp8+V+R90RF9RuF9U6HquyaY9jOf+JIL/f39u5l5ReqJJmq9yQFg\nEcQUU0qbTKaXrlPsKpqWTO3W0cRg4QKkdeumVmlmtZ9nxeU++YiKyaNePjFJrVylDJUm1NLGziLY\nT1BGm0yEtqttsYrPyMbxGRcOabnL60gVn1EWkrYvjA7YdaKWNnahXEzsok2yLara0tER2K2jCcNu\nvHHmQpwoPrNiCn7R2c+JZIs9E7wIdiL6PIBbADyPiA4Q0Zt9lCuYYZri1iVbYhVRtWXLFmBiYroz\n0MS5Vre9SGfFqklU04lbJ3xFxVzKzM9i5g5mXsjM/+SjXMEMU6HdpI2FTdpiIgSYzQVk2UJVF9nU\nxD1C6zrDLLuPhIgppiFkFdomHVJ1TlU6sgqVcFCRlp9/dBTo6QHe9Kbicvqr7qsux8vOnfnUoUzq\nOMOs1L4PJoZ430eVnadZIwKq2KY0TPKXq87p6Ji5MKijY2rxUJguwdXZ5SM6QxUVk+SUM7k3eS9s\n0T0PXR1cFihVGZfV22VG8YQkBSjUNirG5qiqYDdZupzWiarWJhNMOqTtCsqs4Wkmm2C4MDY2ZhX6\nmdbuPFZkJuXqV31um1Kg6tjmW6pKSo6kfiVRMSWSls7Ux1SriqYLk5V9WZ2MthEoqmcBAAcPmt9z\n3b22ccxl2RfV9VnrrnnsmNruHC54ynLNupL3HsA6VPe5Ug5fE+nv+6iqxp6myZnEgie1qUraRZRo\n3pW4duxLY7fVbtMWIaWZQJIyIdo8h6R2Jz27LM86LfuiboFSXv2raFOHjVwoI7dNUiI6ky0ZswAx\nxdiTJrhNOlFSm6qQOU+FiWA3tbFnEcZRTE0gOqGTlgkxTVhFMx2qnnuaSUh3T03uga2ATht8y9yx\nygUbuVDGO2U78DKLYC+VtE6cVWPPW7tw1axMbYOq8tM21XAVBiZOy6TnlSUTYtLmGCb3dWQkfUAy\nqYPpswyfUdZrqihDcFbdxu7yHotgL5mkF8qkExWtsSdplj6m/j52hMoS0aLSfE1yh7vmLrfZ/ERH\n2nJ407aH5aRFF4W5VfLYo7UMU0fYHtOBrWhTkct7LIK94mSJismqCZqU5/JSm4Q7mnDFFdl3HNLV\nzyZ3ePzeRuuStNtQ2v00FWZJ9VLdi3j7VLbapPuZlFuFKNv996mMmArgbdvGKumLCnGZJYhgrzlp\nbfKhYYeYmECyTv2rbO80bX904HSZUfnS2FV7miYN9qb1SArhBMzqrMOXqcOmnOFh9VqDJBt20djW\nQwR7zTFtkw8haJK+NqtQrXKEgsmMBQhMGSYDVdL9tBFmvqJuTAfrJI1d9/yLNnXY1C+agVP1HLIO\nMmUggj0nihrpTdvkQwimCQUfnb4sjd30eUXPM7kXLhp7dGDwXX/bPVF1GrtukGtrm/pNWIeqOxx1\nGntW30eZiGDPgSI7cpEau2+bvYoyIhRcyzExpVRtnUGSbVw3QMU3CAn9Bjpnc7wtVQsRjKOzseva\nVeR+rK6IYM+BIjtyligSVyFoq9naCP0y8na4Pi8T04ypDySPmZ0uXFQ1OF94oToqRuVYHRoaO1HP\nJMEellGlRT1JUT7xe1XGgOQLEew5kNTRfWOr4RZhHsoyiPgQhLbttBE8qogS3ZSdKDkqxhZbO7Xu\nGdhEE6mE2+Dg2InrJ/X18B6UJSBN75euz5Uxo/KFCPYc0L3o7e3+r1VFh3CWFzmr6cLlZTStr04g\nqj4PD18Js2zNYC4x96rno2rX4OBYosCOl1mmgDQR7ml9rgpRMbaIYM+BqmrsRZFl6p11wZXLoGI6\nYCQtyNE973DlaXRq75Je2NZxnfQMsmabDDV2UwdytP1FCkjVc+3oYF6wYOrv7m6/s6qqIII9B6po\nYy+SvDR2E4HkOqikCZ40waqzNQ8P6yNIbDRX21BTXxq7qu6hjT3pnlRBuzUN7XzLW8ZKrWseg54I\n9hyoYlRMkeRlY89LYzchTTioEpSFK09NomfSMBFS0cEr6RnYPp+44IlGxbg+5yI0eNPQznAGUgZ5\nyQoR7DlRtTj2IomHwdlsVpHFxq4Lv8v6oiSZYeJae/yZp63SjAtk1bVDoW67QjSpD2bpn2mJ2tIo\nSvEx1dhDn0EZ5KWIiGCvOVVrU9aX1jUqRmfuyLoDErO5gIgLh5ER/eIXk5c4yWGaR44cU7L2uTRh\n5kspMglHLVtjzysUVAR7zcmqPfkmqwYyNjbm1JAssehplzKd0re3z0yslbRcPU0g69rU3j5z0VCR\nzzrre5QkzHxr89Hn292tvnaZNnbR2KOFABcB+BGAnwD4y7TzZ4Ngr0rMbVYNZGzbNqeGuFzX9J6Z\nauwqzVol2E2jYrLmkslroM9TY89zgB4ZUW/UsnHjzPZUZc2Haz1qJ9gBtAP4KYDnApgL4IcAzkz6\nTdMF+8hTiswNAAAenElEQVRIdfJaZNbYh4edCnC5rulvTKf0qiMu2FXmGt2Lm8XpmudAnzXuO6lu\nZQzQ8bUGpuGvvgS/jXnR10I/U4oU7C8E8LXI3+8G8O6k31RFsOehBajyXJi+EHmQ2cY+OKhsyDFQ\n4j1zua7tilPd4Gkj2KPCWBdnHZoMuruDv02erSpOPq+BPjpLjPbnpD04VfdT9S7kOUDrnnd8lysT\nH0CZzt+sYcM2FCnYXw/gHyN/Xwbg40m/qYJgz6szpDnnynAKZRnAdq9Ta+z3oi/1ntle1/bF0T3D\nJJNJVLDHV4qamHjmzp3KmGgjaEwGA1d02R2TFnCZkucAbaqxp5WX5PvwKdzzWuhng6lgp+Bcd4jo\nDQBewcxvaf19GYDzmPkdsfOGAAwBQG9v7znbt2/HxMQEenp6Ml3flc2bgUOHZn7e1QUMDrqXe9NN\nE9i7V92mOXOAVauAxYvdy8+b8XFg587g3nR2Auf+5o/Rf+fX0IHJE+c8iTnYgVX4EYKGZL1n0Wvv\n2AFMTl0q9Z5F69vVBaxcCWzfrr/GWWdN4PbbZz6fOXOmXzeJzs7gXF09dX1LhY97NzExgS9/ucf4\nmgAwPGx+ruoeJ/Vh03dL97xf8YoJnHHG1DNKK2/jRn1dfL5zWWTGj388gW9/u8f4Huro7+/fzcwr\nUk80kf5JB2pqiskrrCkpl7St9lB0VI1KOxscHONLMcL3oo+Pgfhe9PGlGLG+Z6ZtUZkwQrOC6b1I\n0vyTNqUwPcJoEV19TKN2fNrYbfK65z1rtNHyVfcxLhfSysvi+8irXfHfDQ2NeXn2KNAUMwfAfwI4\nHVPO0yVJvylbsOfp3PS1X2PWl8PkuziqFyQtPNDkntm+ECamDNvfh+fbCkGX9poMHL6jYnTXLCu+\nPotSopILaX28KL+WS7v6+tTvkYusKUywB9fCagD3IIiOWZ92fpmCPakT+Fo67EPTzhIh4rpUXZc5\n0FXA2rYl7XybF0P3DGw09u5udVoCEw0tqVwfgjXavuHhMa2jtMz4eldc5EKVItHiEKnfI5cBp1DB\nbnuUKdjzdrT4alOaqSjN2Wcbg6x7MeIdcu7cqSgRU0Fha/Yy1ahdXoykbeTS7rNNFkhdEjLVhta2\nxOs/ODg2Q4h3d0+P5rF9ZmXi+g4VFR1jS201dtujTMGel209xFebkoSyqWAybWtSeW9961hmoVCG\nxq4jHhpoUraLwMhTyMTrHQoN06icIoWdy+w1yztUtF/KhFra2F2OKmrsvqZrvtqUJBhMbbimbU2a\nxfjIja0LxbviCvPzfQinkZHAbBF96U12LzKJo9YtaLH5PF5Xlfad5AdJC//Lo78n4Tq4lb2+JQ/C\nrKJZBxwR7BqyalJpL6XPNumulWaqsLWxJ2n2vtpjs/2bqu0mtmITB1uaz0A14NjmUonHx8fraLKK\nMs0ZmKSxm5iyilgo56pENVGw126BkstRhagYl9HT5KXMq03ROqetZLSNikkLD/RB3jMl05A4lyif\npLqnace22n/SOTrhHtrYTcP/fN73JFzNnmVuOJ4XIthzJGuHMHkp82hTXqaJpPKj4YG2ZdnMMtJe\nctNnlvZskpKApdUp6f6YaMfR/pF0Xoip8zgaFWOj8RdlY89DY6+qgzQNEew54aNDmAinPNqUZAP3\npbUkhQfalGHrF0gLWTR5ZknhhXG7s2tcvu7+mGrXISYbq9tq3Glx33lHxST5Enzb2POe+dliqniI\nYM8JHx2iLI0970ieJFSrAHUd2TaSJ+0lN7nfadppPFLERLDb2O9NZlO2Grutxl3lnEu+o2LKfBfi\n2PRpEew54aNDlGVjL1NLiW8cktR+09h705c8zWlpa98Oo2KSfqOKM09q98iIPmZdVQfTZ2mjcfuM\nxLLV8pNmk64zg7po7DZ1EcGeQBYbua8OUWRUTPSaZdkVo+1Ju4e+Xzpded3dZtkTkzQnmygdm3qE\naX5D4Ra2P6t5IgnbJfgqXO3ySf4A01W68Xq62NjLWGFroyyKYNfgI0yxCOFYRFRMXjb1tJfMRCM3\nCeUzbYdO2Jg4F6M26yguWxfa5paZP9+/eSIJ26RZ8XNNbPq6ATrtty4+lLS1E/H7Z5N33ieisXsQ\n7D60wSLCpOoQg6t6oTo61HlRoi9Zmg09/F639N5lcE0zdSQdqrLiC5RMMBV8LoLRR5+M9zkbc4/J\nzCc+gNuUkWTq1NUzno89jbLMM2Jj9yDYq+Q0SSJLnouippI2gir6kiVNg006uOsL6CJYdUIs6jw1\n1ep07bYdcGzCKNPqE+0rcQ03aYZhG9Fj8pxGRtwScOnqGd9BKY28ZUPSuylRMRkFe5WcJkm4ZqYr\ncippY1qIv2Sqjmz6bFxfQFtTSHQ7u3gd07bGs3mBR0ayCUaXPq3qK0ND0+PYTZ3KNvc1j9w4ddDY\nVe1KSoehQwS7hjIdiDa4PMCiBy1XjV1HmoYYCkOdhuuqsYdx/PFMhiqTUnSgUg0qrv1L1yYTx6zL\nQKe6F4ODY1YhoOE9T+oHLrHvPhy2JjZ203J8yAbdPQojs0wRwZ5AkeYKV1weYNFmJlcbu46kzh/9\ne+7cmZtBm5oeTF/cpEFAJdizRvRcccXM38ydaxalYXPNJF/D4OCY0syTZCrS5bkpWlmyjYqxKccH\naUqLKSLYa04dNHZmt6iYpLJ0ibBUmqDLC+grgiUu2MMptcvgOjIyczCMl2t733Qra+MDYrxNthEr\n4flVVJaqJBeS7qGN4iWCvebUwcZug2l74gLC9mXwJWCK1NjT2unLfJFmOovb2EOSBrkq9C0dVZIL\nSb4I0dhFsKdSRc2J2X2gsnkZfA5surJ0GjvgXoe02YGvGVfadXTmMt2A4LKLU5H9s2pywTbltIqi\nBXsbhEowMADs2wccPx78OzBQdo3cWb8+6P5xiIANG9TnHz48/bPDh4PPXTjppKn/d3cDmzYBfX3q\nc4mA0dHgfofnEQX/btqU/BxOOy25HvfdZ17n0VFg0SKgrS34d3TU7Drd3cDOnerfbdgAzJs3/fx5\n84CrrzavV1i3oSFg//7gue7fH/wdvZZNWbp2FvF7Fz75SWDrVru+UTom0t/30WSN3WSnlKpq5yp8\nOoND7dj0fFvncZLWHTo5fe09GV5PZ2O3KTdttqCzsc+ZE3yeFJvvo6/58gGZzop0fa7KJss0xBRT\nY0ZG0vc2rFvnVC3BB5I3drYNEfMlOJLK0cWxJw04JoyMMC9YMLM8m2dq0v54lEsYjqhqk2+nu6+B\n1/Q56+RCXdayqBDBbkgVtd6+vnSNsG6dM7r5sy42uqNj5uCV1cYeCi+b55okgMLvVM8nXHCSpT9l\n6Y9ZF27pYvN94avPmrZTJxfqsvpchQh2A6qq9RLpBUf0nDp1zvAZmSxqigo03TlJUTGquGub52qy\nxF+nsWd1jmXBVXCarKb1ga/3TTT27JgK9kzOUyJ6AxHtJaLjRLTCh83fBN/ONl/onFzRz03OyYss\njicTR2DUqaZzVuraOTAALFgw8/OinitzOdcF9E5OlaPZx+9scXEsq1i9Ovh9FJv6FtXeRmAi/XUH\ngOcDeB6AmwGsMP1dVo09T603y5S6yjZ21+vaaOxxzd1X+KDpczXJfWKyg1IZsyiV/8JkWf/IiFvG\nyqKxybmSlo+9aiZYE2ppiilasOc1JfMhdKsaFeN6z0xs7DqBGG2niZDK+lxNBh+dqayIKX7ac0+7\nx3mnhM0Tm2dbh/bYUrRgp+DcbBDRzQDexcy7Es4ZAjAEAL29veds374dExMT6Onpsb7e+DiwYwcw\nOTn12Zw5wKpVwOLF1sWdYPNm4NChmZ93dQGDg2ZluLYpbzZu1H83PKz/Ltqe8XHg5puBI0eSrxW/\nX6bPK+288fEgZvvQoeAaK1dO//03vwmMjSXXbcmSCezdO/V8uroCs9Rdd/nvT1FM7oGu/0VR9UWT\nPpd27+xPtMOm//l4h3JqhvP1f+d3JnDGGdnlQn9//25mTjd7p0l+ADsA3Kk4fj9yzs0oUGNnzkfr\n9WHiyToy56XNZ9XYVXVUabtZ87Dr2m8ym7LV2OPhhHnOokzugYkpSdUX0/qc8Uw0RzthkRp72cEV\nquvr0j7YgiabYvLCh4kn62CVV4fMamOPl2VjYjHd+CEJX4JRFUFShEnMRGkwGZhU6QDS+pxxv/aZ\ngyCGTf/LKhfyNNWa9BfV9XWJ2mwRwe6AD8GapU15h3O5aKVZ9tMMSRNYJvc4i2CM7u4TFexFhjia\nLkJK82PMnWu2UjP6rHVlzdD+NScfB/gd3SOZB0DT/qfqcz4UiSzOcJt+r7q+KrWyC4UIdgAXAzgA\n4NcAfgngaya/q6pgZ84+Jc/SJtfUsTad3hbX/TTjdTTZ+CEJV8FIxHzhhVOfh4Ld1WHq2j90giG+\nMCr6d1tb8v0Kr20y+Bq1NWEEvhd9hQyA8fa4OJTzUJBsymyMxm57VFmwZ6VIjT2t08dXhLoQb4+r\nNhS1y7v+3kRj0mXiCwXm4OBY6kImm6gVGyEXHxTS9opNMy2F55oOvvFjRqjhyIj25GMgb0IyjWh7\nTBfGxZvh26Rp0+8bY2O3PUSwq7HtkK42WRt8aOw2v0/SiFXfxT9L235v27Yx47BNU+esSrC42mKj\n5ZkKNdPB1+iZaW5gVGPXCTRfRNvj6lD27Qx3Ubqi17fd7k+HCPaSKDIqxvQFzoIPG7vp723Ldomt\nHx42X6AUf3FNtLasttjodVUaverarhq7UjgrGvAY5vGlGDESaD6w1djDvW/zdIBn7fe1XKBke4hg\n94PpC5yFNMecy8uk+72tVmTa/mgZNitP48LPpH5ZbbFxwfFPF47w/e19fAzE96JPKWC92dgVD+jR\n7j6+vGNkRr2qYmNX3bM8hbtrvxfBnjN5xysX2SaTTu/bFJMntvZ70xlL9GXXaezRyBmd8DPR2rLa\nYqPHpRjhx6HXnnU29rDsqFPdZRNxVVl5h4Uym0fFmDyzqiCCPUeKWLhQRpt0mp8qNM6WKsxAbDX2\npA2zVTb20Llqkjo4Tci52mJVv7kX6i/uRV9iVEzSdeqQY8W0z9UpU6oI9hzJO06cuVzzUh4vb9kz\nEFsbe9pAPTY2pr1PIyPZUwe7Kg+qvnkMasl1DNMll+0zqrqQN21PEe+zL0Sw50gRI3yd/QaqF76s\nGYip0LE939sqTY91Cn8THxCSNHabNqVdx2TgKXIwMG1PETNwX4hgz5Gma+xZ0L0kvsK0dNcsWnNM\nez5lTu/j9+Ot80f4MYWN/R3d02+UTZ9zeQeKFqC2A1WVZx8htdpoo25UKVF/fNOLdeuK3309im7z\nkp0787ne6GiwKcf+/YGoiG7SUSZlboQyMADs2wccPx78e8E/DODtHZuwD304DsI+9OHtHZtw/tWW\nO1xE0G2YkrSRSlU3tgFm3jPbzT+ayqwS7Fl2gsmy+5CqrLhQ+9SnyhVyuhc7LY2sKy7Cwucz0LF6\ntd3neTIwAKzaMoCX9u3DHDqOl/btw6otA5mEl8vA5TIYCCVjotb7PuoWx24zFTVpk2n8dZFOIF2d\nhofzeUa2Jg9ftuE001KdHHIhedvYi74ndZELNogppoL4noqaajpFakQ6M9XKlflcz1ZzdNXw4zOj\nHTuSNf26aKfR2cvmzeazF5dZq60Js4iZlZCCifT3fdRNY7fRLuuqsTMXGxWjW5wTjxsPcXFqqu5z\nWpa9qmvsqpDMwcGx3KNBTJ2UPhytdZELNojGXkF8O9RUGlCcMpy6RTqiQs2xu3v65wcPqv0Lts9g\ndDTQ0FUkad9VcbCrtN5wBnLw4Mzz83ZmmvaNKjta02jUTMNE+vs+6qax+7axh2VGNaB4Xu6qhG3l\nkSsmSl9fsHT+XkzPh6LKmGj6DJKW6pvkxS47hE7XVl3mymiO+bIxnVkl3eOyUo3kGdIpcewVxfRl\nr1ObTDBNMDV/vpsg/COoY7X/CDMLMX0GSaauLHmxixL4NsnNooLd1FyUZztMTFlpQrSMdyhvE5wI\n9prTtDa5pIS10XTub1cXeH97n3Odk5KDbdzo9nyKXKRjmtzMxcaedztMyk8TomW8Q3kvTBMb+yyh\nrvY8k+gQG5vqs4+pC9R9bkKS72PfPrcyi7Qd6+rf3a32zXR2mq/HyLsdJlE3VYw8KnNhWh6IYC+B\nqq66NMG0o5u+pNSnLlD3uQlJjs5Dh9wG1SKFkc6Be/XVM4XmyAiwdq25o7uIdqQ5WqsoRKviNPeF\nCPYSKDtyIMtsYcOGQKikkfaShnUY2L8Bh8nvGzUwMDPaJqSz021QLVIYZVkhnUYVhGreQlTXv5P6\nfZ73vBRM7DW+j9luYy870ZSNjVXVHtWG0TY223gdLsUI76c+Po7s3rxofnPVptbr1uk32khyJlYh\nk6CPRG1VaEdYjzyiYnTtS9s4PG/EeVpHIr10bHg4tbeUuQjG9tq6Z6Tb1cZELufVftVLHQr3sF4m\nW+MlhVGWGQbpK+1D2e1II4tc0N2jsndbqpVgB/ARAOMAxgDcAOAUk981SrDHpMnY4GCqKlCm1mQ7\nW8jjGeU1YzEZMEw3s67KStMouvs2OOj/GRUp/G3z+SRhG1FUVOx/3aJibgKwlJn7AdwD4N0Zy6sf\nDgbzMu15VbCx5lUHE8fgypXpq36TyioT3f3p6vJ7nSKd+y75fJLQ3aP2drvz604mwc7MX2fmydaf\ntwJYmL1KNcMxzKCsPNJV8P7nVQeTAWPx4umDqu6Fb2srNkrJxKFdVKK2Ip37qmtNTrpfS3ePhobK\n7/dFQoF276Egon8DcB0zj2i+HwIwBAC9vb3nbN++HRMTE+jp6fFy/dLYvHla0vKJJUvQs3dvoEYN\nDpZYMT3j48EGGocOBdVcuTIQeCryekY2dbApc8eOQDCEzJkDrFo1VXa8Parf6H6bFyb1jp4bv289\nPcnPyPZeb9yo/2542LBRhqiutWTJBPbu7XG+lq69efQ5U3y9R/39/buZeUXqiWm2GgA7ANypOH4/\ncs56BDZ2MrH/zHYbe52o2zNKsw3rct/4cq652KazOpOTnlGe+dejEUjh/bO1x7tk4KwjtXKeBtfB\nGgC3AJhn+ptGCXZm66gYz5fM1bnVmGfUQtceHw5dV6d41msnPaO89jhNSrRmo9eoysmSz6eq1Eqw\nA7gIwF0Anm7zu8YJ9ghFtKnIqJqi2lNUBIauPT5CMF3LyFNjdx000p5JWs4gm/vmMyqmqtQtKubj\nAE4GcBMR3UFE12QsTzCg7JWrppg4BKuSXkHldCOy2+vUdbl+ng5t1wikNOd+Wptsoori1yrK7t1k\nskbF/CYzP4eZl7eOtb4qJuipYhKlOKYCuyqD1MAAsGbN9HQJzMC115oPMlmEaF7hr0VHIJl+L+SL\n5IqpIVWIRU/DVGBXaZC68cZAmEexGWSyCNFQa926Nfj7ssv8ZP3Ma9BI2gWsyWGEdUEEew0pMhZ9\nfNwtYZipwK7SIJV1kMkqRPMyS+WxZiLaVmBqPUDtk2c1BBHsNcRGgIR2bqIgNprIXECPjgbx1S6C\nRieY3/606Yb3kdWjlVk44mOQySJEq2KWMiVsK3MQg89c7GI7QY8I9ppiIkCiGiAAHDsW/GsqoNev\nn7lwx1TQqGYVl3eM4mOPTldJX3ztEL62ZrQS6VLLXpVbJbOUUG9EsDcYlQYYYiKgswga1azi/3at\nx5yjM1XSF9+43qupwDXffNk5uatklhLqjQj2BpM1JE0nUNrazIRmfFax4KH8VdKsduqycvgA5c8Y\nhOYggr3BZA1J27AhsMvHOXbM0blXgEpapp066z62Zc8YhOYggr3BZA1JGxgIElElZUK0EpoFqKRl\n2al9RbSUOWMQmoMI9gbjIyRt8eIpQXP8uPocY6FZgErqa1Jgo32PjgaLm+oU0SI0GxHsDcdnSJoX\noZmzSupjUmCjfYfnhhFHccqOaMlqHiqKaD03b65uPeuCCHZBSfiibdw4JRDq4NzzMSmwsdMnRR4B\n5Ua0jI4GWwJEB6jBweoJzfhAeuhQOfmCmoQIdmEG8fj3UGMF6uHcyzopsLHTJ2nkWQY9H5r2lVcC\nR49O/+zo0eDzKlG3hVl1QAR7g/A17U560WaDc8/G5JS0x6broOfLEXvwoN3nvrDth7Iwyz8i2BuC\nzzwjs/1FszE56c699lr3Qa/OGqxLP5SFWf4Rwd4QfAqD2f6i2djp8wj08TWwdnfbfe4Dl35YB99N\n3RDB3hB8atnyotmZnHybp3wNrFdfDXR0TP+soyP4PC9c+mF8cOzqqqbvpk6IYG8IPrXsePx7VZ2k\nTcXXwDowAGzZMn0dw5NPBtpzXhEnPnZsGhyUvpYVEewNwbeWHb5ow8PNdZKWgYlj0ad5Z2Bgqm/Y\nZvd0QWZ71UAEe0OQPCN6qrL4ReVYvOwydY58n+adIp2x0g+rgQj2BlHVUMQyVz9WafGLSsCGW/Hl\nqUUXHeVU1X44mxDBLuRKXtu9mWKirfoYeEzKSBOkeWnRsz3KaTYigl3IlbJjstO0VR8Dj2kZJoI0\nDy1a7N6zj0yCnYg+SERjRHQHEX2diHp9VUxoBmUvdkrTVn0MPKZlJKVRTqtvFsTuPfvIqrF/hJn7\nmXk5gK8AeK+HOgkNomwzQJq26mPgMS0jHkZKpK+Xb8TuPbvIJNiZ+VDkz/kAOFt1hKZRthkgbfGL\nj4HHpoxoGuWtW0WLFvIhs42diDYQ0f0ABiAauxCjCmaApMUvPgYe1zJMtOi65FMXqgUxJyvZRLQD\nwDMVX61n5n+NnPduAJ3M/D5NOUMAhgCgt7f3nO3bt2NiYgI9PT3Ola8iTWvTbGjP+Diwc2cQCtnV\nBaxcGewcZYOPMlRl7tgRbJASMmdOsF1htOzZ8Izqjq829ff372bmFWnnpQp2U4ioD8C/M/PStHNX\nrFjBu3btwp49e7Bs2TIv168KTWuTtKc8Fi2ayokfpa8v0PBD6tQmE5rWHsBfm4jISLBnjYo5I/Ln\nawCMZylPEIQpyo4oEurLnIy//1sieh6A4wD2A1ibvUqCIACB81WlscvCIiGNrFExr2Pmpa2Qx1cz\n8898VUyYvbg4DJvoZCw7okioL1k1dkHwSriKM1zwE91vVRdJ4/KbOhDWff36wPxy2mmBUK9zm4Ri\nkJQCQqVwWQladtqCPJGFRYILItiFSuHiMBQnoyBMRwS7UClcVoKWnbZAEKqGCHahUrg4DMXJKAjT\nEcEuVAqXFARVSFsgCFVComKEyjEwYC+UXX4jCE1FNHZBEISGIYJdEAShYYhgFwRBaBgi2AVBEBqG\nCHZBEISGIYJdEAShYXjbaMPqokS/QpDmtwfAROEVyJemtUnaU32a1qamtQfw16Y+Zn562kmlCPYT\nFyfaZbIbSJ1oWpukPdWnaW1qWnuA4tskphhBEISGIYJdEAShYZQt2DeVfP08aFqbpD3Vp2ltalp7\ngILbVKqNXRAEQfBP2Rq7IAiC4BkR7IIgCA2jMoKdiN5FRExEPWXXJStE9EEiGiOiO4jo60TUW3ad\nskBEHyGi8VabbiCiU8quUxaI6A1EtJeIjhNRbcPqiOgiIvoREf2EiP6y7PpkhYg2E9GDRHRn2XXx\nARE9h4j+g4jubvW3K4u6diUEOxE9B8DLADRll8qPMHM/My8H8BUA7y27Qhm5CcBSZu4HcA+Ad5dc\nn6zcCeC1AL5VdkVcIaJ2AJ8A8EoAZwK4lIjOLLdWmfkMgIvKroRHJgG8k5mfD+C3AfxpUc+oEoId\nwN8D+J8AGuHJZeZDkT/no+btYuavM/Nk689bASwssz5ZYea7mflHZdcjI+cB+Akz/yczHwXwBQC/\nX3KdMsHM3wLwUNn18AUz/5yZf9D6/6MA7gbw7CKuXfoOSkT0GgA/Y+YfElHZ1fEGEW0A8McA/gvA\nfy+5Oj4ZBHBd2ZUQ8GwA90f+PgDg/JLqIqRARIsAnAXgtiKuV4hgJ6IdAJ6p+Go9gL8C8PIi6uGT\npDYx878y83oA64no3QDeDuB9hVbQkrT2tM5Zj2B6OVpk3VwwaU/NUWlBtZ4ZNhUiWgDgXwAMx2bz\nuVGIYGfmVarPiWgZgNMBhNr6QgA/IKLzmPkXRdTNFV2bFHwOwL+j4oI9rT1EtAbAqwBcyDVY/GDx\nfOrKAQDPify9EMADJdVF0EBEHQiE+igzf7Go65ZqimHmPQB+I/ybiPYBWMHMtc7sRkRnMPOPW3++\nBsB4mfXJChFdBOAvAFzAzIfLro8AAPg+gDOI6HQAPwPwRgB/VG6VhCgUaKv/BOBuZv5YkdeuivO0\nafwtEd1JRGMIzEyFhTnlxMcBnAzgplYI5zVlVygLRHQxER0A8EIA/05EXyu7Tra0nNlvB/A1BE65\nbcy8t9xaZYOIPg/gFgDPI6IDRPTmsuuUkRcBuAzA77bemzuIaHURF5aUAoIgCA1DNHZBEISGIYJd\nEAShYYhgFwRBaBgi2AVBEBqGCHZBEISGIYJdEAShYYhgFwRBaBj/Hx757UQYCvHHAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a70e90850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tsne = TSNE(perplexity=50)\n",
    "start = 50\n",
    "X = tsne.fit_transform(model.graph_embeddings[start:])\n",
    "\n",
    "plt.scatter(X[np.where(labels[start:] == 0)[0], 0], X[np.where(labels[start:] == 0)[0], 1], label='normal', c='b')\n",
    "plt.scatter(X[np.where(labels[start:] == 1)[0], 0], X[np.where(labels[start:] == 1)[0], 1], label='outlier', c='r')\n",
    "plt.title(\"TSNE on embeddings\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.7)\n",
    "#plt.scatter(norms[np.where(labels == 1)[0]], label='outlier', c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-220-64973097d897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mprev_cnt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a227e3c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "\n",
    "prev_cnt = 40\n",
    "for i, label in zip(range(prev_cnt, len(labels[prev_cnt:])), labels[prev_cnt:]):\n",
    "    vector_weight = 1 / np.exp(range(0, prev_cnt))\n",
    "    if label == 0:\n",
    "        ax.scatter(i, np.linalg.norm(model.graph_embeddings[i] - sum(model.graph_embeddings[i-prev_cnt:i].T.dot(vector_weight))), c='b')\n",
    "    else:\n",
    "        ax.scatter(i, np.linalg.norm(model.graph_embeddings[i] - sum(model.graph_embeddings[i-prev_cnt:i].T.dot(vector_weight))), c='r')\n",
    "    fig.canvas.draw()   \n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/matplotlib/figure.py:403: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-0a5e90e497d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfunc_tools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterative_drawing_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Macbook/Desktop/IITP/GraphAnomaly/awe/func_tools.py\u001b[0m in \u001b[0;36miterative_drawing_2d\u001b[0;34m(model, labels)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/matplotlib/backends/backend_agg.pyc\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mRendererAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/matplotlib/artist.pyc\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mbefore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mafter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/matplotlib/figure.pyc\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1144\u001b[0;31m                 renderer, self, dsu, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/matplotlib/image.pyc\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, dsu, suppress_composite)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzorder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdsu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/matplotlib/artist.pyc\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mbefore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mafter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2424\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2426\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdsu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2428\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/matplotlib/image.pyc\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, dsu, suppress_composite)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzorder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdsu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/matplotlib/artist.pyc\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mbefore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mafter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/matplotlib/collections.pyc\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m         \u001b[0mCollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/matplotlib/artist.pyc\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mbefore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mafter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/matplotlib/collections.pyc\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    344\u001b[0m             renderer.draw_markers(\n\u001b[1;32m    345\u001b[0m                 \u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrozen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                 mpath.Path(offsets), transOffset, tuple(facecolors[0]))\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             renderer.draw_path_collection(\n",
      "\u001b[0;32m/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/matplotlib/backends/backend_agg.pyc\u001b[0m in \u001b[0;36mdraw_markers\u001b[0;34m(self, *kl, **kw)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;31m# maybe there is better way to do it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_markers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mkl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_markers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_path_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mkl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/matplotlib/backend_bases.pyc\u001b[0m in \u001b[0;36mget_hatch_linewidth\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hatch_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhatch_color\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mget_hatch_linewidth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \"\"\"\n\u001b[1;32m   1124\u001b[0m         \u001b[0mGets\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlinewidth\u001b[0m \u001b[0mto\u001b[0m \u001b[0muse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhatching\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAF/9JREFUeJzt3X+IZWd9x/HPd2Z3WidrEGaXWkx2xlIpBpFaB1Fa2mIC\nTYNUlAYsgwgWBjcWIljQMH+0/WP/EoRQS8JQtcUZbAUVpSIxgiKFap2UKElXxZbdbVDqJqVoXOmS\n3W//OHPZu3fvPff8eM55nvOc9wsOuzNz554fd87nPvf7POc55u4CAORjJfYGAADCItgBIDMEOwBk\nhmAHgMwQ7ACQGYIdADJDsANAZgh2AMgMwQ4AmTkRY6WnT5/2ra2tGKsGgMF66qmnnnf3M8seFyXY\nt7a2dHR0FGPVADBYZnapyuMoxQBAZloHu5n9spn9q5l9x8yeNbO/CrFhAIBmQpRi/k/SW939RTM7\nKemfzezL7v7NAM8NAKipdbB7Me/vi8dfnjxemAsYACIJUmM3s1Uze1rSTyQ96e7fCvG8AID6ggS7\nu19399+UdJekN5nZ62YfY2a7ZnZkZkdXrlwJsVoAwBxBR8W4+/9K+rqk++f8bN/dt919+8yZpcMw\nAQANhRgVc8bMXnH8/5dJuk/S99o+L5C6w0Npa0taWSn+PTyMvUVAIcSomF+V9PdmtqrijeIz7v5P\nAZ4XSNbhobS7K129Wnx96VLxtSTt7MTbLkCSLMbNrLe3t50rTzFkW1tFmM/a3JQuXux7azAWZvaU\nu28vexxXngINXL5c7/tAnwh2oIGzZ+t9H+gTwQ40cP68tL5+6/fW14vvA7ER7EADOzvS/n5RUzcr\n/t3fp+MUaYgybS+Qg50dghxposUOAJkh2AEgMwQ7AGSGYAeAzBDsAJAZgh0AMkOwA0BmCHYAyAzB\nDgCZIdgBIDMEOwBkhmAHgMwQ7ACQGYIdADJDsANAZgh2AMgMwQ4AmSHYASAzBDsAZIZgB4DMEOwA\nkBmCHQAyQ7ADQGZaB7uZ3W1mXzOzC2b2rJk9HGLDAADNhGixvyTpg+7+WklvlvR+M7snwPMC6MDh\nobS1Ja2sFP8eHsbeIoR2ou0TuPuPJf34+P8/M7MLkl4l6d/bPjeAsA4Ppd1d6erV4utLl4qvJWln\nJ952IaygNXYz25L0BknfCvm8AMLY27sZ6hNXrxbfRz6CBbuZnZL0WUkfcPefzvn5rpkdmdnRlStX\nQq0WQA2XL9f7PoYpSLCb2UkVoX7o7p+b9xh333f3bXffPnPmTIjVAklLsZZ99my972OYQoyKMUkf\nl3TB3T/afpO6k+KJhjxNatmXLknuN2vZsf/mzp+X1tdv/d76evH9ujifEuburRZJvyPJJX1X0tPH\nywNlv/PGN77R+3Zw4L6+7l6cZsWyvl58Hwhtc/PWv7XJsrkZe8uKv/nNTXez4t8m5wDnUxySjrxC\nLlvx2H5tb2/70dFRr+vc2ipaTbM2N6WLF3vdFIzAykoRd7PMpBs3+t+e0Dif4jCzp9x9e9njRnPl\nKZ1G6MvhYRHs8+RSy+Z8Sttogp1OI/RhUlu/fv32nzWtZaeI8yltown2kJ1GwCLzxolL0uqqtL+f\nz0VAnE9pG02w7+wUJ9bmZlHn3NzM60RDGhaVIm7cyOtvjfMpbaMJdqn4o7t4sTjJLl7kj3CIUh9i\n11WJIsX95nxK16iCHcOW6tjwaV2UKGLud4pvKKigypjI0EuMcewYvpTHhk8LMU58Wqz9bjNWPfQx\nQEGMY0duch8bvkis/W46Vn12Bkmp+NRCDb49xrEjO6kMsZuUJ8ykEyeKf7sqU8QcE990rDozSMZH\nsNdAvTGuFIbYTde7pZvj1buoe8ceE9/0jZSLlxJQpV4TehlijZ25MdIQu3a7qN7dRd170bpWV/vZ\n76Z/80PpCxkiUWMPi7kxIC2ud0+ErHun0KdweFiUUC5fLlrq588vr5NTY+8ONfbA+HgJaXkZImTd\nO4U+hSZj1bl4KT6CvaIUTjLEN6/OPxG67p1Cn0JTMS9eoi+MYK9syCcZwplujUrFHDBSN61SWr71\nDeEitj5QY6+hSb0RQH9y7wurWmMn2AFkI4UO5y7ReQpgdOgLKxDsALJBX1iBYAeQDTqcCwT7SI15\nSNiY930MmCeeYB+lnIeELQvtnPcd9eX6Js+omBHKdUhYlUvZc9131DfEqQ8Y7oiFch0SViW0c913\n1DfEN3mGO2KhXIeEVZnPJ9d9j2HoZYyc538i2EeoryFh0yf+6dPF0mUIVAlthsOFkUNfRdZv8lXm\n9g29DHE+9tx0Pa/5vLm8u57Lvur84bHndM9BDnOuD/EeC6o4HzvBjk6CbtkNKZaFQNNtIrT7YTb/\nNTVr/9x9voZD+3vpNdglfULSTyQ9U+XxBHs6umq1LDrxq4TA0FpSQwuHELpqsQ/tte9b38H+u5J+\ni2Afnq5O0DYt9lQ/5s8L8KEGUds3o672O9XXPhW9l2IkbRHsw9PVR+o2NfYuP+Y3tSjINjaGF0Sh\nQrmLTyopvvYpqRrsjIoZua5GBszO2bGxIZ06dfPnL3tZ/9vUxt7erReySMXXL7ww//EpD5lbtC97\ne/Wep4tL91N87Yeot2A3s10zOzKzoytXrvS1WizR5fC/6RP/0UdvvQDohRcWD49ru01djK+uG9Qp\nB1HK47cZjhpIlWZ9lUWUYgarj86/spr7vHW2GRXTZ+13Y2N4Nfa6r0XfxtgZXZWosSMly0bJhArD\nGKM1hhZEMa4xQBhVgz3IXDFm9mlJvy/ptKT/lvQX7v7xRY9nrpjxWTQvx7QQc3R0ORdMTve8nezL\notck5flSxoxJwJCUeTPpzQoRvkOc2CkmJkUbFiYBQ1KmR8ksUrfDcV4n6ZA631KYRItRKHki2NGb\nySiZg4P24btoEippGLdGS2USrSG9EaKGKoX40Audp2jb4dhFJ2mfnaChtj/ENg+t83fMxCRgyFno\nKxT7nhogxPZX2WZCOy9Vg51SDJK0rP5cVhtuUrsOdTVm1XWHqG0v2+ZUyj2IoEr6h15osaNM1Zbo\nvMecO9es5d1XC7rJY5tuMxNq5UeUYjBUVQNpXpmhaZiFCMFlzzG7vefOddvPwIRa+SHYMVhtAqnp\n75Z9AqgavmXrrtuar7LOZc9Jiz0/BDsGq2xelmWB1ybM5rWo65RLytZd51NInXWWvQkMda54LEaw\nY7DmBdLJk+5ra8tDatE8KGtr7isrxf9XV4vQXqbum0RZkFb9JBG6lX1wcOuc8RsbBPuQVQ12RsWg\nsrIRHyGvopydy31zU7rzTunatVsfd/Wq9PDDt65XKn53Y+PWx167dvMS+evXpccekx56qHw/F82j\nsmh623nbPbk4quoomC6m1P3FL27+v2y65L6lcOVttqqkf+iFFvvwLJvdsOuP/FXuoTq93iq35ltd\nrbafIVrPVY9R6BZ7nefr+ybSlInqE6UYhBSiftzF+hett+obQd31tAmfKsEZOvCqloD6Dlo6dpsh\n2BFUWUB0cRVolZtGL1omv9ekxV72hjC9LV20bKc/aayu3rrOpqoGaN9BW/baYTGCHUGFbLE3Hckx\n+3tlN5Ku8kYwrwO1ylj0eR27Gxvt52vposVc9Xn7HPNe1plMi70cwY6gQtXYm469Xl2tNgJmbe1m\nyG5s3Pz/HXfcHBWzslJ83WSIYJVPAmtraUxqNr1PXQ4TrWvRuibj/bEYwY7glrW0q5Qnml4tOQnY\n2QuGpr/e2Chaz2Wt6Spj0xfty8HB8lCfLBsb9Y5t7KtE+6yxl73GKEewI0lN5zeZflyb1vSiZdko\nkXlvGsuWOrX4FDoT+xoVk8K+DhXBjiSVXVXqXq+TtE5rf9lSZZRI3aXKBVVl68t1+N+Y9jW0rIOd\nOaaH6+Dg9sCTitbwdMljMiqkTigv6kxt0mJv0/qv+8lg+tjk/nfdxcifMck22Hm3H76y0SwT817n\nspEUi94wqi6zI2S6CPXpN6Ex4txtL9tgpz43fHUumqk6KVfbFvZ0wNx7b3fBvroabtreoeHcbS/b\nYI89egDtlZ3gy8oRsx2akxEvXQVxn4tZtcnJhopzt72qwT64ScBC3FIM3akysdP589L6+q3fW1+X\nHnhg+a3cdnakixelT32qmNzqhReKx+bAXXr88Xwnw+Lc7VGV9A+9UGPPU9ubSdT5qN6mozT1JdfS\nBOdue8q1FOM+jtEDQ9S2hlqn9h47fLtcUi9NtDn/zp27ORqm6rz4uCnrYEea2tZQ205YlcvSZI6d\nvrRpddNib49gR+/attjbTliVw7JovpRUQrHNa8yomPaqBnuQzlMzu9/Mvm9mPzSzD4d4TgzPok7R\n8+er/X7ZHYim5dzZ5l7s72wn9MMPF3eMmnb1qrS31+/2tbnDUxd3h8ICVdK/bJG0Kuk/JP2apDVJ\n35F0T9nv0GIfthCTgbVdf9WLl4a2VJ1yeHq/+0SLPS71VYqR9BZJT0x9/YikR8p+h2Afrr5KAnXG\ns+dSc29ysVXfoUiNPa4+g/2PJf3t1NfvlvSxst8h2Ierj1ZXkwAY+vDH6fnm697ftW9tPpWl0AEc\nQ6j97jPYH5wT7H8953G7ko4kHZ09e7bZXiG6Pq4ebHJHpjbzxKSwTB+/shb75PiPKRSHLuQnlarB\nHqLz9DlJd099fZekH82p5e+7+7a7b585cybAahFDH1cPLutke+gh6cSJooP1xAnpfe+Trl0Lt/4Y\npo/fvE7oCfeiU/nixds7lZGmvb3+O75DBPu3Jb3GzF5tZmuS3iXpiwGeFx2ocsl/mbYjX6ooe/N4\n6CHpscek69eL712/Lr34Yrh1xzJ9/CajgxapOoqk7WuNMKKMBqrSrF+2SHpA0g9UjI7ZW/Z4auxx\nhPpI2HWdtGw768zTPqRl3vFs05/RZUflWOvkTYXslxIXKGHWEIabLbsRQ+wA7mNpcpPwWV291oxs\nqS9GjZ1gH5G2HZ9dtdTKhvjNngCLWuyTaXxjh3KoZRLATY95V53cQ2gcpGhwo2KaLAR7HCl+tK9y\nMc50yJ06Nf8x584VSy4XKqUawMypHhfBjtuk+NG+ysU4kxtQlIX2HXfED+O6y9ra4k8Z03daavLm\n2dUbMS32uAj2EanzMS+1j/ZVWtgrK/FDOPSyslK8WVX5xNI0kLsonVFjj4tgb2hoPf59nWgxW+x9\nLKdO9b8t052kk7+5RX0IbVvwIQ3tHMkJwd7AEFsjfX00jllj7ytg3fsP99nXqconmNT/JtEdgr2B\nIdYP++zM6mNUTIxx6rOzU9Z5o2nbWTv7OlV9Y0n5bxLdqRrsVjy2X9vb2350dNT7epdZWSlOm1lm\n0o0b/W9PFVtbxU2fZ00uOx+iRfvU1MmT0p13Fje+njXvOB0eFvOfz3v87POurUk//3nzbZus//Cw\nuMT80qXi723ZaZny3yS6Y2ZPufv2sscFudFGLoZ4F/U+LvHv27x9WluTNjaaPd+dd0qPPlr9OO3s\nSM8/Lx0cFMErSaurt/67uSl98pO3zwFSx2T9h4fS7u7NNzP3Irin1zcr5b9JJKBKsz70kmopZog1\ndvc8O7MW7VOTGvik3NHFcWpak686dcBQ/ybRDY25xs580flq0tnaZT163vacPHlzfPpsDb7OPVy7\nfEPCMI022Gnh3C63YJjen42NxSHa9rWvetza3ipwiJ32iGO0wR7rJEk1PHN5owsRsnXX19dxy+U1\nQvdGG+wx5rJI+cTMoTUY4/j2fdxSbRggLVWDPbvhjjGG/6U85DDlIZyTIX6XLxejPM6fn39XoBjH\nN+XjhvEa7XDHGMP/otwhpaJUh3BOD/FzL/7d3Z1/l58YxzfEceviDkbcFQmVVGnWh15SHhXTRKrl\njoOD+bMH9lUmKnsd6hyzGMe3bfln3myUbY97yiU/9ENjrbHHkOIJt2hY4MZGf6Fedkzq9IXEOr5N\nGwgHB4v3r82bUaoNCPSHYO9Zap1fsUNg2frrbl9qx7dM2UVLbTrxuckFqgZ7dp2nKMTu/Fu2/kmN\nffqS/PV1aX9/fgfqkCzad6ldh2/KnfTox2g7T1GI3Wm6bP07O0WIb24WYb+5mUeoS4v33axdJ36V\ngQF0rkISpZhcxa77x15/FXXLO3Uukprd98nt/brc5iEcc7QjauyIXZeOvf4ydUOwyeP73vfY/Sro\nXtVgp8aOUapbrx5CfTt2vwq6R40dKFH3oqeUL0KbiN2vgnQQ7BiluiE4hNDM8aYraIZgxyjVDcEh\nhGbOI41QD8GOUaobgn2HZtNhizs7Rc3/xo3iX0J9nFp1nprZg5L+UtJrJb3J3Sv1iNJ5CiyW88Vb\naKevztNnJL1T0jdaPg+AY3t7t98k++rV4vtAFSfa/LK7X5Akm9xSHUBrQxiBg7RRYwcSM4QROEjb\n0mA3s6+a2TNzlrfXWZGZ7ZrZkZkdXblypfkWA5mLNQKHeWbysbQU4+73hViRu+9L2peKztMQzwnk\naNJBWuW2gaHMdthO7mg1vT0YjiBTCpjZ1yX9OaNigGEawpQJ6GlUjJm9w8yek/QWSV8ysyfaPB+A\nOOiwzUurYHf3z7v7Xe7+S+7+K+7+B6E2DEB/6LDNC6Ni0IscOuZy2IdFhjBlAqprNY4dqCKHjrkc\n9qFMjA5bdIf52NG5HDrmctgHDB/zsSMZTTrmUit70LmIISHY0bm6HXOTsselS8UdgSZlj5jhTuci\nhoRgR+fqdsylOAkWnYsYEoIdnas7l3mKZQ9uYoEhIdjRizo3gEi17NH1TSxS61fAcBHsSM4Yyx4p\n9itguAh2JGeMZY8U+xUwXIxjBxKwslK01GeZFaUfQGIcOzAoqfYrYJgIdiABY+xXQHcIdiABY+xX\nQHeYBAxIxM4OQY4waLEDQGYIdgDIDMEOAJkh2AEgMwQ7AGSGYAeAzBDsAJAZgh0AMkOwA0BmCHYM\nDjekAMoxpQAGZXJDisnc5ZMbUkhcjg9M0GLHoHBDCmA5gh2DkuKNroHUtAp2M/uImX3PzL5rZp83\ns1eE2jBgHm5IASzXtsX+pKTXufvrJf1A0iPtNwlYjBtSAMu1CnZ3/4q7v3T85Tcl3dV+k4DFuCEF\nsFzIUTHvlfSPAZ8PmIsbUgDllga7mX1V0ivn/GjP3b9w/Jg9SS9JWjii2Mx2Je1K0lkKogDQmaXB\n7u73lf3czN4j6W2S7nV3L3mefUn7krS9vb3wcQCAdlqVYszsfkkfkvR77n512eMBAN1rOyrmY5Je\nLulJM3vazB4PsE0AgBZatdjd/ddDbQgAIAyuPAWAzBDsAJAZgh0AMkOwA0BmCHYAyAzBDgCZIdgB\nDAa3RayGW+MBGARui1gdLXYAg8BtEasj2AEMArdFrI5gBzAI3BaxOoIdwCBwW8TqCHYAg8BtEatj\nVAyAweC2iNXQYgeAzBDsAJAZgh0AMkOwA0BmCHYAyAzBDgCZIdgBIDPm7v2v1OyKpEs9r/a0pOd7\nXueQcHyW4xiV4/iUC3F8Nt39zLIHRQn2GMzsyN23Y29Hqjg+y3GMynF8yvV5fCjFAEBmCHYAyMyY\ngn0/9gYkjuOzHMeoHMenXG/HZzQ1dgAYizG12AFgFEYV7Gb2ETP7npl918w+b2aviL1NKTGzB83s\nWTO7YWaMbjhmZveb2ffN7Idm9uHY25MaM/uEmf3EzJ6JvS0pMrO7zexrZnbh+Px6uOt1jirYJT0p\n6XXu/npJP5D0SOTtSc0zkt4p6RuxNyQVZrYq6W8k/aGkeyT9iZndE3erkvN3ku6PvREJe0nSB939\ntZLeLOn9Xf8NjSrY3f0r7v7S8ZfflHRXzO1JjbtfcPfvx96OxLxJ0g/d/T/d/Zqkf5D09sjblBR3\n/4ak/4m9Haly9x+7+78d//9nki5IelWX6xxVsM94r6Qvx94IJO9Vkv5r6uvn1PFJiXyZ2ZakN0j6\nVpfrye7WeGb2VUmvnPOjPXf/wvFj9lR8PDrsc9tSUOX44BY253sMJUNtZnZK0mclfcDdf9rlurIL\ndne/r+znZvYeSW+TdK+PcKznsuOD2zwn6e6pr++S9KNI24KBMrOTKkL90N0/1/X6RlWKMbP7JX1I\n0h+5+9XY24NB+Lak15jZq81sTdK7JH0x8jZhQMzMJH1c0gV3/2gf6xxVsEv6mKSXS3rSzJ42s8dj\nb1BKzOwdZvacpLdI+pKZPRF7m2I77mz/M0lPqOj0+oy7Pxt3q9JiZp+W9C+SfsPMnjOzP429TYn5\nbUnvlvTW49x52swe6HKFXHkKAJkZW4sdALJHsANAZgh2AMgMwQ4AmSHYASAzBDsAZIZgB4DMEOwA\nkJn/B6r81x7Jdn2/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1fe42790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "func_tools.iterative_drawing_2d(model, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1a495357d0>"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2e54bb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prev_cnt = 3\n",
    "prev_dataset = []\n",
    "for i, label in zip(range(prev_cnt+20, len(labels[prev_cnt:])), labels[prev_cnt:]):\n",
    "    vector_weight = sum(np.exp(range(0, prev_cnt))) / np.exp(range(0, prev_cnt))\n",
    "    prev_dataset.append(model.graph_embeddings[i] - sum(model.graph_embeddings[i-prev_cnt:i].T.dot(vector_weight)))\n",
    "\n",
    "fig = plt.figure()\n",
    "cls = OneClassSVM(kernel='rbf', gamma=5)\n",
    "cls.fit(model.graph_embeddings[np.where(labels[prev_cnt:] == 0)[0]][:])\n",
    "plt.scatter(np.where(labels[prev_cnt:]==0), \n",
    "            cls.decision_function(model.graph_embeddings)[np.where(labels[prev_cnt:]==0)], c='b', label='normal')\n",
    "plt.scatter(np.where(labels[prev_cnt:]==1), \n",
    "            cls.decision_function(model.graph_embeddings)[np.where(labels[prev_cnt:]==1)], c='r', label='outlier')\n",
    "plt.grid()\n",
    "plt.title(\"One class SVM forest outlier score\")\n",
    "plt.ylabel('score')\n",
    "plt.xlabel('days')\n",
    "#fig.savefig('oneclass_svm.pdf', format='pdf')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of labels=636 does not match number of samples=637",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-b0173da2815a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    325\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 327\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             raise ValueError(\"Number of labels=%d does not match \"\n\u001b[0;32m--> 236\u001b[0;31m                              \"number of samples=%d\" % (len(y), n_samples))\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_weight_fraction_leaf\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"min_weight_fraction_leaf must in [0, 0.5]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of labels=636 does not match number of samples=637"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cls = RandomForestClassifier(n_estimators = 100)\n",
    "cls.fit(model.graph_embeddings, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193.41898\n"
     ]
    }
   ],
   "source": [
    "with model.graph.as_default():\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    v = sess.run(model.word_embeddings)    \n",
    "    print(np.linalg.norm(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Macbook/anaconda/envs/py27/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import hdf5storage\n",
    "mat = hdf5storage.loadmat('enron/Date_weekend_cropped.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "emails = pd.read_csv('../enron/emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "r,t,y = emails.ix[100]['message'].split('\\n')[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['16', 'Aug', '2000']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.split()[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20000\n",
      "40000\n",
      "60000\n",
      "80000\n",
      "100000\n",
      "120000\n",
      "140000\n",
      "160000\n",
      "180000\n",
      "200000\n",
      "220000\n",
      "240000\n",
      "260000\n",
      "280000\n",
      "300000\n",
      "320000\n",
      "340000\n",
      "360000\n",
      "380000\n",
      "400000\n",
      "420000\n",
      "440000\n",
      "460000\n",
      "480000\n",
      "500000\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "for i in range(len(emails)):\n",
    "    \n",
    "    if i%20000 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    DATE, FROM, TO = emails.ix[i]['message'].split('\\n')[1:4]\n",
    "    \n",
    "    condition1 = DATE[:4] == 'Date' and FROM[:4] == 'From' and TO[:2] == 'To'\n",
    "    condition2 = DATE[4:] != '' and FROM[4:] != '' and TO[2:] != ''\n",
    "    \n",
    "    try:\n",
    "        dataset.append((' '.join(DATE.split()[2:5]), FROM.split()[1], TO.split()[1]))\n",
    "    except IndexError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'24 Jun 1999'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[3000][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(1999, 6, 24, 0, 0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.strptime(temp[3000][0], '%d %b %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp = sorted(dataset, key=lambda x: datetime.datetime.strptime(x[0], '%d %b %Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def check_time(x):\n",
    "    first = datetime.datetime.strptime(x[0], '%d %b %Y') > datetime.datetime(2000, 6, 24, 0, 0) \n",
    "    second = datetime.datetime.strptime(x[0], '%d %b %Y') < datetime.datetime(2002, 3, 24, 0, 0) \n",
    "    return first and second\n",
    "temp1 = [x for x in temp if check_time(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp1 = np.array(temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "time_steps = []\n",
    "for date in sorted(np.unique(temp1[:, 0]), key=lambda x: datetime.datetime.strptime(x, '%d %b %Y')):\n",
    "    date_array = []\n",
    "    for item in temp1:\n",
    "        if item[0] == date:\n",
    "            date_array.append(item)\n",
    "    time_steps.append(date_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sorted(np.unique(temp1[:, 0]), key=lambda x: datetime.datetime.strptime(x, '%d %b %Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sorting(x):\n",
    "    print x\n",
    "    return datetime.datetime.strptime(x[0], '%d %b %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i, step in enumerate(time_steps):\n",
    "    f = open('../enron/enron_{0}.txt'.format(i), 'w')\n",
    "    for line in step:\n",
    "        f.write(' '.join(line[1:])+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4deca2cce197>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../enron/time_steps.txt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%d %b %Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "f = open('../enron/time_steps.txt'.format(i), 'w')\n",
    "for i in sorted(np.unique(temp1[:, 0]), key=lambda x: datetime.datetime.strptime(x, '%d %b %Y')):\n",
    "    f.write(i + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "time_steps = []\n",
    "for graph in sorted(os.listdir('../enron/graphs/')[1:], key=lambda x: int(x.split('_')[1].split('.')[0])):\n",
    "    f = open('../enron/graphs/' + graph)\n",
    "    lines = f.readlines()\n",
    "    time_steps.append(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.has_edge(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': 2}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graphs = []\n",
    "for time_step in time_steps:\n",
    "    graph = nx.Graph()\n",
    "    for line in time_step:\n",
    "        FROM, TO = line.strip().split()\n",
    "        if graph.has_edge(FROM, TO):\n",
    "            graph[FROM][TO]['weight'] += 1\n",
    "        else:\n",
    "            graph.add_edge(FROM, TO, weight=1)\n",
    "            \n",
    "    graphs.append(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, graph in enumerate(graphs):\n",
    "    nx.write_graphml(graph, '../enron/parsed_graphs/enron_' + str(i) + '.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps = open('../enron/time_steps.txt')\n",
    "lines = steps.readlines()\n",
    "steps.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "steps = open('../enron/time_steps.txt', 'w')\n",
    "for i, line in enumerate(lines):\n",
    "    steps.write(line.strip() + '\\t' + str(i) + '\\n')\n",
    "steps.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = np.zeros(636)\n",
    "for i in [171, 480, 484, 512, 577, 584, 589]:\n",
    "    labels[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('../enron/parsed_graphs/labels.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for i in labels:\n",
    "    print i\n",
    "    f.write(str(int(i)) + ' ')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('../enron/time_steps.txt')\n",
    "lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['25 Jun 2000\\t0\\n',\n",
       " '26 Jun 2000\\t1\\n',\n",
       " '27 Jun 2000\\t2\\n',\n",
       " '28 Jun 2000\\t3\\n',\n",
       " '29 Jun 2000\\t4\\n',\n",
       " '30 Jun 2000\\t5\\n',\n",
       " '1 Jul 2000\\t6\\n',\n",
       " '2 Jul 2000\\t7\\n',\n",
       " '3 Jul 2000\\t8\\n',\n",
       " '4 Jul 2000\\t9\\n',\n",
       " '5 Jul 2000\\t10\\n',\n",
       " '6 Jul 2000\\t11\\n',\n",
       " '7 Jul 2000\\t12\\n',\n",
       " '8 Jul 2000\\t13\\n',\n",
       " '9 Jul 2000\\t14\\n',\n",
       " '10 Jul 2000\\t15\\n',\n",
       " '11 Jul 2000\\t16\\n',\n",
       " '12 Jul 2000\\t17\\n',\n",
       " '13 Jul 2000\\t18\\n',\n",
       " '14 Jul 2000\\t19\\n',\n",
       " '15 Jul 2000\\t20\\n',\n",
       " '16 Jul 2000\\t21\\n',\n",
       " '17 Jul 2000\\t22\\n',\n",
       " '18 Jul 2000\\t23\\n',\n",
       " '19 Jul 2000\\t24\\n',\n",
       " '20 Jul 2000\\t25\\n',\n",
       " '21 Jul 2000\\t26\\n',\n",
       " '22 Jul 2000\\t27\\n',\n",
       " '23 Jul 2000\\t28\\n',\n",
       " '24 Jul 2000\\t29\\n',\n",
       " '25 Jul 2000\\t30\\n',\n",
       " '26 Jul 2000\\t31\\n',\n",
       " '27 Jul 2000\\t32\\n',\n",
       " '28 Jul 2000\\t33\\n',\n",
       " '29 Jul 2000\\t34\\n',\n",
       " '30 Jul 2000\\t35\\n',\n",
       " '31 Jul 2000\\t36\\n',\n",
       " '1 Aug 2000\\t37\\n',\n",
       " '2 Aug 2000\\t38\\n',\n",
       " '3 Aug 2000\\t39\\n',\n",
       " '4 Aug 2000\\t40\\n',\n",
       " '5 Aug 2000\\t41\\n',\n",
       " '6 Aug 2000\\t42\\n',\n",
       " '7 Aug 2000\\t43\\n',\n",
       " '8 Aug 2000\\t44\\n',\n",
       " '9 Aug 2000\\t45\\n',\n",
       " '10 Aug 2000\\t46\\n',\n",
       " '11 Aug 2000\\t47\\n',\n",
       " '12 Aug 2000\\t48\\n',\n",
       " '13 Aug 2000\\t49\\n',\n",
       " '14 Aug 2000\\t50\\n',\n",
       " '15 Aug 2000\\t51\\n',\n",
       " '16 Aug 2000\\t52\\n',\n",
       " '17 Aug 2000\\t53\\n',\n",
       " '18 Aug 2000\\t54\\n',\n",
       " '19 Aug 2000\\t55\\n',\n",
       " '20 Aug 2000\\t56\\n',\n",
       " '21 Aug 2000\\t57\\n',\n",
       " '22 Aug 2000\\t58\\n',\n",
       " '23 Aug 2000\\t59\\n',\n",
       " '24 Aug 2000\\t60\\n',\n",
       " '25 Aug 2000\\t61\\n',\n",
       " '26 Aug 2000\\t62\\n',\n",
       " '27 Aug 2000\\t63\\n',\n",
       " '28 Aug 2000\\t64\\n',\n",
       " '29 Aug 2000\\t65\\n',\n",
       " '30 Aug 2000\\t66\\n',\n",
       " '31 Aug 2000\\t67\\n',\n",
       " '1 Sep 2000\\t68\\n',\n",
       " '2 Sep 2000\\t69\\n',\n",
       " '3 Sep 2000\\t70\\n',\n",
       " '4 Sep 2000\\t71\\n',\n",
       " '5 Sep 2000\\t72\\n',\n",
       " '6 Sep 2000\\t73\\n',\n",
       " '7 Sep 2000\\t74\\n',\n",
       " '8 Sep 2000\\t75\\n',\n",
       " '9 Sep 2000\\t76\\n',\n",
       " '10 Sep 2000\\t77\\n',\n",
       " '11 Sep 2000\\t78\\n',\n",
       " '12 Sep 2000\\t79\\n',\n",
       " '13 Sep 2000\\t80\\n',\n",
       " '14 Sep 2000\\t81\\n',\n",
       " '15 Sep 2000\\t82\\n',\n",
       " '16 Sep 2000\\t83\\n',\n",
       " '17 Sep 2000\\t84\\n',\n",
       " '18 Sep 2000\\t85\\n',\n",
       " '19 Sep 2000\\t86\\n',\n",
       " '20 Sep 2000\\t87\\n',\n",
       " '21 Sep 2000\\t88\\n',\n",
       " '22 Sep 2000\\t89\\n',\n",
       " '23 Sep 2000\\t90\\n',\n",
       " '24 Sep 2000\\t91\\n',\n",
       " '25 Sep 2000\\t92\\n',\n",
       " '26 Sep 2000\\t93\\n',\n",
       " '27 Sep 2000\\t94\\n',\n",
       " '28 Sep 2000\\t95\\n',\n",
       " '29 Sep 2000\\t96\\n',\n",
       " '30 Sep 2000\\t97\\n',\n",
       " '1 Oct 2000\\t98\\n',\n",
       " '2 Oct 2000\\t99\\n',\n",
       " '3 Oct 2000\\t100\\n',\n",
       " '4 Oct 2000\\t101\\n',\n",
       " '5 Oct 2000\\t102\\n',\n",
       " '6 Oct 2000\\t103\\n',\n",
       " '7 Oct 2000\\t104\\n',\n",
       " '8 Oct 2000\\t105\\n',\n",
       " '9 Oct 2000\\t106\\n',\n",
       " '10 Oct 2000\\t107\\n',\n",
       " '11 Oct 2000\\t108\\n',\n",
       " '12 Oct 2000\\t109\\n',\n",
       " '13 Oct 2000\\t110\\n',\n",
       " '14 Oct 2000\\t111\\n',\n",
       " '15 Oct 2000\\t112\\n',\n",
       " '16 Oct 2000\\t113\\n',\n",
       " '17 Oct 2000\\t114\\n',\n",
       " '18 Oct 2000\\t115\\n',\n",
       " '19 Oct 2000\\t116\\n',\n",
       " '20 Oct 2000\\t117\\n',\n",
       " '21 Oct 2000\\t118\\n',\n",
       " '22 Oct 2000\\t119\\n',\n",
       " '23 Oct 2000\\t120\\n',\n",
       " '24 Oct 2000\\t121\\n',\n",
       " '25 Oct 2000\\t122\\n',\n",
       " '26 Oct 2000\\t123\\n',\n",
       " '27 Oct 2000\\t124\\n',\n",
       " '28 Oct 2000\\t125\\n',\n",
       " '29 Oct 2000\\t126\\n',\n",
       " '30 Oct 2000\\t127\\n',\n",
       " '31 Oct 2000\\t128\\n',\n",
       " '1 Nov 2000\\t129\\n',\n",
       " '2 Nov 2000\\t130\\n',\n",
       " '3 Nov 2000\\t131\\n',\n",
       " '4 Nov 2000\\t132\\n',\n",
       " '5 Nov 2000\\t133\\n',\n",
       " '6 Nov 2000\\t134\\n',\n",
       " '7 Nov 2000\\t135\\n',\n",
       " '8 Nov 2000\\t136\\n',\n",
       " '9 Nov 2000\\t137\\n',\n",
       " '10 Nov 2000\\t138\\n',\n",
       " '11 Nov 2000\\t139\\n',\n",
       " '12 Nov 2000\\t140\\n',\n",
       " '13 Nov 2000\\t141\\n',\n",
       " '14 Nov 2000\\t142\\n',\n",
       " '15 Nov 2000\\t143\\n',\n",
       " '16 Nov 2000\\t144\\n',\n",
       " '17 Nov 2000\\t145\\n',\n",
       " '18 Nov 2000\\t146\\n',\n",
       " '19 Nov 2000\\t147\\n',\n",
       " '20 Nov 2000\\t148\\n',\n",
       " '21 Nov 2000\\t149\\n',\n",
       " '22 Nov 2000\\t150\\n',\n",
       " '23 Nov 2000\\t151\\n',\n",
       " '24 Nov 2000\\t152\\n',\n",
       " '25 Nov 2000\\t153\\n',\n",
       " '26 Nov 2000\\t154\\n',\n",
       " '27 Nov 2000\\t155\\n',\n",
       " '28 Nov 2000\\t156\\n',\n",
       " '29 Nov 2000\\t157\\n',\n",
       " '30 Nov 2000\\t158\\n',\n",
       " '1 Dec 2000\\t159\\n',\n",
       " '2 Dec 2000\\t160\\n',\n",
       " '3 Dec 2000\\t161\\n',\n",
       " '4 Dec 2000\\t162\\n',\n",
       " '5 Dec 2000\\t163\\n',\n",
       " '6 Dec 2000\\t164\\n',\n",
       " '7 Dec 2000\\t165\\n',\n",
       " '8 Dec 2000\\t166\\n',\n",
       " '9 Dec 2000\\t167\\n',\n",
       " '10 Dec 2000\\t168\\n',\n",
       " '11 Dec 2000\\t169\\n',\n",
       " '12 Dec 2000\\t170\\n',\n",
       " '13 Dec 2000\\t171\\n',\n",
       " '14 Dec 2000\\t172\\n',\n",
       " '15 Dec 2000\\t173\\n',\n",
       " '16 Dec 2000\\t174\\n',\n",
       " '17 Dec 2000\\t175\\n',\n",
       " '18 Dec 2000\\t176\\n',\n",
       " '19 Dec 2000\\t177\\n',\n",
       " '20 Dec 2000\\t178\\n',\n",
       " '21 Dec 2000\\t179\\n',\n",
       " '22 Dec 2000\\t180\\n',\n",
       " '23 Dec 2000\\t181\\n',\n",
       " '24 Dec 2000\\t182\\n',\n",
       " '25 Dec 2000\\t183\\n',\n",
       " '26 Dec 2000\\t184\\n',\n",
       " '27 Dec 2000\\t185\\n',\n",
       " '28 Dec 2000\\t186\\n',\n",
       " '29 Dec 2000\\t187\\n',\n",
       " '30 Dec 2000\\t188\\n',\n",
       " '31 Dec 2000\\t189\\n',\n",
       " '1 Jan 2001\\t190\\n',\n",
       " '2 Jan 2001\\t191\\n',\n",
       " '3 Jan 2001\\t192\\n',\n",
       " '4 Jan 2001\\t193\\n',\n",
       " '5 Jan 2001\\t194\\n',\n",
       " '6 Jan 2001\\t195\\n',\n",
       " '7 Jan 2001\\t196\\n',\n",
       " '8 Jan 2001\\t197\\n',\n",
       " '9 Jan 2001\\t198\\n',\n",
       " '10 Jan 2001\\t199\\n',\n",
       " '11 Jan 2001\\t200\\n',\n",
       " '12 Jan 2001\\t201\\n',\n",
       " '13 Jan 2001\\t202\\n',\n",
       " '14 Jan 2001\\t203\\n',\n",
       " '15 Jan 2001\\t204\\n',\n",
       " '16 Jan 2001\\t205\\n',\n",
       " '17 Jan 2001\\t206\\n',\n",
       " '18 Jan 2001\\t207\\n',\n",
       " '19 Jan 2001\\t208\\n',\n",
       " '20 Jan 2001\\t209\\n',\n",
       " '21 Jan 2001\\t210\\n',\n",
       " '22 Jan 2001\\t211\\n',\n",
       " '23 Jan 2001\\t212\\n',\n",
       " '24 Jan 2001\\t213\\n',\n",
       " '25 Jan 2001\\t214\\n',\n",
       " '26 Jan 2001\\t215\\n',\n",
       " '27 Jan 2001\\t216\\n',\n",
       " '28 Jan 2001\\t217\\n',\n",
       " '29 Jan 2001\\t218\\n',\n",
       " '30 Jan 2001\\t219\\n',\n",
       " '31 Jan 2001\\t220\\n',\n",
       " '1 Feb 2001\\t221\\n',\n",
       " '2 Feb 2001\\t222\\n',\n",
       " '3 Feb 2001\\t223\\n',\n",
       " '4 Feb 2001\\t224\\n',\n",
       " '5 Feb 2001\\t225\\n',\n",
       " '6 Feb 2001\\t226\\n',\n",
       " '7 Feb 2001\\t227\\n',\n",
       " '8 Feb 2001\\t228\\n',\n",
       " '9 Feb 2001\\t229\\n',\n",
       " '10 Feb 2001\\t230\\n',\n",
       " '11 Feb 2001\\t231\\n',\n",
       " '12 Feb 2001\\t232\\n',\n",
       " '13 Feb 2001\\t233\\n',\n",
       " '14 Feb 2001\\t234\\n',\n",
       " '15 Feb 2001\\t235\\n',\n",
       " '16 Feb 2001\\t236\\n',\n",
       " '17 Feb 2001\\t237\\n',\n",
       " '18 Feb 2001\\t238\\n',\n",
       " '19 Feb 2001\\t239\\n',\n",
       " '20 Feb 2001\\t240\\n',\n",
       " '21 Feb 2001\\t241\\n',\n",
       " '22 Feb 2001\\t242\\n',\n",
       " '23 Feb 2001\\t243\\n',\n",
       " '24 Feb 2001\\t244\\n',\n",
       " '25 Feb 2001\\t245\\n',\n",
       " '26 Feb 2001\\t246\\n',\n",
       " '27 Feb 2001\\t247\\n',\n",
       " '28 Feb 2001\\t248\\n',\n",
       " '1 Mar 2001\\t249\\n',\n",
       " '2 Mar 2001\\t250\\n',\n",
       " '3 Mar 2001\\t251\\n',\n",
       " '4 Mar 2001\\t252\\n',\n",
       " '5 Mar 2001\\t253\\n',\n",
       " '6 Mar 2001\\t254\\n',\n",
       " '7 Mar 2001\\t255\\n',\n",
       " '8 Mar 2001\\t256\\n',\n",
       " '9 Mar 2001\\t257\\n',\n",
       " '10 Mar 2001\\t258\\n',\n",
       " '11 Mar 2001\\t259\\n',\n",
       " '12 Mar 2001\\t260\\n',\n",
       " '13 Mar 2001\\t261\\n',\n",
       " '14 Mar 2001\\t262\\n',\n",
       " '15 Mar 2001\\t263\\n',\n",
       " '16 Mar 2001\\t264\\n',\n",
       " '17 Mar 2001\\t265\\n',\n",
       " '18 Mar 2001\\t266\\n',\n",
       " '19 Mar 2001\\t267\\n',\n",
       " '20 Mar 2001\\t268\\n',\n",
       " '21 Mar 2001\\t269\\n',\n",
       " '22 Mar 2001\\t270\\n',\n",
       " '23 Mar 2001\\t271\\n',\n",
       " '24 Mar 2001\\t272\\n',\n",
       " '25 Mar 2001\\t273\\n',\n",
       " '26 Mar 2001\\t274\\n',\n",
       " '27 Mar 2001\\t275\\n',\n",
       " '28 Mar 2001\\t276\\n',\n",
       " '29 Mar 2001\\t277\\n',\n",
       " '30 Mar 2001\\t278\\n',\n",
       " '31 Mar 2001\\t279\\n',\n",
       " '1 Apr 2001\\t280\\n',\n",
       " '2 Apr 2001\\t281\\n',\n",
       " '3 Apr 2001\\t282\\n',\n",
       " '4 Apr 2001\\t283\\n',\n",
       " '5 Apr 2001\\t284\\n',\n",
       " '6 Apr 2001\\t285\\n',\n",
       " '7 Apr 2001\\t286\\n',\n",
       " '8 Apr 2001\\t287\\n',\n",
       " '9 Apr 2001\\t288\\n',\n",
       " '10 Apr 2001\\t289\\n',\n",
       " '11 Apr 2001\\t290\\n',\n",
       " '12 Apr 2001\\t291\\n',\n",
       " '13 Apr 2001\\t292\\n',\n",
       " '14 Apr 2001\\t293\\n',\n",
       " '15 Apr 2001\\t294\\n',\n",
       " '16 Apr 2001\\t295\\n',\n",
       " '17 Apr 2001\\t296\\n',\n",
       " '18 Apr 2001\\t297\\n',\n",
       " '19 Apr 2001\\t298\\n',\n",
       " '20 Apr 2001\\t299\\n',\n",
       " '21 Apr 2001\\t300\\n',\n",
       " '22 Apr 2001\\t301\\n',\n",
       " '23 Apr 2001\\t302\\n',\n",
       " '24 Apr 2001\\t303\\n',\n",
       " '25 Apr 2001\\t304\\n',\n",
       " '26 Apr 2001\\t305\\n',\n",
       " '27 Apr 2001\\t306\\n',\n",
       " '28 Apr 2001\\t307\\n',\n",
       " '29 Apr 2001\\t308\\n',\n",
       " '30 Apr 2001\\t309\\n',\n",
       " '1 May 2001\\t310\\n',\n",
       " '2 May 2001\\t311\\n',\n",
       " '3 May 2001\\t312\\n',\n",
       " '4 May 2001\\t313\\n',\n",
       " '5 May 2001\\t314\\n',\n",
       " '6 May 2001\\t315\\n',\n",
       " '7 May 2001\\t316\\n',\n",
       " '8 May 2001\\t317\\n',\n",
       " '9 May 2001\\t318\\n',\n",
       " '10 May 2001\\t319\\n',\n",
       " '11 May 2001\\t320\\n',\n",
       " '12 May 2001\\t321\\n',\n",
       " '13 May 2001\\t322\\n',\n",
       " '14 May 2001\\t323\\n',\n",
       " '15 May 2001\\t324\\n',\n",
       " '16 May 2001\\t325\\n',\n",
       " '17 May 2001\\t326\\n',\n",
       " '18 May 2001\\t327\\n',\n",
       " '19 May 2001\\t328\\n',\n",
       " '20 May 2001\\t329\\n',\n",
       " '21 May 2001\\t330\\n',\n",
       " '22 May 2001\\t331\\n',\n",
       " '23 May 2001\\t332\\n',\n",
       " '24 May 2001\\t333\\n',\n",
       " '25 May 2001\\t334\\n',\n",
       " '26 May 2001\\t335\\n',\n",
       " '27 May 2001\\t336\\n',\n",
       " '28 May 2001\\t337\\n',\n",
       " '29 May 2001\\t338\\n',\n",
       " '30 May 2001\\t339\\n',\n",
       " '31 May 2001\\t340\\n',\n",
       " '1 Jun 2001\\t341\\n',\n",
       " '2 Jun 2001\\t342\\n',\n",
       " '3 Jun 2001\\t343\\n',\n",
       " '4 Jun 2001\\t344\\n',\n",
       " '5 Jun 2001\\t345\\n',\n",
       " '6 Jun 2001\\t346\\n',\n",
       " '7 Jun 2001\\t347\\n',\n",
       " '8 Jun 2001\\t348\\n',\n",
       " '9 Jun 2001\\t349\\n',\n",
       " '10 Jun 2001\\t350\\n',\n",
       " '11 Jun 2001\\t351\\n',\n",
       " '12 Jun 2001\\t352\\n',\n",
       " '13 Jun 2001\\t353\\n',\n",
       " '14 Jun 2001\\t354\\n',\n",
       " '15 Jun 2001\\t355\\n',\n",
       " '16 Jun 2001\\t356\\n',\n",
       " '17 Jun 2001\\t357\\n',\n",
       " '18 Jun 2001\\t358\\n',\n",
       " '19 Jun 2001\\t359\\n',\n",
       " '20 Jun 2001\\t360\\n',\n",
       " '21 Jun 2001\\t361\\n',\n",
       " '22 Jun 2001\\t362\\n',\n",
       " '23 Jun 2001\\t363\\n',\n",
       " '24 Jun 2001\\t364\\n',\n",
       " '25 Jun 2001\\t365\\n',\n",
       " '26 Jun 2001\\t366\\n',\n",
       " '27 Jun 2001\\t367\\n',\n",
       " '28 Jun 2001\\t368\\n',\n",
       " '29 Jun 2001\\t369\\n',\n",
       " '30 Jun 2001\\t370\\n',\n",
       " '1 Jul 2001\\t371\\n',\n",
       " '2 Jul 2001\\t372\\n',\n",
       " '3 Jul 2001\\t373\\n',\n",
       " '4 Jul 2001\\t374\\n',\n",
       " '5 Jul 2001\\t375\\n',\n",
       " '6 Jul 2001\\t376\\n',\n",
       " '7 Jul 2001\\t377\\n',\n",
       " '8 Jul 2001\\t378\\n',\n",
       " '9 Jul 2001\\t379\\n',\n",
       " '10 Jul 2001\\t380\\n',\n",
       " '11 Jul 2001\\t381\\n',\n",
       " '12 Jul 2001\\t382\\n',\n",
       " '13 Jul 2001\\t383\\n',\n",
       " '14 Jul 2001\\t384\\n',\n",
       " '15 Jul 2001\\t385\\n',\n",
       " '16 Jul 2001\\t386\\n',\n",
       " '17 Jul 2001\\t387\\n',\n",
       " '18 Jul 2001\\t388\\n',\n",
       " '19 Jul 2001\\t389\\n',\n",
       " '20 Jul 2001\\t390\\n',\n",
       " '21 Jul 2001\\t391\\n',\n",
       " '22 Jul 2001\\t392\\n',\n",
       " '23 Jul 2001\\t393\\n',\n",
       " '24 Jul 2001\\t394\\n',\n",
       " '25 Jul 2001\\t395\\n',\n",
       " '26 Jul 2001\\t396\\n',\n",
       " '27 Jul 2001\\t397\\n',\n",
       " '28 Jul 2001\\t398\\n',\n",
       " '29 Jul 2001\\t399\\n',\n",
       " '30 Jul 2001\\t400\\n',\n",
       " '31 Jul 2001\\t401\\n',\n",
       " '1 Aug 2001\\t402\\n',\n",
       " '2 Aug 2001\\t403\\n',\n",
       " '3 Aug 2001\\t404\\n',\n",
       " '4 Aug 2001\\t405\\n',\n",
       " '5 Aug 2001\\t406\\n',\n",
       " '6 Aug 2001\\t407\\n',\n",
       " '7 Aug 2001\\t408\\n',\n",
       " '8 Aug 2001\\t409\\n',\n",
       " '9 Aug 2001\\t410\\n',\n",
       " '10 Aug 2001\\t411\\n',\n",
       " '11 Aug 2001\\t412\\n',\n",
       " '12 Aug 2001\\t413\\n',\n",
       " '13 Aug 2001\\t414\\n',\n",
       " '14 Aug 2001\\t415\\n',\n",
       " '15 Aug 2001\\t416\\n',\n",
       " '16 Aug 2001\\t417\\n',\n",
       " '17 Aug 2001\\t418\\n',\n",
       " '18 Aug 2001\\t419\\n',\n",
       " '19 Aug 2001\\t420\\n',\n",
       " '20 Aug 2001\\t421\\n',\n",
       " '21 Aug 2001\\t422\\n',\n",
       " '22 Aug 2001\\t423\\n',\n",
       " '23 Aug 2001\\t424\\n',\n",
       " '24 Aug 2001\\t425\\n',\n",
       " '25 Aug 2001\\t426\\n',\n",
       " '26 Aug 2001\\t427\\n',\n",
       " '27 Aug 2001\\t428\\n',\n",
       " '28 Aug 2001\\t429\\n',\n",
       " '29 Aug 2001\\t430\\n',\n",
       " '30 Aug 2001\\t431\\n',\n",
       " '31 Aug 2001\\t432\\n',\n",
       " '1 Sep 2001\\t433\\n',\n",
       " '2 Sep 2001\\t434\\n',\n",
       " '3 Sep 2001\\t435\\n',\n",
       " '4 Sep 2001\\t436\\n',\n",
       " '5 Sep 2001\\t437\\n',\n",
       " '6 Sep 2001\\t438\\n',\n",
       " '7 Sep 2001\\t439\\n',\n",
       " '8 Sep 2001\\t440\\n',\n",
       " '9 Sep 2001\\t441\\n',\n",
       " '10 Sep 2001\\t442\\n',\n",
       " '11 Sep 2001\\t443\\n',\n",
       " '12 Sep 2001\\t444\\n',\n",
       " '13 Sep 2001\\t445\\n',\n",
       " '14 Sep 2001\\t446\\n',\n",
       " '15 Sep 2001\\t447\\n',\n",
       " '16 Sep 2001\\t448\\n',\n",
       " '17 Sep 2001\\t449\\n',\n",
       " '18 Sep 2001\\t450\\n',\n",
       " '19 Sep 2001\\t451\\n',\n",
       " '20 Sep 2001\\t452\\n',\n",
       " '21 Sep 2001\\t453\\n',\n",
       " '22 Sep 2001\\t454\\n',\n",
       " '23 Sep 2001\\t455\\n',\n",
       " '24 Sep 2001\\t456\\n',\n",
       " '25 Sep 2001\\t457\\n',\n",
       " '26 Sep 2001\\t458\\n',\n",
       " '27 Sep 2001\\t459\\n',\n",
       " '28 Sep 2001\\t460\\n',\n",
       " '29 Sep 2001\\t461\\n',\n",
       " '30 Sep 2001\\t462\\n',\n",
       " '1 Oct 2001\\t463\\n',\n",
       " '2 Oct 2001\\t464\\n',\n",
       " '3 Oct 2001\\t465\\n',\n",
       " '4 Oct 2001\\t466\\n',\n",
       " '5 Oct 2001\\t467\\n',\n",
       " '6 Oct 2001\\t468\\n',\n",
       " '7 Oct 2001\\t469\\n',\n",
       " '8 Oct 2001\\t470\\n',\n",
       " '9 Oct 2001\\t471\\n',\n",
       " '10 Oct 2001\\t472\\n',\n",
       " '11 Oct 2001\\t473\\n',\n",
       " '12 Oct 2001\\t474\\n',\n",
       " '13 Oct 2001\\t475\\n',\n",
       " '14 Oct 2001\\t476\\n',\n",
       " '15 Oct 2001\\t477\\n',\n",
       " '16 Oct 2001\\t478\\n',\n",
       " '17 Oct 2001\\t479\\n',\n",
       " '18 Oct 2001\\t480\\n',\n",
       " '19 Oct 2001\\t481\\n',\n",
       " '20 Oct 2001\\t482\\n',\n",
       " '21 Oct 2001\\t483\\n',\n",
       " '22 Oct 2001\\t484\\n',\n",
       " '23 Oct 2001\\t485\\n',\n",
       " '24 Oct 2001\\t486\\n',\n",
       " '25 Oct 2001\\t487\\n',\n",
       " '26 Oct 2001\\t488\\n',\n",
       " '27 Oct 2001\\t489\\n',\n",
       " '28 Oct 2001\\t490\\n',\n",
       " '29 Oct 2001\\t491\\n',\n",
       " '30 Oct 2001\\t492\\n',\n",
       " '31 Oct 2001\\t493\\n',\n",
       " '1 Nov 2001\\t494\\n',\n",
       " '2 Nov 2001\\t495\\n',\n",
       " '3 Nov 2001\\t496\\n',\n",
       " '4 Nov 2001\\t497\\n',\n",
       " '5 Nov 2001\\t498\\n',\n",
       " '6 Nov 2001\\t499\\n',\n",
       " '7 Nov 2001\\t500\\n',\n",
       " '8 Nov 2001\\t501\\n',\n",
       " '9 Nov 2001\\t502\\n',\n",
       " '10 Nov 2001\\t503\\n',\n",
       " '11 Nov 2001\\t504\\n',\n",
       " '12 Nov 2001\\t505\\n',\n",
       " '13 Nov 2001\\t506\\n',\n",
       " '14 Nov 2001\\t507\\n',\n",
       " '15 Nov 2001\\t508\\n',\n",
       " '16 Nov 2001\\t509\\n',\n",
       " '17 Nov 2001\\t510\\n',\n",
       " '18 Nov 2001\\t511\\n',\n",
       " '19 Nov 2001\\t512\\n',\n",
       " '20 Nov 2001\\t513\\n',\n",
       " '21 Nov 2001\\t514\\n',\n",
       " '22 Nov 2001\\t515\\n',\n",
       " '23 Nov 2001\\t516\\n',\n",
       " '24 Nov 2001\\t517\\n',\n",
       " '25 Nov 2001\\t518\\n',\n",
       " '26 Nov 2001\\t519\\n',\n",
       " '27 Nov 2001\\t520\\n',\n",
       " '28 Nov 2001\\t521\\n',\n",
       " '29 Nov 2001\\t522\\n',\n",
       " '30 Nov 2001\\t523\\n',\n",
       " '1 Dec 2001\\t524\\n',\n",
       " '2 Dec 2001\\t525\\n',\n",
       " '3 Dec 2001\\t526\\n',\n",
       " '4 Dec 2001\\t527\\n',\n",
       " '5 Dec 2001\\t528\\n',\n",
       " '6 Dec 2001\\t529\\n',\n",
       " '7 Dec 2001\\t530\\n',\n",
       " '8 Dec 2001\\t531\\n',\n",
       " '9 Dec 2001\\t532\\n',\n",
       " '10 Dec 2001\\t533\\n',\n",
       " '11 Dec 2001\\t534\\n',\n",
       " '12 Dec 2001\\t535\\n',\n",
       " '13 Dec 2001\\t536\\n',\n",
       " '14 Dec 2001\\t537\\n',\n",
       " '15 Dec 2001\\t538\\n',\n",
       " '16 Dec 2001\\t539\\n',\n",
       " '17 Dec 2001\\t540\\n',\n",
       " '18 Dec 2001\\t541\\n',\n",
       " '19 Dec 2001\\t542\\n',\n",
       " '20 Dec 2001\\t543\\n',\n",
       " '21 Dec 2001\\t544\\n',\n",
       " '22 Dec 2001\\t545\\n',\n",
       " '23 Dec 2001\\t546\\n',\n",
       " '24 Dec 2001\\t547\\n',\n",
       " '25 Dec 2001\\t548\\n',\n",
       " '26 Dec 2001\\t549\\n',\n",
       " '27 Dec 2001\\t550\\n',\n",
       " '28 Dec 2001\\t551\\n',\n",
       " '29 Dec 2001\\t552\\n',\n",
       " '30 Dec 2001\\t553\\n',\n",
       " '31 Dec 2001\\t554\\n',\n",
       " '1 Jan 2002\\t555\\n',\n",
       " '2 Jan 2002\\t556\\n',\n",
       " '3 Jan 2002\\t557\\n',\n",
       " '4 Jan 2002\\t558\\n',\n",
       " '5 Jan 2002\\t559\\n',\n",
       " '6 Jan 2002\\t560\\n',\n",
       " '7 Jan 2002\\t561\\n',\n",
       " '8 Jan 2002\\t562\\n',\n",
       " '9 Jan 2002\\t563\\n',\n",
       " '10 Jan 2002\\t564\\n',\n",
       " '11 Jan 2002\\t565\\n',\n",
       " '12 Jan 2002\\t566\\n',\n",
       " '13 Jan 2002\\t567\\n',\n",
       " '14 Jan 2002\\t568\\n',\n",
       " '15 Jan 2002\\t569\\n',\n",
       " '16 Jan 2002\\t570\\n',\n",
       " '17 Jan 2002\\t571\\n',\n",
       " '18 Jan 2002\\t572\\n',\n",
       " '19 Jan 2002\\t573\\n',\n",
       " '20 Jan 2002\\t574\\n',\n",
       " '21 Jan 2002\\t575\\n',\n",
       " '22 Jan 2002\\t576\\n',\n",
       " '23 Jan 2002\\t577\\n',\n",
       " '24 Jan 2002\\t578\\n',\n",
       " '25 Jan 2002\\t579\\n',\n",
       " '26 Jan 2002\\t580\\n',\n",
       " '27 Jan 2002\\t581\\n',\n",
       " '28 Jan 2002\\t582\\n',\n",
       " '29 Jan 2002\\t583\\n',\n",
       " '30 Jan 2002\\t584\\n',\n",
       " '31 Jan 2002\\t585\\n',\n",
       " '1 Feb 2002\\t586\\n',\n",
       " '2 Feb 2002\\t587\\n',\n",
       " '3 Feb 2002\\t588\\n',\n",
       " '4 Feb 2002\\t589\\n',\n",
       " '5 Feb 2002\\t590\\n',\n",
       " '6 Feb 2002\\t591\\n',\n",
       " '7 Feb 2002\\t592\\n',\n",
       " '8 Feb 2002\\t593\\n',\n",
       " '9 Feb 2002\\t594\\n',\n",
       " '10 Feb 2002\\t595\\n',\n",
       " '11 Feb 2002\\t596\\n',\n",
       " '12 Feb 2002\\t597\\n',\n",
       " '13 Feb 2002\\t598\\n',\n",
       " '14 Feb 2002\\t599\\n',\n",
       " '15 Feb 2002\\t600\\n',\n",
       " '16 Feb 2002\\t601\\n',\n",
       " '17 Feb 2002\\t602\\n',\n",
       " '18 Feb 2002\\t603\\n',\n",
       " '19 Feb 2002\\t604\\n',\n",
       " '20 Feb 2002\\t605\\n',\n",
       " '21 Feb 2002\\t606\\n',\n",
       " '22 Feb 2002\\t607\\n',\n",
       " '23 Feb 2002\\t608\\n',\n",
       " '24 Feb 2002\\t609\\n',\n",
       " '25 Feb 2002\\t610\\n',\n",
       " '26 Feb 2002\\t611\\n',\n",
       " '27 Feb 2002\\t612\\n',\n",
       " '28 Feb 2002\\t613\\n',\n",
       " '1 Mar 2002\\t614\\n',\n",
       " '2 Mar 2002\\t615\\n',\n",
       " '3 Mar 2002\\t616\\n',\n",
       " '4 Mar 2002\\t617\\n',\n",
       " '5 Mar 2002\\t618\\n',\n",
       " '6 Mar 2002\\t619\\n',\n",
       " '7 Mar 2002\\t620\\n',\n",
       " '8 Mar 2002\\t621\\n',\n",
       " '9 Mar 2002\\t622\\n',\n",
       " '10 Mar 2002\\t623\\n',\n",
       " '11 Mar 2002\\t624\\n',\n",
       " '12 Mar 2002\\t625\\n',\n",
       " '13 Mar 2002\\t626\\n',\n",
       " '14 Mar 2002\\t627\\n',\n",
       " '15 Mar 2002\\t628\\n',\n",
       " '16 Mar 2002\\t629\\n',\n",
       " '17 Mar 2002\\t630\\n',\n",
       " '18 Mar 2002\\t631\\n',\n",
       " '19 Mar 2002\\t632\\n',\n",
       " '20 Mar 2002\\t633\\n',\n",
       " '21 Mar 2002\\t634\\n',\n",
       " '22 Mar 2002\\t635\\n',\n",
       " '23 Mar 2002\\t636\\n']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = map(lambda x: x.split()[-1], lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = [x for i, x in list(enumerate(temp)) if i % 6 != 0 and i % 7 != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sunday = temp[0::7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saturday = temp[6::7] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dayoffs = map(lambda x: int(x), sunday + saturday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = map(lambda x: int(x), temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = [x for x in temp if x not in dayoffs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 299,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 312,\n",
       " 313,\n",
       " 316,\n",
       " 317,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 330,\n",
       " 331,\n",
       " 332,\n",
       " 333,\n",
       " 334,\n",
       " 337,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 341,\n",
       " 344,\n",
       " 345,\n",
       " 346,\n",
       " 347,\n",
       " 348,\n",
       " 351,\n",
       " 352,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 358,\n",
       " 359,\n",
       " 360,\n",
       " 361,\n",
       " 362,\n",
       " 365,\n",
       " 366,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 372,\n",
       " 373,\n",
       " 374,\n",
       " 375,\n",
       " 376,\n",
       " 379,\n",
       " 380,\n",
       " 381,\n",
       " 382,\n",
       " 383,\n",
       " 386,\n",
       " 387,\n",
       " 388,\n",
       " 389,\n",
       " 390,\n",
       " 393,\n",
       " 394,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 400,\n",
       " 401,\n",
       " 402,\n",
       " 403,\n",
       " 404,\n",
       " 407,\n",
       " 408,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 417,\n",
       " 418,\n",
       " 421,\n",
       " 422,\n",
       " 423,\n",
       " 424,\n",
       " 425,\n",
       " 428,\n",
       " 429,\n",
       " 430,\n",
       " 431,\n",
       " 432,\n",
       " 435,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 442,\n",
       " 443,\n",
       " 444,\n",
       " 445,\n",
       " 446,\n",
       " 449,\n",
       " 450,\n",
       " 451,\n",
       " 452,\n",
       " 453,\n",
       " 456,\n",
       " 457,\n",
       " 458,\n",
       " 459,\n",
       " 460,\n",
       " 463,\n",
       " 464,\n",
       " 465,\n",
       " 466,\n",
       " 467,\n",
       " 470,\n",
       " 471,\n",
       " 472,\n",
       " 473,\n",
       " 474,\n",
       " 477,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 481,\n",
       " 484,\n",
       " 485,\n",
       " 486,\n",
       " 487,\n",
       " 488,\n",
       " 491,\n",
       " 492,\n",
       " 493,\n",
       " 494,\n",
       " 495,\n",
       " 498,\n",
       " 499,\n",
       " 500,\n",
       " 501,\n",
       " 502,\n",
       " 505,\n",
       " 506,\n",
       " 507,\n",
       " 508,\n",
       " 509,\n",
       " 512,\n",
       " 513,\n",
       " 514,\n",
       " 515,\n",
       " 516,\n",
       " 519,\n",
       " 520,\n",
       " 521,\n",
       " 522,\n",
       " 523,\n",
       " 526,\n",
       " 527,\n",
       " 528,\n",
       " 529,\n",
       " 530,\n",
       " 533,\n",
       " 534,\n",
       " 535,\n",
       " 536,\n",
       " 537,\n",
       " 540,\n",
       " 541,\n",
       " 542,\n",
       " 543,\n",
       " 544,\n",
       " 547,\n",
       " 548,\n",
       " 549,\n",
       " 550,\n",
       " 551,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 557,\n",
       " 558,\n",
       " 561,\n",
       " 562,\n",
       " 563,\n",
       " 564,\n",
       " 565,\n",
       " 568,\n",
       " 569,\n",
       " 570,\n",
       " 571,\n",
       " 572,\n",
       " 575,\n",
       " 576,\n",
       " 577,\n",
       " 578,\n",
       " 579,\n",
       " 582,\n",
       " 583,\n",
       " 584,\n",
       " 585,\n",
       " 586,\n",
       " 589,\n",
       " 590,\n",
       " 591,\n",
       " 592,\n",
       " 593,\n",
       " 596,\n",
       " 597,\n",
       " 598,\n",
       " 599,\n",
       " 600,\n",
       " 603,\n",
       " 604,\n",
       " 605,\n",
       " 606,\n",
       " 607,\n",
       " 610,\n",
       " 611,\n",
       " 612,\n",
       " 613,\n",
       " 614,\n",
       " 617,\n",
       " 618,\n",
       " 619,\n",
       " 620,\n",
       " 621,\n",
       " 624,\n",
       " 625,\n",
       " 626,\n",
       " 627,\n",
       " 628,\n",
       " 631,\n",
       " 632,\n",
       " 633,\n",
       " 634,\n",
       " 635]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = os.listdir('../enron/parsed_graphs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = files[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_files = [x for x in files if int(x.split('.')[0].split('_')[1]) in temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in new_files:\n",
    "    copyfile('../enron/parsed_graphs/'+f, '../enron/res_graphs/'+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = [True if i not in dayoffs else False for i in range(len(files)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['enron_0.graphml',\n",
       " 'enron_1.graphml',\n",
       " 'enron_10.graphml',\n",
       " 'enron_100.graphml',\n",
       " 'enron_101.graphml',\n",
       " 'enron_102.graphml',\n",
       " 'enron_103.graphml',\n",
       " 'enron_104.graphml',\n",
       " 'enron_105.graphml',\n",
       " 'enron_106.graphml',\n",
       " 'enron_107.graphml',\n",
       " 'enron_108.graphml',\n",
       " 'enron_109.graphml',\n",
       " 'enron_11.graphml',\n",
       " 'enron_110.graphml',\n",
       " 'enron_111.graphml',\n",
       " 'enron_112.graphml',\n",
       " 'enron_113.graphml',\n",
       " 'enron_114.graphml',\n",
       " 'enron_115.graphml',\n",
       " 'enron_116.graphml',\n",
       " 'enron_117.graphml',\n",
       " 'enron_118.graphml',\n",
       " 'enron_119.graphml',\n",
       " 'enron_12.graphml',\n",
       " 'enron_120.graphml',\n",
       " 'enron_121.graphml',\n",
       " 'enron_122.graphml',\n",
       " 'enron_123.graphml',\n",
       " 'enron_124.graphml',\n",
       " 'enron_125.graphml',\n",
       " 'enron_126.graphml',\n",
       " 'enron_127.graphml',\n",
       " 'enron_128.graphml',\n",
       " 'enron_129.graphml',\n",
       " 'enron_13.graphml',\n",
       " 'enron_130.graphml',\n",
       " 'enron_131.graphml',\n",
       " 'enron_132.graphml',\n",
       " 'enron_133.graphml',\n",
       " 'enron_134.graphml',\n",
       " 'enron_135.graphml',\n",
       " 'enron_136.graphml',\n",
       " 'enron_137.graphml',\n",
       " 'enron_138.graphml',\n",
       " 'enron_139.graphml',\n",
       " 'enron_14.graphml',\n",
       " 'enron_140.graphml',\n",
       " 'enron_141.graphml',\n",
       " 'enron_142.graphml',\n",
       " 'enron_143.graphml',\n",
       " 'enron_144.graphml',\n",
       " 'enron_145.graphml',\n",
       " 'enron_146.graphml',\n",
       " 'enron_147.graphml',\n",
       " 'enron_148.graphml',\n",
       " 'enron_149.graphml',\n",
       " 'enron_15.graphml',\n",
       " 'enron_150.graphml',\n",
       " 'enron_151.graphml',\n",
       " 'enron_152.graphml',\n",
       " 'enron_153.graphml',\n",
       " 'enron_154.graphml',\n",
       " 'enron_155.graphml',\n",
       " 'enron_156.graphml',\n",
       " 'enron_157.graphml',\n",
       " 'enron_158.graphml',\n",
       " 'enron_159.graphml',\n",
       " 'enron_16.graphml',\n",
       " 'enron_160.graphml',\n",
       " 'enron_161.graphml',\n",
       " 'enron_162.graphml',\n",
       " 'enron_163.graphml',\n",
       " 'enron_164.graphml',\n",
       " 'enron_165.graphml',\n",
       " 'enron_166.graphml',\n",
       " 'enron_167.graphml',\n",
       " 'enron_168.graphml',\n",
       " 'enron_169.graphml',\n",
       " 'enron_17.graphml',\n",
       " 'enron_170.graphml',\n",
       " 'enron_171.graphml',\n",
       " 'enron_172.graphml',\n",
       " 'enron_173.graphml',\n",
       " 'enron_174.graphml',\n",
       " 'enron_175.graphml',\n",
       " 'enron_176.graphml',\n",
       " 'enron_177.graphml',\n",
       " 'enron_178.graphml',\n",
       " 'enron_179.graphml',\n",
       " 'enron_18.graphml',\n",
       " 'enron_180.graphml',\n",
       " 'enron_181.graphml',\n",
       " 'enron_182.graphml',\n",
       " 'enron_183.graphml',\n",
       " 'enron_184.graphml',\n",
       " 'enron_185.graphml',\n",
       " 'enron_186.graphml',\n",
       " 'enron_187.graphml',\n",
       " 'enron_188.graphml',\n",
       " 'enron_189.graphml',\n",
       " 'enron_19.graphml',\n",
       " 'enron_190.graphml',\n",
       " 'enron_191.graphml',\n",
       " 'enron_192.graphml',\n",
       " 'enron_193.graphml',\n",
       " 'enron_194.graphml',\n",
       " 'enron_195.graphml',\n",
       " 'enron_196.graphml',\n",
       " 'enron_197.graphml',\n",
       " 'enron_198.graphml',\n",
       " 'enron_199.graphml',\n",
       " 'enron_2.graphml',\n",
       " 'enron_20.graphml',\n",
       " 'enron_200.graphml',\n",
       " 'enron_201.graphml',\n",
       " 'enron_202.graphml',\n",
       " 'enron_203.graphml',\n",
       " 'enron_204.graphml',\n",
       " 'enron_205.graphml',\n",
       " 'enron_206.graphml',\n",
       " 'enron_207.graphml',\n",
       " 'enron_208.graphml',\n",
       " 'enron_209.graphml',\n",
       " 'enron_21.graphml',\n",
       " 'enron_210.graphml',\n",
       " 'enron_211.graphml',\n",
       " 'enron_212.graphml',\n",
       " 'enron_213.graphml',\n",
       " 'enron_214.graphml',\n",
       " 'enron_215.graphml',\n",
       " 'enron_216.graphml',\n",
       " 'enron_217.graphml',\n",
       " 'enron_218.graphml',\n",
       " 'enron_219.graphml',\n",
       " 'enron_22.graphml',\n",
       " 'enron_220.graphml',\n",
       " 'enron_221.graphml',\n",
       " 'enron_222.graphml',\n",
       " 'enron_223.graphml',\n",
       " 'enron_224.graphml',\n",
       " 'enron_225.graphml',\n",
       " 'enron_226.graphml',\n",
       " 'enron_227.graphml',\n",
       " 'enron_228.graphml',\n",
       " 'enron_229.graphml',\n",
       " 'enron_23.graphml',\n",
       " 'enron_230.graphml',\n",
       " 'enron_231.graphml',\n",
       " 'enron_232.graphml',\n",
       " 'enron_233.graphml',\n",
       " 'enron_234.graphml',\n",
       " 'enron_235.graphml',\n",
       " 'enron_236.graphml',\n",
       " 'enron_237.graphml',\n",
       " 'enron_238.graphml',\n",
       " 'enron_239.graphml',\n",
       " 'enron_24.graphml',\n",
       " 'enron_240.graphml',\n",
       " 'enron_241.graphml',\n",
       " 'enron_242.graphml',\n",
       " 'enron_243.graphml',\n",
       " 'enron_244.graphml',\n",
       " 'enron_245.graphml',\n",
       " 'enron_246.graphml',\n",
       " 'enron_247.graphml',\n",
       " 'enron_248.graphml',\n",
       " 'enron_249.graphml',\n",
       " 'enron_25.graphml',\n",
       " 'enron_250.graphml',\n",
       " 'enron_251.graphml',\n",
       " 'enron_252.graphml',\n",
       " 'enron_253.graphml',\n",
       " 'enron_254.graphml',\n",
       " 'enron_255.graphml',\n",
       " 'enron_256.graphml',\n",
       " 'enron_257.graphml',\n",
       " 'enron_258.graphml',\n",
       " 'enron_259.graphml',\n",
       " 'enron_26.graphml',\n",
       " 'enron_260.graphml',\n",
       " 'enron_261.graphml',\n",
       " 'enron_262.graphml',\n",
       " 'enron_263.graphml',\n",
       " 'enron_264.graphml',\n",
       " 'enron_265.graphml',\n",
       " 'enron_266.graphml',\n",
       " 'enron_267.graphml',\n",
       " 'enron_268.graphml',\n",
       " 'enron_269.graphml',\n",
       " 'enron_27.graphml',\n",
       " 'enron_270.graphml',\n",
       " 'enron_271.graphml',\n",
       " 'enron_272.graphml',\n",
       " 'enron_273.graphml',\n",
       " 'enron_274.graphml',\n",
       " 'enron_275.graphml',\n",
       " 'enron_276.graphml',\n",
       " 'enron_277.graphml',\n",
       " 'enron_278.graphml',\n",
       " 'enron_279.graphml',\n",
       " 'enron_28.graphml',\n",
       " 'enron_280.graphml',\n",
       " 'enron_281.graphml',\n",
       " 'enron_282.graphml',\n",
       " 'enron_283.graphml',\n",
       " 'enron_284.graphml',\n",
       " 'enron_285.graphml',\n",
       " 'enron_286.graphml',\n",
       " 'enron_287.graphml',\n",
       " 'enron_288.graphml',\n",
       " 'enron_289.graphml',\n",
       " 'enron_29.graphml',\n",
       " 'enron_290.graphml',\n",
       " 'enron_291.graphml',\n",
       " 'enron_292.graphml',\n",
       " 'enron_293.graphml',\n",
       " 'enron_294.graphml',\n",
       " 'enron_295.graphml',\n",
       " 'enron_296.graphml',\n",
       " 'enron_297.graphml',\n",
       " 'enron_298.graphml',\n",
       " 'enron_299.graphml',\n",
       " 'enron_3.graphml',\n",
       " 'enron_30.graphml',\n",
       " 'enron_300.graphml',\n",
       " 'enron_301.graphml',\n",
       " 'enron_302.graphml',\n",
       " 'enron_303.graphml',\n",
       " 'enron_304.graphml',\n",
       " 'enron_305.graphml',\n",
       " 'enron_306.graphml',\n",
       " 'enron_307.graphml',\n",
       " 'enron_308.graphml',\n",
       " 'enron_309.graphml',\n",
       " 'enron_31.graphml',\n",
       " 'enron_310.graphml',\n",
       " 'enron_311.graphml',\n",
       " 'enron_312.graphml',\n",
       " 'enron_313.graphml',\n",
       " 'enron_314.graphml',\n",
       " 'enron_315.graphml',\n",
       " 'enron_316.graphml',\n",
       " 'enron_317.graphml',\n",
       " 'enron_318.graphml',\n",
       " 'enron_319.graphml',\n",
       " 'enron_32.graphml',\n",
       " 'enron_320.graphml',\n",
       " 'enron_321.graphml',\n",
       " 'enron_322.graphml',\n",
       " 'enron_323.graphml',\n",
       " 'enron_324.graphml',\n",
       " 'enron_325.graphml',\n",
       " 'enron_326.graphml',\n",
       " 'enron_327.graphml',\n",
       " 'enron_328.graphml',\n",
       " 'enron_329.graphml',\n",
       " 'enron_33.graphml',\n",
       " 'enron_330.graphml',\n",
       " 'enron_331.graphml',\n",
       " 'enron_332.graphml',\n",
       " 'enron_333.graphml',\n",
       " 'enron_334.graphml',\n",
       " 'enron_335.graphml',\n",
       " 'enron_336.graphml',\n",
       " 'enron_337.graphml',\n",
       " 'enron_338.graphml',\n",
       " 'enron_339.graphml',\n",
       " 'enron_34.graphml',\n",
       " 'enron_340.graphml',\n",
       " 'enron_341.graphml',\n",
       " 'enron_342.graphml',\n",
       " 'enron_343.graphml',\n",
       " 'enron_344.graphml',\n",
       " 'enron_345.graphml',\n",
       " 'enron_346.graphml',\n",
       " 'enron_347.graphml',\n",
       " 'enron_348.graphml',\n",
       " 'enron_349.graphml',\n",
       " 'enron_35.graphml',\n",
       " 'enron_350.graphml',\n",
       " 'enron_351.graphml',\n",
       " 'enron_352.graphml',\n",
       " 'enron_353.graphml',\n",
       " 'enron_354.graphml',\n",
       " 'enron_355.graphml',\n",
       " 'enron_356.graphml',\n",
       " 'enron_357.graphml',\n",
       " 'enron_358.graphml',\n",
       " 'enron_359.graphml',\n",
       " 'enron_36.graphml',\n",
       " 'enron_360.graphml',\n",
       " 'enron_361.graphml',\n",
       " 'enron_362.graphml',\n",
       " 'enron_363.graphml',\n",
       " 'enron_364.graphml',\n",
       " 'enron_365.graphml',\n",
       " 'enron_366.graphml',\n",
       " 'enron_367.graphml',\n",
       " 'enron_368.graphml',\n",
       " 'enron_369.graphml',\n",
       " 'enron_37.graphml',\n",
       " 'enron_370.graphml',\n",
       " 'enron_371.graphml',\n",
       " 'enron_372.graphml',\n",
       " 'enron_373.graphml',\n",
       " 'enron_374.graphml',\n",
       " 'enron_375.graphml',\n",
       " 'enron_376.graphml',\n",
       " 'enron_377.graphml',\n",
       " 'enron_378.graphml',\n",
       " 'enron_379.graphml',\n",
       " 'enron_38.graphml',\n",
       " 'enron_380.graphml',\n",
       " 'enron_381.graphml',\n",
       " 'enron_382.graphml',\n",
       " 'enron_383.graphml',\n",
       " 'enron_384.graphml',\n",
       " 'enron_385.graphml',\n",
       " 'enron_386.graphml',\n",
       " 'enron_387.graphml',\n",
       " 'enron_388.graphml',\n",
       " 'enron_389.graphml',\n",
       " 'enron_39.graphml',\n",
       " 'enron_390.graphml',\n",
       " 'enron_391.graphml',\n",
       " 'enron_392.graphml',\n",
       " 'enron_393.graphml',\n",
       " 'enron_394.graphml',\n",
       " 'enron_395.graphml',\n",
       " 'enron_396.graphml',\n",
       " 'enron_397.graphml',\n",
       " 'enron_398.graphml',\n",
       " 'enron_399.graphml',\n",
       " 'enron_4.graphml',\n",
       " 'enron_40.graphml',\n",
       " 'enron_400.graphml',\n",
       " 'enron_401.graphml',\n",
       " 'enron_402.graphml',\n",
       " 'enron_403.graphml',\n",
       " 'enron_404.graphml',\n",
       " 'enron_405.graphml',\n",
       " 'enron_406.graphml',\n",
       " 'enron_407.graphml',\n",
       " 'enron_408.graphml',\n",
       " 'enron_409.graphml',\n",
       " 'enron_41.graphml',\n",
       " 'enron_410.graphml',\n",
       " 'enron_411.graphml',\n",
       " 'enron_412.graphml',\n",
       " 'enron_413.graphml',\n",
       " 'enron_414.graphml',\n",
       " 'enron_415.graphml',\n",
       " 'enron_416.graphml',\n",
       " 'enron_417.graphml',\n",
       " 'enron_418.graphml',\n",
       " 'enron_419.graphml',\n",
       " 'enron_42.graphml',\n",
       " 'enron_420.graphml',\n",
       " 'enron_421.graphml',\n",
       " 'enron_422.graphml',\n",
       " 'enron_423.graphml',\n",
       " 'enron_424.graphml',\n",
       " 'enron_425.graphml',\n",
       " 'enron_426.graphml',\n",
       " 'enron_427.graphml',\n",
       " 'enron_428.graphml',\n",
       " 'enron_429.graphml',\n",
       " 'enron_43.graphml',\n",
       " 'enron_430.graphml',\n",
       " 'enron_431.graphml',\n",
       " 'enron_432.graphml',\n",
       " 'enron_433.graphml',\n",
       " 'enron_434.graphml',\n",
       " 'enron_435.graphml',\n",
       " 'enron_436.graphml',\n",
       " 'enron_437.graphml',\n",
       " 'enron_438.graphml',\n",
       " 'enron_439.graphml',\n",
       " 'enron_44.graphml',\n",
       " 'enron_440.graphml',\n",
       " 'enron_441.graphml',\n",
       " 'enron_442.graphml',\n",
       " 'enron_443.graphml',\n",
       " 'enron_444.graphml',\n",
       " 'enron_445.graphml',\n",
       " 'enron_446.graphml',\n",
       " 'enron_447.graphml',\n",
       " 'enron_448.graphml',\n",
       " 'enron_449.graphml',\n",
       " 'enron_45.graphml',\n",
       " 'enron_450.graphml',\n",
       " 'enron_451.graphml',\n",
       " 'enron_452.graphml',\n",
       " 'enron_453.graphml',\n",
       " 'enron_454.graphml',\n",
       " 'enron_455.graphml',\n",
       " 'enron_456.graphml',\n",
       " 'enron_457.graphml',\n",
       " 'enron_458.graphml',\n",
       " 'enron_459.graphml',\n",
       " 'enron_46.graphml',\n",
       " 'enron_460.graphml',\n",
       " 'enron_461.graphml',\n",
       " 'enron_462.graphml',\n",
       " 'enron_463.graphml',\n",
       " 'enron_464.graphml',\n",
       " 'enron_465.graphml',\n",
       " 'enron_466.graphml',\n",
       " 'enron_467.graphml',\n",
       " 'enron_468.graphml',\n",
       " 'enron_469.graphml',\n",
       " 'enron_47.graphml',\n",
       " 'enron_470.graphml',\n",
       " 'enron_471.graphml',\n",
       " 'enron_472.graphml',\n",
       " 'enron_473.graphml',\n",
       " 'enron_474.graphml',\n",
       " 'enron_475.graphml',\n",
       " 'enron_476.graphml',\n",
       " 'enron_477.graphml',\n",
       " 'enron_478.graphml',\n",
       " 'enron_479.graphml',\n",
       " 'enron_48.graphml',\n",
       " 'enron_480.graphml',\n",
       " 'enron_481.graphml',\n",
       " 'enron_482.graphml',\n",
       " 'enron_483.graphml',\n",
       " 'enron_484.graphml',\n",
       " 'enron_485.graphml',\n",
       " 'enron_486.graphml',\n",
       " 'enron_487.graphml',\n",
       " 'enron_488.graphml',\n",
       " 'enron_489.graphml',\n",
       " 'enron_49.graphml',\n",
       " 'enron_490.graphml',\n",
       " 'enron_491.graphml',\n",
       " 'enron_492.graphml',\n",
       " 'enron_493.graphml',\n",
       " 'enron_494.graphml',\n",
       " 'enron_495.graphml',\n",
       " 'enron_496.graphml',\n",
       " 'enron_497.graphml',\n",
       " 'enron_498.graphml',\n",
       " 'enron_499.graphml',\n",
       " 'enron_5.graphml',\n",
       " 'enron_50.graphml',\n",
       " 'enron_500.graphml',\n",
       " 'enron_501.graphml',\n",
       " 'enron_502.graphml',\n",
       " 'enron_503.graphml',\n",
       " 'enron_504.graphml',\n",
       " 'enron_505.graphml',\n",
       " 'enron_506.graphml',\n",
       " 'enron_507.graphml',\n",
       " 'enron_508.graphml',\n",
       " 'enron_509.graphml',\n",
       " 'enron_51.graphml',\n",
       " 'enron_510.graphml',\n",
       " 'enron_511.graphml',\n",
       " 'enron_512.graphml',\n",
       " 'enron_513.graphml',\n",
       " 'enron_514.graphml',\n",
       " 'enron_515.graphml',\n",
       " 'enron_516.graphml',\n",
       " 'enron_517.graphml',\n",
       " 'enron_518.graphml',\n",
       " 'enron_519.graphml',\n",
       " 'enron_52.graphml',\n",
       " 'enron_520.graphml',\n",
       " 'enron_521.graphml',\n",
       " 'enron_522.graphml',\n",
       " 'enron_523.graphml',\n",
       " 'enron_524.graphml',\n",
       " 'enron_525.graphml',\n",
       " 'enron_526.graphml',\n",
       " 'enron_527.graphml',\n",
       " 'enron_528.graphml',\n",
       " 'enron_529.graphml',\n",
       " 'enron_53.graphml',\n",
       " 'enron_530.graphml',\n",
       " 'enron_531.graphml',\n",
       " 'enron_532.graphml',\n",
       " 'enron_533.graphml',\n",
       " 'enron_534.graphml',\n",
       " 'enron_535.graphml',\n",
       " 'enron_536.graphml',\n",
       " 'enron_537.graphml',\n",
       " 'enron_538.graphml',\n",
       " 'enron_539.graphml',\n",
       " 'enron_54.graphml',\n",
       " 'enron_540.graphml',\n",
       " 'enron_541.graphml',\n",
       " 'enron_542.graphml',\n",
       " 'enron_543.graphml',\n",
       " 'enron_544.graphml',\n",
       " 'enron_545.graphml',\n",
       " 'enron_546.graphml',\n",
       " 'enron_547.graphml',\n",
       " 'enron_548.graphml',\n",
       " 'enron_549.graphml',\n",
       " 'enron_55.graphml',\n",
       " 'enron_550.graphml',\n",
       " 'enron_551.graphml',\n",
       " 'enron_552.graphml',\n",
       " 'enron_553.graphml',\n",
       " 'enron_554.graphml',\n",
       " 'enron_555.graphml',\n",
       " 'enron_556.graphml',\n",
       " 'enron_557.graphml',\n",
       " 'enron_558.graphml',\n",
       " 'enron_559.graphml',\n",
       " 'enron_56.graphml',\n",
       " 'enron_560.graphml',\n",
       " 'enron_561.graphml',\n",
       " 'enron_562.graphml',\n",
       " 'enron_563.graphml',\n",
       " 'enron_564.graphml',\n",
       " 'enron_565.graphml',\n",
       " 'enron_566.graphml',\n",
       " 'enron_567.graphml',\n",
       " 'enron_568.graphml',\n",
       " 'enron_569.graphml',\n",
       " 'enron_57.graphml',\n",
       " 'enron_570.graphml',\n",
       " 'enron_571.graphml',\n",
       " 'enron_572.graphml',\n",
       " 'enron_573.graphml',\n",
       " 'enron_574.graphml',\n",
       " 'enron_575.graphml',\n",
       " 'enron_576.graphml',\n",
       " 'enron_577.graphml',\n",
       " 'enron_578.graphml',\n",
       " 'enron_579.graphml',\n",
       " 'enron_58.graphml',\n",
       " 'enron_580.graphml',\n",
       " 'enron_581.graphml',\n",
       " 'enron_582.graphml',\n",
       " 'enron_583.graphml',\n",
       " 'enron_584.graphml',\n",
       " 'enron_585.graphml',\n",
       " 'enron_586.graphml',\n",
       " 'enron_587.graphml',\n",
       " 'enron_588.graphml',\n",
       " 'enron_589.graphml',\n",
       " 'enron_59.graphml',\n",
       " 'enron_590.graphml',\n",
       " 'enron_591.graphml',\n",
       " 'enron_592.graphml',\n",
       " 'enron_593.graphml',\n",
       " 'enron_594.graphml',\n",
       " 'enron_595.graphml',\n",
       " 'enron_596.graphml',\n",
       " 'enron_597.graphml',\n",
       " 'enron_598.graphml',\n",
       " 'enron_599.graphml',\n",
       " 'enron_6.graphml',\n",
       " 'enron_60.graphml',\n",
       " 'enron_600.graphml',\n",
       " 'enron_601.graphml',\n",
       " 'enron_602.graphml',\n",
       " 'enron_603.graphml',\n",
       " 'enron_604.graphml',\n",
       " 'enron_605.graphml',\n",
       " 'enron_606.graphml',\n",
       " 'enron_607.graphml',\n",
       " 'enron_608.graphml',\n",
       " 'enron_609.graphml',\n",
       " 'enron_61.graphml',\n",
       " 'enron_610.graphml',\n",
       " 'enron_611.graphml',\n",
       " 'enron_612.graphml',\n",
       " 'enron_613.graphml',\n",
       " 'enron_614.graphml',\n",
       " 'enron_615.graphml',\n",
       " 'enron_616.graphml',\n",
       " 'enron_617.graphml',\n",
       " 'enron_618.graphml',\n",
       " 'enron_619.graphml',\n",
       " 'enron_62.graphml',\n",
       " 'enron_620.graphml',\n",
       " 'enron_621.graphml',\n",
       " 'enron_622.graphml',\n",
       " 'enron_623.graphml',\n",
       " 'enron_624.graphml',\n",
       " 'enron_625.graphml',\n",
       " 'enron_626.graphml',\n",
       " 'enron_627.graphml',\n",
       " 'enron_628.graphml',\n",
       " 'enron_629.graphml',\n",
       " 'enron_63.graphml',\n",
       " 'enron_630.graphml',\n",
       " 'enron_631.graphml',\n",
       " 'enron_632.graphml',\n",
       " 'enron_633.graphml',\n",
       " 'enron_634.graphml',\n",
       " 'enron_635.graphml',\n",
       " 'enron_636.graphml',\n",
       " 'enron_64.graphml',\n",
       " 'enron_65.graphml',\n",
       " 'enron_66.graphml',\n",
       " 'enron_67.graphml',\n",
       " 'enron_68.graphml',\n",
       " 'enron_69.graphml',\n",
       " 'enron_7.graphml',\n",
       " 'enron_70.graphml',\n",
       " 'enron_71.graphml',\n",
       " 'enron_72.graphml',\n",
       " 'enron_73.graphml',\n",
       " 'enron_74.graphml',\n",
       " 'enron_75.graphml',\n",
       " 'enron_76.graphml',\n",
       " 'enron_77.graphml',\n",
       " 'enron_78.graphml',\n",
       " 'enron_79.graphml',\n",
       " 'enron_8.graphml',\n",
       " 'enron_80.graphml',\n",
       " 'enron_81.graphml',\n",
       " 'enron_82.graphml',\n",
       " 'enron_83.graphml',\n",
       " 'enron_84.graphml',\n",
       " 'enron_85.graphml',\n",
       " 'enron_86.graphml',\n",
       " 'enron_87.graphml',\n",
       " 'enron_88.graphml',\n",
       " 'enron_89.graphml',\n",
       " 'enron_9.graphml',\n",
       " 'enron_90.graphml',\n",
       " 'enron_91.graphml',\n",
       " 'enron_92.graphml',\n",
       " 'enron_93.graphml',\n",
       " 'enron_94.graphml',\n",
       " 'enron_95.graphml',\n",
       " 'enron_96.graphml',\n",
       " 'enron_97.graphml',\n",
       " 'enron_98.graphml',\n",
       " 'enron_99.graphml']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637\n"
     ]
    }
   ],
   "source": [
    "c = open('../enron/time_steps.txt')\n",
    "q = c.readlines()\n",
    "c.close()\n",
    "print(len(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mAnonymousWalkEmbeddings.py\u001b[m\u001b[m*  \u001b[1m\u001b[36mdoc2vec_results2\u001b[m\u001b[m/\r\n",
      "AnonymousWalkEmbeddings.pyc  \u001b[1m\u001b[36mdocker\u001b[m\u001b[m/\r\n",
      "\u001b[31mAnonymousWalkKernel.py\u001b[m\u001b[m*      func_tools.py\r\n",
      "AnonymousWalkKernel.pyc      func_tools.pyc\r\n",
      "\u001b[31mReadme.md\u001b[m\u001b[m*                   isolation_forest.pdf\r\n",
      "\u001b[31mTutorial.ipynb\u001b[m\u001b[m*              \u001b[1m\u001b[36mmutag\u001b[m\u001b[m/\r\n",
      "__init__.py                  oneclass_svm.pdf\r\n",
      "__init__.pyc                 setuptools-33.1.1.zip\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel27",
   "language": "python",
   "name": "kernel27"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
